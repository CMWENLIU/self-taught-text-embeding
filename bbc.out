
Parameters:-------------------------------------------------------
ALLOW_SOFT_PLACEMENT=True
BATCH_SIZE=64
CHECKPOINT_EVERY=100
DEV_SAMPLE_PERCENTAGE=0.2
DROPOUT_KEEP_PROB=0.5
EMBEDDING_DIM=100
EMBEDDING_DIR=./embedding/
EVALUATE_EVERY=100
FILTER_SIZES=3,4,5
L2_REG_LAMBDA=0.0
LABELED_DATA_DIR=./labeled-data/
LOG_DEVICE_PLACEMENT=False
NUM_CHECKPOINTS=5
NUM_EPOCHS=100
NUM_FILTERS=64
TRAINED_EMBEDDING=True
TRANSFER_LEARNING=False
UNLABELED_DATA_DIR=./unlabeled-data/

Loading data for CNN classification model--------------------------
Following is the data loaded for CNN model:
./labeled-data/s.txt
./labeled-data/t.txt
./labeled-data/b.txt
./labeled-data/e.txt
./labeled-data/p.txt
Following is the labels for supervised learning:
[1, 0, 0, 0, 0]
[0, 1, 0, 0, 0]
[0, 0, 1, 0, 0]
[0, 0, 0, 1, 0]
[0, 0, 0, 0, 1]
Data is successfully loaded!
Vocabulary Size: 27157
Train/Dev split: 1679/419
Shape of x_train:  (1679, 988)
Shape of y_train:  (1679, 5)
Shape of x_dev:  (419, 988)
Shape of y_dev:  (419, 5)
Writing to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038

Load embedding file--------------------------------------------------
Following data are being loaded to train embedding vetors:
./labeled-data/s.txt
./labeled-data/t.txt
./labeled-data/b.txt
./labeled-data/e.txt
./labeled-data/p.txt
Totally: 2098 lines of text
embedding file: ./embedding/labeled.100.vec has been sucessfully loaded!

2018-03-14T17:37:22.640911: step 1, loss 6.34888, acc 0.1875
2018-03-14T17:37:23.499724: step 2, loss 6.36047, acc 0.140625
2018-03-14T17:37:24.303648: step 3, loss 4.94172, acc 0.234375
2018-03-14T17:37:25.133342: step 4, loss 6.33578, acc 0.15625
2018-03-14T17:37:25.968152: step 5, loss 5.1729, acc 0.265625
2018-03-14T17:37:26.790464: step 6, loss 6.82543, acc 0.15625
2018-03-14T17:37:27.599125: step 7, loss 5.48904, acc 0.21875
2018-03-14T17:37:28.435462: step 8, loss 5.58758, acc 0.296875
2018-03-14T17:37:29.242867: step 9, loss 4.41868, acc 0.296875
2018-03-14T17:37:30.065501: step 10, loss 4.8448, acc 0.21875
2018-03-14T17:37:30.890306: step 11, loss 4.4671, acc 0.25
2018-03-14T17:37:31.697597: step 12, loss 4.88991, acc 0.234375
2018-03-14T17:37:32.514769: step 13, loss 4.56514, acc 0.234375
2018-03-14T17:37:33.340822: step 14, loss 5.17623, acc 0.234375
2018-03-14T17:37:34.154940: step 15, loss 4.84137, acc 0.203125
2018-03-14T17:37:34.970310: step 16, loss 4.99322, acc 0.1875
2018-03-14T17:37:35.780445: step 17, loss 4.50654, acc 0.1875
2018-03-14T17:37:36.586623: step 18, loss 5.29646, acc 0.296875
2018-03-14T17:37:37.398529: step 19, loss 4.55362, acc 0.203125
2018-03-14T17:37:38.220536: step 20, loss 4.27549, acc 0.3125
2018-03-14T17:37:39.048136: step 21, loss 4.2007, acc 0.328125
2018-03-14T17:37:39.862134: step 22, loss 4.1008, acc 0.3125
2018-03-14T17:37:40.672581: step 23, loss 4.53515, acc 0.234375
2018-03-14T17:37:41.518432: step 24, loss 4.23485, acc 0.34375
2018-03-14T17:37:42.343310: step 25, loss 4.03717, acc 0.40625
2018-03-14T17:37:43.164529: step 26, loss 4.12726, acc 0.296875
2018-03-14T17:37:43.386340: step 27, loss 3.05679, acc 0.333333
2018-03-14T17:37:44.212307: step 28, loss 4.25228, acc 0.3125
2018-03-14T17:37:45.026789: step 29, loss 3.77926, acc 0.34375
2018-03-14T17:37:45.854532: step 30, loss 3.17096, acc 0.359375
2018-03-14T17:37:46.664076: step 31, loss 3.35336, acc 0.390625
2018-03-14T17:37:47.501272: step 32, loss 3.58722, acc 0.328125
2018-03-14T17:37:48.343077: step 33, loss 3.05432, acc 0.453125
2018-03-14T17:37:49.171533: step 34, loss 2.85456, acc 0.453125
2018-03-14T17:37:49.990153: step 35, loss 2.9082, acc 0.328125
2018-03-14T17:37:50.802048: step 36, loss 2.67056, acc 0.375
2018-03-14T17:37:51.640532: step 37, loss 2.81881, acc 0.4375
2018-03-14T17:37:52.456129: step 38, loss 3.34807, acc 0.3125
2018-03-14T17:37:53.275229: step 39, loss 3.1039, acc 0.375
2018-03-14T17:37:54.104112: step 40, loss 3.12395, acc 0.265625
2018-03-14T17:37:54.943188: step 41, loss 3.05234, acc 0.34375
2018-03-14T17:37:55.767228: step 42, loss 3.45814, acc 0.3125
2018-03-14T17:37:56.579729: step 43, loss 2.42862, acc 0.453125
2018-03-14T17:37:57.404516: step 44, loss 2.7099, acc 0.375
2018-03-14T17:37:58.223793: step 45, loss 2.73295, acc 0.375
2018-03-14T17:37:59.027636: step 46, loss 2.37106, acc 0.4375
2018-03-14T17:37:59.837006: step 47, loss 2.76716, acc 0.328125
2018-03-14T17:38:00.665551: step 48, loss 3.07892, acc 0.359375
2018-03-14T17:38:01.477355: step 49, loss 2.89568, acc 0.265625
2018-03-14T17:38:02.302777: step 50, loss 3.33346, acc 0.34375
2018-03-14T17:38:03.112904: step 51, loss 2.27864, acc 0.4375
2018-03-14T17:38:03.926679: step 52, loss 1.94962, acc 0.484375
2018-03-14T17:38:04.725148: step 53, loss 2.42518, acc 0.375
2018-03-14T17:38:04.942741: step 54, loss 2.66016, acc 0.466667
2018-03-14T17:38:05.751687: step 55, loss 1.70303, acc 0.4375
2018-03-14T17:38:06.591993: step 56, loss 2.40308, acc 0.453125
2018-03-14T17:38:07.398734: step 57, loss 2.50616, acc 0.34375
2018-03-14T17:38:08.207385: step 58, loss 1.94109, acc 0.4375
2018-03-14T17:38:09.029931: step 59, loss 2.19704, acc 0.4375
2018-03-14T17:38:09.842134: step 60, loss 2.03584, acc 0.375
2018-03-14T17:38:10.666255: step 61, loss 1.8219, acc 0.40625
2018-03-14T17:38:11.495194: step 62, loss 2.16644, acc 0.53125
2018-03-14T17:38:12.348869: step 63, loss 2.12461, acc 0.421875
2018-03-14T17:38:13.158297: step 64, loss 2.21062, acc 0.375
2018-03-14T17:38:13.984612: step 65, loss 2.00291, acc 0.5
2018-03-14T17:38:14.814022: step 66, loss 2.37564, acc 0.4375
2018-03-14T17:38:15.644984: step 67, loss 1.8888, acc 0.59375
2018-03-14T17:38:16.474818: step 68, loss 1.87924, acc 0.40625
2018-03-14T17:38:17.294441: step 69, loss 2.20064, acc 0.453125
2018-03-14T17:38:18.137436: step 70, loss 1.68896, acc 0.53125
2018-03-14T17:38:18.950586: step 71, loss 1.72118, acc 0.4375
2018-03-14T17:38:19.758610: step 72, loss 1.52835, acc 0.5
2018-03-14T17:38:20.571985: step 73, loss 1.21052, acc 0.609375
2018-03-14T17:38:21.384987: step 74, loss 1.87381, acc 0.53125
2018-03-14T17:38:22.190928: step 75, loss 1.58652, acc 0.515625
2018-03-14T17:38:22.994095: step 76, loss 1.87312, acc 0.53125
2018-03-14T17:38:23.806923: step 77, loss 1.7499, acc 0.484375
2018-03-14T17:38:24.652535: step 78, loss 2.32746, acc 0.390625
2018-03-14T17:38:25.460930: step 79, loss 1.57026, acc 0.484375
2018-03-14T17:38:26.270579: step 80, loss 1.56073, acc 0.515625
2018-03-14T17:38:26.488113: step 81, loss 1.41238, acc 0.333333
2018-03-14T17:38:27.307755: step 82, loss 2.20279, acc 0.46875
2018-03-14T17:38:28.124642: step 83, loss 1.62249, acc 0.59375
2018-03-14T17:38:28.942903: step 84, loss 1.33536, acc 0.59375
2018-03-14T17:38:29.758477: step 85, loss 1.63592, acc 0.515625
2018-03-14T17:38:30.603130: step 86, loss 1.35663, acc 0.46875
2018-03-14T17:38:31.419874: step 87, loss 1.50798, acc 0.546875
2018-03-14T17:38:32.243512: step 88, loss 1.50155, acc 0.5
2018-03-14T17:38:33.070137: step 89, loss 1.87834, acc 0.53125
2018-03-14T17:38:33.871667: step 90, loss 1.64208, acc 0.453125
2018-03-14T17:38:34.685714: step 91, loss 1.6773, acc 0.515625
2018-03-14T17:38:35.510817: step 92, loss 1.49418, acc 0.46875
2018-03-14T17:38:36.354629: step 93, loss 1.64743, acc 0.515625
2018-03-14T17:38:37.158796: step 94, loss 1.53992, acc 0.546875
2018-03-14T17:38:37.956646: step 95, loss 1.66141, acc 0.515625
2018-03-14T17:38:38.761680: step 96, loss 1.5417, acc 0.515625
2018-03-14T17:38:39.576611: step 97, loss 1.47008, acc 0.5625
2018-03-14T17:38:40.378112: step 98, loss 1.22551, acc 0.578125
2018-03-14T17:38:41.198625: step 99, loss 1.41591, acc 0.578125
2018-03-14T17:38:42.054355: step 100, loss 1.40734, acc 0.515625

Evaluation:
2018-03-14T17:39:10.152481: step 100, loss 0.818269, acc 0.706444

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-100

2018-03-14T17:39:16.524268: step 101, loss 1.49927, acc 0.59375
2018-03-14T17:39:17.625892: step 102, loss 1.20719, acc 0.578125
2018-03-14T17:39:18.424268: step 103, loss 1.55406, acc 0.515625
2018-03-14T17:39:19.224930: step 104, loss 1.23456, acc 0.546875
2018-03-14T17:39:20.016566: step 105, loss 1.38758, acc 0.53125
2018-03-14T17:39:20.878142: step 106, loss 1.13673, acc 0.6875
2018-03-14T17:39:21.665968: step 107, loss 1.28645, acc 0.5
2018-03-14T17:39:21.886675: step 108, loss 1.24817, acc 0.4
2018-03-14T17:39:22.858989: step 109, loss 1.71062, acc 0.578125
2018-03-14T17:39:23.644674: step 110, loss 1.30913, acc 0.515625
2018-03-14T17:39:24.434662: step 111, loss 1.41905, acc 0.484375
2018-03-14T17:39:25.225838: step 112, loss 1.64941, acc 0.59375
2018-03-14T17:39:26.026949: step 113, loss 0.919167, acc 0.6875
2018-03-14T17:39:26.807321: step 114, loss 1.17731, acc 0.609375
2018-03-14T17:39:27.595101: step 115, loss 1.35677, acc 0.5625
2018-03-14T17:39:28.394423: step 116, loss 1.30674, acc 0.578125
2018-03-14T17:39:29.182313: step 117, loss 1.37186, acc 0.59375
2018-03-14T17:39:29.970878: step 118, loss 1.00655, acc 0.671875
2018-03-14T17:39:30.762425: step 119, loss 1.05389, acc 0.671875
2018-03-14T17:39:31.547689: step 120, loss 0.88986, acc 0.671875
2018-03-14T17:39:32.336756: step 121, loss 1.19214, acc 0.5625
2018-03-14T17:39:33.126799: step 122, loss 0.617179, acc 0.78125
2018-03-14T17:39:33.918816: step 123, loss 1.22641, acc 0.5
2018-03-14T17:39:34.705098: step 124, loss 0.96385, acc 0.609375
2018-03-14T17:39:35.490286: step 125, loss 0.794686, acc 0.703125
2018-03-14T17:39:36.281096: step 126, loss 1.39924, acc 0.609375
2018-03-14T17:39:37.070855: step 127, loss 1.10432, acc 0.6875
2018-03-14T17:39:37.856313: step 128, loss 1.36121, acc 0.5625
2018-03-14T17:39:38.643234: step 129, loss 1.08423, acc 0.640625
2018-03-14T17:39:39.428983: step 130, loss 1.31323, acc 0.59375
2018-03-14T17:39:40.225201: step 131, loss 1.4386, acc 0.578125
2018-03-14T17:39:41.009108: step 132, loss 1.47661, acc 0.609375
2018-03-14T17:39:41.804065: step 133, loss 0.965686, acc 0.625
2018-03-14T17:39:42.590735: step 134, loss 0.658805, acc 0.765625
2018-03-14T17:39:42.813297: step 135, loss 0.957782, acc 0.6
2018-03-14T17:39:43.595231: step 136, loss 1.2142, acc 0.59375
2018-03-14T17:39:44.389823: step 137, loss 0.845026, acc 0.75
2018-03-14T17:39:45.172632: step 138, loss 0.918558, acc 0.640625
2018-03-14T17:39:45.961260: step 139, loss 0.917138, acc 0.640625
2018-03-14T17:39:46.754147: step 140, loss 0.826179, acc 0.671875
2018-03-14T17:39:47.548207: step 141, loss 0.846317, acc 0.734375
2018-03-14T17:39:48.346345: step 142, loss 1.09307, acc 0.546875
2018-03-14T17:39:49.136864: step 143, loss 1.15523, acc 0.515625
2018-03-14T17:39:49.921241: step 144, loss 1.30233, acc 0.515625
2018-03-14T17:39:50.710628: step 145, loss 0.966309, acc 0.640625
2018-03-14T17:39:51.519932: step 146, loss 0.805996, acc 0.765625
2018-03-14T17:39:52.323231: step 147, loss 1.02439, acc 0.609375
2018-03-14T17:39:53.116744: step 148, loss 0.733593, acc 0.734375
2018-03-14T17:39:53.905980: step 149, loss 0.845171, acc 0.71875
2018-03-14T17:39:54.706252: step 150, loss 0.72443, acc 0.65625
2018-03-14T17:39:55.503794: step 151, loss 0.888704, acc 0.65625
2018-03-14T17:39:56.298107: step 152, loss 1.07246, acc 0.609375
2018-03-14T17:39:57.090160: step 153, loss 1.27231, acc 0.640625
2018-03-14T17:39:57.891534: step 154, loss 0.726833, acc 0.734375
2018-03-14T17:39:58.692195: step 155, loss 1.26835, acc 0.5625
2018-03-14T17:39:59.478385: step 156, loss 0.89033, acc 0.625
2018-03-14T17:40:00.281196: step 157, loss 0.881412, acc 0.65625
2018-03-14T17:40:01.074994: step 158, loss 1.34122, acc 0.53125
2018-03-14T17:40:01.868483: step 159, loss 0.727928, acc 0.734375
2018-03-14T17:40:02.660495: step 160, loss 0.694796, acc 0.75
2018-03-14T17:40:03.446956: step 161, loss 0.354515, acc 0.875
2018-03-14T17:40:03.663395: step 162, loss 0.35828, acc 0.933333
2018-03-14T17:40:04.452761: step 163, loss 0.947041, acc 0.640625
2018-03-14T17:40:05.243982: step 164, loss 0.698806, acc 0.734375
2018-03-14T17:40:06.036235: step 165, loss 0.720997, acc 0.71875
2018-03-14T17:40:06.825837: step 166, loss 0.584311, acc 0.765625
2018-03-14T17:40:07.621536: step 167, loss 0.665496, acc 0.75
2018-03-14T17:40:08.424431: step 168, loss 0.590934, acc 0.828125
2018-03-14T17:40:09.220623: step 169, loss 0.757391, acc 0.6875
2018-03-14T17:40:10.021926: step 170, loss 0.701709, acc 0.734375
2018-03-14T17:40:10.822657: step 171, loss 0.742017, acc 0.75
2018-03-14T17:40:11.608944: step 172, loss 0.857597, acc 0.671875
2018-03-14T17:40:12.407703: step 173, loss 0.664276, acc 0.78125
2018-03-14T17:40:13.199318: step 174, loss 0.8196, acc 0.71875
2018-03-14T17:40:13.994616: step 175, loss 0.718127, acc 0.703125
2018-03-14T17:40:14.795910: step 176, loss 0.676652, acc 0.765625
2018-03-14T17:40:15.596084: step 177, loss 0.75307, acc 0.734375
2018-03-14T17:40:16.392149: step 178, loss 0.600372, acc 0.78125
2018-03-14T17:40:17.197134: step 179, loss 0.625793, acc 0.703125
2018-03-14T17:40:18.011381: step 180, loss 0.978167, acc 0.6875
2018-03-14T17:40:18.846545: step 181, loss 0.780035, acc 0.765625
2018-03-14T17:40:19.658681: step 182, loss 0.489206, acc 0.875
2018-03-14T17:40:20.463009: step 183, loss 0.68741, acc 0.703125
2018-03-14T17:40:21.261158: step 184, loss 0.617646, acc 0.75
2018-03-14T17:40:22.056550: step 185, loss 0.653727, acc 0.78125
2018-03-14T17:40:22.877516: step 186, loss 0.755464, acc 0.75
2018-03-14T17:40:23.678183: step 187, loss 0.938546, acc 0.625
2018-03-14T17:40:24.489188: step 188, loss 0.711864, acc 0.734375
2018-03-14T17:40:24.711649: step 189, loss 0.563723, acc 0.666667
2018-03-14T17:40:25.519627: step 190, loss 0.677658, acc 0.75
2018-03-14T17:40:26.325567: step 191, loss 0.472892, acc 0.859375
2018-03-14T17:40:27.134194: step 192, loss 0.681092, acc 0.734375
2018-03-14T17:40:27.943629: step 193, loss 0.75476, acc 0.734375
2018-03-14T17:40:28.748607: step 194, loss 0.608191, acc 0.78125
2018-03-14T17:40:29.565731: step 195, loss 0.667771, acc 0.75
2018-03-14T17:40:30.371456: step 196, loss 0.630201, acc 0.75
2018-03-14T17:40:31.180449: step 197, loss 0.567676, acc 0.8125
2018-03-14T17:40:31.982450: step 198, loss 0.672193, acc 0.796875
2018-03-14T17:40:32.790379: step 199, loss 0.714074, acc 0.75
2018-03-14T17:40:33.591327: step 200, loss 0.768498, acc 0.734375

Evaluation:
2018-03-14T17:40:44.579580: step 200, loss 0.634962, acc 0.794749

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-200

2018-03-14T17:40:46.480921: step 201, loss 0.611802, acc 0.71875
2018-03-14T17:40:47.313333: step 202, loss 0.61994, acc 0.765625
2018-03-14T17:40:48.109744: step 203, loss 0.685375, acc 0.75
2018-03-14T17:40:48.913791: step 204, loss 0.414639, acc 0.84375
2018-03-14T17:40:49.713360: step 205, loss 0.572636, acc 0.796875
2018-03-14T17:40:50.513475: step 206, loss 0.567618, acc 0.8125
2018-03-14T17:40:51.309314: step 207, loss 0.533187, acc 0.828125
2018-03-14T17:40:52.109798: step 208, loss 0.451228, acc 0.84375
2018-03-14T17:40:52.910485: step 209, loss 0.632377, acc 0.796875
2018-03-14T17:40:53.699923: step 210, loss 0.526781, acc 0.796875
2018-03-14T17:40:54.489968: step 211, loss 0.631556, acc 0.765625
2018-03-14T17:40:55.284218: step 212, loss 0.602293, acc 0.78125
2018-03-14T17:40:56.074652: step 213, loss 0.820263, acc 0.734375
2018-03-14T17:40:56.865347: step 214, loss 0.643162, acc 0.78125
2018-03-14T17:40:57.653439: step 215, loss 0.672544, acc 0.765625
2018-03-14T17:40:57.874496: step 216, loss 0.631581, acc 0.733333
2018-03-14T17:40:58.694752: step 217, loss 0.508679, acc 0.8125
2018-03-14T17:40:59.489958: step 218, loss 0.456319, acc 0.828125
2018-03-14T17:41:00.283563: step 219, loss 0.533194, acc 0.84375
2018-03-14T17:41:01.075209: step 220, loss 0.629468, acc 0.78125
2018-03-14T17:41:01.860625: step 221, loss 0.506887, acc 0.84375
2018-03-14T17:41:02.649857: step 222, loss 0.453834, acc 0.796875
2018-03-14T17:41:03.447913: step 223, loss 0.495874, acc 0.828125
2018-03-14T17:41:04.247840: step 224, loss 0.401425, acc 0.90625
2018-03-14T17:41:05.035070: step 225, loss 0.595053, acc 0.84375
2018-03-14T17:41:05.825369: step 226, loss 0.646638, acc 0.828125
2018-03-14T17:41:06.628405: step 227, loss 0.623037, acc 0.8125
2018-03-14T17:41:07.427793: step 228, loss 0.665779, acc 0.734375
2018-03-14T17:41:08.228931: step 229, loss 0.511985, acc 0.859375
2018-03-14T17:41:09.064067: step 230, loss 0.490447, acc 0.828125
2018-03-14T17:41:09.858718: step 231, loss 0.430682, acc 0.890625
2018-03-14T17:41:10.656096: step 232, loss 0.552546, acc 0.765625
2018-03-14T17:41:11.457246: step 233, loss 0.484053, acc 0.828125
2018-03-14T17:41:12.253244: step 234, loss 0.435868, acc 0.828125
2018-03-14T17:41:13.051087: step 235, loss 0.491272, acc 0.84375
2018-03-14T17:41:13.844875: step 236, loss 0.343411, acc 0.875
2018-03-14T17:41:14.634166: step 237, loss 0.551344, acc 0.78125
2018-03-14T17:41:15.433103: step 238, loss 0.474618, acc 0.796875
2018-03-14T17:41:16.230130: step 239, loss 0.445699, acc 0.796875
2018-03-14T17:41:17.026181: step 240, loss 0.505194, acc 0.84375
2018-03-14T17:41:17.813513: step 241, loss 0.47357, acc 0.875
2018-03-14T17:41:18.612794: step 242, loss 0.409621, acc 0.875
2018-03-14T17:41:18.835636: step 243, loss 0.624501, acc 0.733333
2018-03-14T17:41:19.635010: step 244, loss 0.424875, acc 0.890625
2018-03-14T17:41:20.437487: step 245, loss 0.539633, acc 0.8125
2018-03-14T17:41:21.238748: step 246, loss 0.459485, acc 0.8125
2018-03-14T17:41:22.027497: step 247, loss 0.453031, acc 0.8125
2018-03-14T17:41:22.818483: step 248, loss 0.479841, acc 0.796875
2018-03-14T17:41:23.614002: step 249, loss 0.387969, acc 0.859375
2018-03-14T17:41:24.408946: step 250, loss 0.556058, acc 0.8125
2018-03-14T17:41:25.208266: step 251, loss 0.44278, acc 0.828125
2018-03-14T17:41:26.001457: step 252, loss 0.402388, acc 0.859375
2018-03-14T17:41:26.795893: step 253, loss 0.373505, acc 0.890625
2018-03-14T17:41:27.594425: step 254, loss 0.384464, acc 0.875
2018-03-14T17:41:28.396777: step 255, loss 0.305149, acc 0.890625
2018-03-14T17:41:29.201080: step 256, loss 0.357976, acc 0.890625
2018-03-14T17:41:29.994709: step 257, loss 0.41478, acc 0.875
2018-03-14T17:41:30.792607: step 258, loss 0.418423, acc 0.828125
2018-03-14T17:41:31.596107: step 259, loss 0.425659, acc 0.859375
2018-03-14T17:41:32.384068: step 260, loss 0.395748, acc 0.921875
2018-03-14T17:41:33.183870: step 261, loss 0.49708, acc 0.796875
2018-03-14T17:41:33.981441: step 262, loss 0.397489, acc 0.875
2018-03-14T17:41:34.779973: step 263, loss 0.382517, acc 0.859375
2018-03-14T17:41:35.578195: step 264, loss 0.494482, acc 0.859375
2018-03-14T17:41:36.374769: step 265, loss 0.434653, acc 0.828125
2018-03-14T17:41:37.181860: step 266, loss 0.324414, acc 0.921875
2018-03-14T17:41:37.980089: step 267, loss 0.395121, acc 0.859375
2018-03-14T17:41:38.786096: step 268, loss 0.428928, acc 0.859375
2018-03-14T17:41:39.586870: step 269, loss 0.478081, acc 0.875
2018-03-14T17:41:39.808578: step 270, loss 0.337287, acc 0.933333
2018-03-14T17:41:40.602519: step 271, loss 0.348092, acc 0.90625
2018-03-14T17:41:41.405666: step 272, loss 0.334077, acc 0.90625
2018-03-14T17:41:42.194256: step 273, loss 0.508114, acc 0.796875
2018-03-14T17:41:42.993212: step 274, loss 0.469818, acc 0.828125
2018-03-14T17:41:43.794734: step 275, loss 0.336113, acc 0.90625
2018-03-14T17:41:44.581265: step 276, loss 0.489049, acc 0.859375
2018-03-14T17:41:45.381819: step 277, loss 0.330914, acc 0.90625
2018-03-14T17:41:46.177231: step 278, loss 0.387219, acc 0.90625
2018-03-14T17:41:46.977409: step 279, loss 0.250987, acc 0.96875
2018-03-14T17:41:47.773039: step 280, loss 0.441926, acc 0.859375
2018-03-14T17:41:48.563182: step 281, loss 0.490203, acc 0.84375
2018-03-14T17:41:49.351822: step 282, loss 0.403561, acc 0.875
2018-03-14T17:41:50.149640: step 283, loss 0.489871, acc 0.765625
2018-03-14T17:41:50.944794: step 284, loss 0.451636, acc 0.890625
2018-03-14T17:41:51.734017: step 285, loss 0.456168, acc 0.875
2018-03-14T17:41:52.537443: step 286, loss 0.452884, acc 0.859375
2018-03-14T17:41:53.339748: step 287, loss 0.406963, acc 0.84375
2018-03-14T17:41:54.134128: step 288, loss 0.363786, acc 0.921875
2018-03-14T17:41:54.922789: step 289, loss 0.346829, acc 0.953125
2018-03-14T17:41:55.709796: step 290, loss 0.383317, acc 0.875
2018-03-14T17:41:56.512279: step 291, loss 0.415245, acc 0.859375
2018-03-14T17:41:57.316928: step 292, loss 0.44726, acc 0.84375
2018-03-14T17:41:58.131001: step 293, loss 0.287358, acc 0.90625
2018-03-14T17:41:58.934043: step 294, loss 0.467674, acc 0.84375
2018-03-14T17:41:59.743466: step 295, loss 0.3056, acc 0.890625
2018-03-14T17:42:00.573106: step 296, loss 0.312834, acc 0.921875
2018-03-14T17:42:00.795367: step 297, loss 0.414555, acc 0.866667
2018-03-14T17:42:01.634649: step 298, loss 0.351684, acc 0.9375
2018-03-14T17:42:02.441471: step 299, loss 0.346385, acc 0.90625
2018-03-14T17:42:03.241167: step 300, loss 0.283734, acc 0.921875

Evaluation:
2018-03-14T17:42:05.279399: step 300, loss 0.550454, acc 0.813842

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-300

2018-03-14T17:42:06.168365: step 301, loss 0.420403, acc 0.890625
2018-03-14T17:42:06.964964: step 302, loss 0.293939, acc 0.921875
2018-03-14T17:42:07.774301: step 303, loss 0.372455, acc 0.875
2018-03-14T17:42:08.571252: step 304, loss 0.29266, acc 0.90625
2018-03-14T17:42:09.364556: step 305, loss 0.245385, acc 0.9375
2018-03-14T17:42:10.175275: step 306, loss 0.366185, acc 0.921875
2018-03-14T17:42:10.971263: step 307, loss 0.290296, acc 0.9375
2018-03-14T17:42:11.763966: step 308, loss 0.379623, acc 0.859375
2018-03-14T17:42:12.565251: step 309, loss 0.328014, acc 0.90625
2018-03-14T17:42:13.358130: step 310, loss 0.368513, acc 0.90625
2018-03-14T17:42:14.146768: step 311, loss 0.270667, acc 0.9375
2018-03-14T17:42:14.956153: step 312, loss 0.282388, acc 0.921875
2018-03-14T17:42:15.748097: step 313, loss 0.380387, acc 0.890625
2018-03-14T17:42:16.544800: step 314, loss 0.33603, acc 0.90625
2018-03-14T17:42:17.340150: step 315, loss 0.330761, acc 0.90625
2018-03-14T17:42:18.149997: step 316, loss 0.32791, acc 0.921875
2018-03-14T17:42:18.956479: step 317, loss 0.331329, acc 0.890625
2018-03-14T17:42:19.763760: step 318, loss 0.365031, acc 0.90625
2018-03-14T17:42:20.562143: step 319, loss 0.369532, acc 0.859375
2018-03-14T17:42:21.361032: step 320, loss 0.363977, acc 0.890625
2018-03-14T17:42:22.159117: step 321, loss 0.376316, acc 0.90625
2018-03-14T17:42:22.951690: step 322, loss 0.352496, acc 0.90625
2018-03-14T17:42:23.740797: step 323, loss 0.300296, acc 0.90625
2018-03-14T17:42:23.963531: step 324, loss 0.311916, acc 0.866667
2018-03-14T17:42:24.754521: step 325, loss 0.282675, acc 0.9375
2018-03-14T17:42:25.546731: step 326, loss 0.35547, acc 0.890625
2018-03-14T17:42:26.350595: step 327, loss 0.241644, acc 0.96875
2018-03-14T17:42:27.145859: step 328, loss 0.269032, acc 0.96875
2018-03-14T17:42:27.939224: step 329, loss 0.352886, acc 0.875
2018-03-14T17:42:28.740871: step 330, loss 0.262864, acc 0.9375
2018-03-14T17:42:29.530730: step 331, loss 0.371707, acc 0.890625
2018-03-14T17:42:30.320171: step 332, loss 0.3553, acc 0.890625
2018-03-14T17:42:31.121443: step 333, loss 0.320568, acc 0.890625
2018-03-14T17:42:31.914737: step 334, loss 0.326865, acc 0.90625
2018-03-14T17:42:32.709547: step 335, loss 0.375233, acc 0.890625
2018-03-14T17:42:33.508680: step 336, loss 0.260917, acc 0.921875
2018-03-14T17:42:34.303894: step 337, loss 0.429218, acc 0.90625
2018-03-14T17:42:35.092734: step 338, loss 0.265614, acc 0.90625
2018-03-14T17:42:35.884922: step 339, loss 0.240338, acc 0.953125
2018-03-14T17:42:36.677974: step 340, loss 0.304777, acc 0.921875
2018-03-14T17:42:37.467622: step 341, loss 0.271652, acc 0.921875
2018-03-14T17:42:38.255829: step 342, loss 0.239495, acc 0.9375
2018-03-14T17:42:39.052087: step 343, loss 0.324517, acc 0.921875
2018-03-14T17:42:39.852254: step 344, loss 0.237531, acc 0.96875
2018-03-14T17:42:40.645509: step 345, loss 0.266236, acc 0.953125
2018-03-14T17:42:41.436703: step 346, loss 0.329859, acc 0.859375
2018-03-14T17:42:42.238988: step 347, loss 0.394395, acc 0.859375
2018-03-14T17:42:43.030323: step 348, loss 0.274103, acc 0.890625
2018-03-14T17:42:43.830684: step 349, loss 0.207473, acc 0.953125
2018-03-14T17:42:44.626114: step 350, loss 0.240994, acc 0.953125
2018-03-14T17:42:44.845666: step 351, loss 0.284118, acc 1
2018-03-14T17:42:45.629165: step 352, loss 0.274162, acc 0.921875
2018-03-14T17:42:46.427039: step 353, loss 0.347986, acc 0.921875
2018-03-14T17:42:47.220423: step 354, loss 0.258381, acc 0.921875
2018-03-14T17:42:48.021167: step 355, loss 0.231478, acc 0.9375
2018-03-14T17:42:48.811273: step 356, loss 0.285623, acc 0.921875
2018-03-14T17:42:49.600322: step 357, loss 0.23385, acc 0.9375
2018-03-14T17:42:50.388403: step 358, loss 0.233595, acc 0.9375
2018-03-14T17:42:51.182491: step 359, loss 0.302956, acc 0.9375
2018-03-14T17:42:51.979815: step 360, loss 0.189975, acc 0.984375
2018-03-14T17:42:52.773707: step 361, loss 0.247308, acc 0.953125
2018-03-14T17:42:53.565000: step 362, loss 0.181433, acc 0.984375
2018-03-14T17:42:54.362185: step 363, loss 0.195167, acc 0.9375
2018-03-14T17:42:55.159751: step 364, loss 0.222023, acc 0.9375
2018-03-14T17:42:55.955079: step 365, loss 0.238362, acc 0.953125
2018-03-14T17:42:56.757543: step 366, loss 0.319754, acc 0.953125
2018-03-14T17:42:57.562219: step 367, loss 0.23523, acc 0.953125
2018-03-14T17:42:58.354149: step 368, loss 0.226787, acc 0.953125
2018-03-14T17:42:59.148492: step 369, loss 0.345139, acc 0.875
2018-03-14T17:42:59.944024: step 370, loss 0.299509, acc 0.90625
2018-03-14T17:43:00.734457: step 371, loss 0.261923, acc 0.96875
2018-03-14T17:43:01.522752: step 372, loss 0.220058, acc 0.953125
2018-03-14T17:43:02.317455: step 373, loss 0.305094, acc 0.9375
2018-03-14T17:43:03.111066: step 374, loss 0.324712, acc 0.875
2018-03-14T17:43:03.910175: step 375, loss 0.244417, acc 0.9375
2018-03-14T17:43:04.702696: step 376, loss 0.257311, acc 0.9375
2018-03-14T17:43:05.496877: step 377, loss 0.211756, acc 0.96875
2018-03-14T17:43:05.714909: step 378, loss 0.150256, acc 1
2018-03-14T17:43:06.515408: step 379, loss 0.265976, acc 0.90625
2018-03-14T17:43:07.309007: step 380, loss 0.191277, acc 0.96875
2018-03-14T17:43:08.104050: step 381, loss 0.196048, acc 0.9375
2018-03-14T17:43:08.904045: step 382, loss 0.20223, acc 0.953125
2018-03-14T17:43:09.686544: step 383, loss 0.370173, acc 0.90625
2018-03-14T17:43:10.474284: step 384, loss 0.258192, acc 0.921875
2018-03-14T17:43:11.274463: step 385, loss 0.237271, acc 0.921875
2018-03-14T17:43:12.075729: step 386, loss 0.200336, acc 0.96875
2018-03-14T17:43:12.867790: step 387, loss 0.219791, acc 0.921875
2018-03-14T17:43:13.658312: step 388, loss 0.253227, acc 0.90625
2018-03-14T17:43:14.451558: step 389, loss 0.300289, acc 0.921875
2018-03-14T17:43:15.246567: step 390, loss 0.219084, acc 0.9375
2018-03-14T17:43:16.052022: step 391, loss 0.176961, acc 1
2018-03-14T17:43:16.838798: step 392, loss 0.176462, acc 0.96875
2018-03-14T17:43:17.637849: step 393, loss 0.188585, acc 0.96875
2018-03-14T17:43:18.428870: step 394, loss 0.27191, acc 0.9375
2018-03-14T17:43:19.221473: step 395, loss 0.172435, acc 0.96875
2018-03-14T17:43:20.014375: step 396, loss 0.249535, acc 0.953125
2018-03-14T17:43:20.808536: step 397, loss 0.201553, acc 0.953125
2018-03-14T17:43:21.607470: step 398, loss 0.15828, acc 0.984375
2018-03-14T17:43:22.405008: step 399, loss 0.23755, acc 0.96875
2018-03-14T17:43:23.198980: step 400, loss 0.144643, acc 0.96875

Evaluation:
2018-03-14T17:43:24.712448: step 400, loss 0.507898, acc 0.823389

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-400

2018-03-14T17:43:25.622294: step 401, loss 0.220676, acc 0.96875
2018-03-14T17:43:26.417176: step 402, loss 0.188335, acc 1
2018-03-14T17:43:27.221197: step 403, loss 0.261482, acc 0.921875
2018-03-14T17:43:28.008551: step 404, loss 0.267977, acc 0.90625
2018-03-14T17:43:28.232764: step 405, loss 0.137253, acc 1
2018-03-14T17:43:29.022443: step 406, loss 0.200457, acc 0.96875
2018-03-14T17:43:29.819181: step 407, loss 0.270047, acc 0.9375
2018-03-14T17:43:30.616216: step 408, loss 0.184629, acc 0.96875
2018-03-14T17:43:31.414114: step 409, loss 0.185692, acc 0.953125
2018-03-14T17:43:32.207903: step 410, loss 0.233465, acc 0.984375
2018-03-14T17:43:33.009538: step 411, loss 0.22851, acc 0.96875
2018-03-14T17:43:33.809360: step 412, loss 0.193822, acc 0.984375
2018-03-14T17:43:34.597230: step 413, loss 0.147989, acc 1
2018-03-14T17:43:35.390866: step 414, loss 0.159986, acc 0.953125
2018-03-14T17:43:36.190514: step 415, loss 0.167891, acc 0.953125
2018-03-14T17:43:36.993246: step 416, loss 0.160629, acc 0.984375
2018-03-14T17:43:37.796344: step 417, loss 0.270166, acc 0.9375
2018-03-14T17:43:38.592881: step 418, loss 0.244569, acc 0.90625
2018-03-14T17:43:39.396927: step 419, loss 0.187936, acc 0.953125
2018-03-14T17:43:40.196075: step 420, loss 0.212697, acc 0.90625
2018-03-14T17:43:40.997271: step 421, loss 0.173926, acc 0.96875
2018-03-14T17:43:41.790385: step 422, loss 0.186207, acc 0.953125
2018-03-14T17:43:42.597896: step 423, loss 0.213373, acc 0.953125
2018-03-14T17:43:43.388771: step 424, loss 0.197384, acc 0.984375
2018-03-14T17:43:44.185805: step 425, loss 0.248787, acc 0.9375
2018-03-14T17:43:44.982632: step 426, loss 0.233221, acc 0.953125
2018-03-14T17:43:45.775916: step 427, loss 0.240392, acc 0.921875
2018-03-14T17:43:46.573191: step 428, loss 0.297181, acc 0.875
2018-03-14T17:43:47.377184: step 429, loss 0.278699, acc 0.890625
2018-03-14T17:43:48.174392: step 430, loss 0.121299, acc 1
2018-03-14T17:43:48.971761: step 431, loss 0.203767, acc 0.9375
2018-03-14T17:43:49.194713: step 432, loss 0.175225, acc 1
2018-03-14T17:43:49.988089: step 433, loss 0.211732, acc 0.953125
2018-03-14T17:43:50.784419: step 434, loss 0.173423, acc 0.984375
2018-03-14T17:43:51.588763: step 435, loss 0.223806, acc 0.953125
2018-03-14T17:43:52.391651: step 436, loss 0.167674, acc 0.984375
2018-03-14T17:43:53.180956: step 437, loss 0.195151, acc 0.9375
2018-03-14T17:43:53.977829: step 438, loss 0.152941, acc 0.96875
2018-03-14T17:43:54.776633: step 439, loss 0.141891, acc 1
2018-03-14T17:43:55.580162: step 440, loss 0.11566, acc 1
2018-03-14T17:43:56.369931: step 441, loss 0.132367, acc 0.96875
2018-03-14T17:43:57.168577: step 442, loss 0.171308, acc 0.96875
2018-03-14T17:43:57.963263: step 443, loss 0.199304, acc 0.96875
2018-03-14T17:43:58.754682: step 444, loss 0.173908, acc 0.984375
2018-03-14T17:43:59.551314: step 445, loss 0.232849, acc 0.953125
2018-03-14T17:44:00.350493: step 446, loss 0.137504, acc 1
2018-03-14T17:44:01.155051: step 447, loss 0.209437, acc 0.96875
2018-03-14T17:44:01.956460: step 448, loss 0.149817, acc 0.984375
2018-03-14T17:44:02.754059: step 449, loss 0.178291, acc 0.984375
2018-03-14T17:44:03.553839: step 450, loss 0.12779, acc 1
2018-03-14T17:44:04.359450: step 451, loss 0.169011, acc 0.96875
2018-03-14T17:44:05.159502: step 452, loss 0.220223, acc 0.984375
2018-03-14T17:44:05.961865: step 453, loss 0.11852, acc 0.984375
2018-03-14T17:44:06.758470: step 454, loss 0.191028, acc 0.953125
2018-03-14T17:44:07.549435: step 455, loss 0.203667, acc 0.921875
2018-03-14T17:44:08.351510: step 456, loss 0.189882, acc 0.953125
2018-03-14T17:44:09.149001: step 457, loss 0.176234, acc 0.953125
2018-03-14T17:44:09.943887: step 458, loss 0.183787, acc 0.96875
2018-03-14T17:44:10.165562: step 459, loss 0.295496, acc 1
2018-03-14T17:44:10.963955: step 460, loss 0.152093, acc 0.96875
2018-03-14T17:44:11.764939: step 461, loss 0.137896, acc 0.984375
2018-03-14T17:44:12.563192: step 462, loss 0.158128, acc 0.96875
2018-03-14T17:44:13.355817: step 463, loss 0.183025, acc 0.96875
2018-03-14T17:44:14.161374: step 464, loss 0.168498, acc 0.953125
2018-03-14T17:44:14.962763: step 465, loss 0.169627, acc 0.9375
2018-03-14T17:44:15.763727: step 466, loss 0.123133, acc 0.984375
2018-03-14T17:44:16.571149: step 467, loss 0.167812, acc 0.953125
2018-03-14T17:44:17.369367: step 468, loss 0.118757, acc 0.984375
2018-03-14T17:44:18.163361: step 469, loss 0.114312, acc 0.984375
2018-03-14T17:44:18.958238: step 470, loss 0.198499, acc 0.953125
2018-03-14T17:44:19.755164: step 471, loss 0.126452, acc 0.984375
2018-03-14T17:44:20.553572: step 472, loss 0.16443, acc 0.984375
2018-03-14T17:44:21.357731: step 473, loss 0.11415, acc 0.984375
2018-03-14T17:44:22.161167: step 474, loss 0.155561, acc 0.984375
2018-03-14T17:44:22.945477: step 475, loss 0.113287, acc 1
2018-03-14T17:44:23.746850: step 476, loss 0.176498, acc 0.953125
2018-03-14T17:44:24.553979: step 477, loss 0.202942, acc 0.953125
2018-03-14T17:44:25.344151: step 478, loss 0.221902, acc 0.953125
2018-03-14T17:44:26.151486: step 479, loss 0.180306, acc 0.96875
2018-03-14T17:44:26.949504: step 480, loss 0.148881, acc 0.96875
2018-03-14T17:44:27.750451: step 481, loss 0.130104, acc 0.96875
2018-03-14T17:44:28.549411: step 482, loss 0.182818, acc 0.96875
2018-03-14T17:44:29.342462: step 483, loss 0.287397, acc 0.921875
2018-03-14T17:44:30.139793: step 484, loss 0.155355, acc 0.984375
2018-03-14T17:44:30.928869: step 485, loss 0.145781, acc 0.984375
2018-03-14T17:44:31.151490: step 486, loss 0.197675, acc 0.933333
2018-03-14T17:44:31.942956: step 487, loss 0.0939077, acc 1
2018-03-14T17:44:32.738796: step 488, loss 0.17415, acc 0.984375
2018-03-14T17:44:33.535407: step 489, loss 0.13122, acc 0.96875
2018-03-14T17:44:34.326298: step 490, loss 0.13601, acc 0.96875
2018-03-14T17:44:35.112644: step 491, loss 0.113384, acc 1
2018-03-14T17:44:35.909558: step 492, loss 0.11961, acc 1
2018-03-14T17:44:36.703862: step 493, loss 0.134152, acc 0.984375
2018-03-14T17:44:37.499376: step 494, loss 0.21823, acc 0.953125
2018-03-14T17:44:38.297978: step 495, loss 0.107766, acc 1
2018-03-14T17:44:39.088394: step 496, loss 0.192976, acc 0.921875
2018-03-14T17:44:39.880032: step 497, loss 0.136933, acc 0.96875
2018-03-14T17:44:40.678094: step 498, loss 0.150912, acc 0.96875
2018-03-14T17:44:41.475803: step 499, loss 0.162092, acc 0.953125
2018-03-14T17:44:42.271680: step 500, loss 0.158115, acc 0.953125

Evaluation:
2018-03-14T17:44:44.236358: step 500, loss 0.485132, acc 0.847255

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-500

2018-03-14T17:44:45.150796: step 501, loss 0.17234, acc 0.90625
2018-03-14T17:44:45.939003: step 502, loss 0.126538, acc 1
2018-03-14T17:44:46.740379: step 503, loss 0.0898243, acc 1
2018-03-14T17:44:47.530476: step 504, loss 0.0837793, acc 1
2018-03-14T17:44:48.331933: step 505, loss 0.174605, acc 0.96875
2018-03-14T17:44:49.124168: step 506, loss 0.157807, acc 0.984375
2018-03-14T17:44:49.920555: step 507, loss 0.108174, acc 1
2018-03-14T17:44:50.714356: step 508, loss 0.136913, acc 1
2018-03-14T17:44:51.511407: step 509, loss 0.141295, acc 0.984375
2018-03-14T17:44:52.308649: step 510, loss 0.143567, acc 0.96875
2018-03-14T17:44:53.103803: step 511, loss 0.110925, acc 0.984375
2018-03-14T17:44:53.903247: step 512, loss 0.153653, acc 0.984375
2018-03-14T17:44:54.124478: step 513, loss 0.0751559, acc 1
2018-03-14T17:44:54.911908: step 514, loss 0.116457, acc 0.984375
2018-03-14T17:44:55.704497: step 515, loss 0.132103, acc 1
2018-03-14T17:44:56.507258: step 516, loss 0.1635, acc 0.984375
2018-03-14T17:44:57.309517: step 517, loss 0.159804, acc 0.9375
2018-03-14T17:44:58.112410: step 518, loss 0.118781, acc 0.96875
2018-03-14T17:44:58.897571: step 519, loss 0.155187, acc 0.96875
2018-03-14T17:44:59.691294: step 520, loss 0.134829, acc 0.96875
2018-03-14T17:45:00.484752: step 521, loss 0.100261, acc 0.984375
2018-03-14T17:45:01.273320: step 522, loss 0.117618, acc 1
2018-03-14T17:45:02.066855: step 523, loss 0.128853, acc 1
2018-03-14T17:45:02.858823: step 524, loss 0.143677, acc 0.984375
2018-03-14T17:45:03.649191: step 525, loss 0.0968454, acc 1
2018-03-14T17:45:04.435887: step 526, loss 0.161766, acc 0.953125
2018-03-14T17:45:05.225593: step 527, loss 0.14606, acc 0.984375
2018-03-14T17:45:06.026292: step 528, loss 0.153679, acc 0.953125
2018-03-14T17:45:06.821391: step 529, loss 0.103826, acc 0.984375
2018-03-14T17:45:07.619003: step 530, loss 0.129876, acc 0.984375
2018-03-14T17:45:08.419255: step 531, loss 0.153713, acc 0.96875
2018-03-14T17:45:09.213022: step 532, loss 0.165873, acc 0.984375
2018-03-14T17:45:10.010779: step 533, loss 0.106686, acc 1
2018-03-14T17:45:10.814918: step 534, loss 0.119038, acc 0.984375
2018-03-14T17:45:11.612559: step 535, loss 0.121658, acc 1
2018-03-14T17:45:12.402540: step 536, loss 0.118914, acc 0.984375
2018-03-14T17:45:13.198783: step 537, loss 0.107463, acc 0.96875
2018-03-14T17:45:13.988730: step 538, loss 0.121449, acc 0.96875
2018-03-14T17:45:14.791083: step 539, loss 0.139725, acc 0.96875
2018-03-14T17:45:15.015028: step 540, loss 0.0503705, acc 1
2018-03-14T17:45:15.816072: step 541, loss 0.107602, acc 0.984375
2018-03-14T17:45:16.611216: step 542, loss 0.151747, acc 0.984375
2018-03-14T17:45:17.409310: step 543, loss 0.160415, acc 0.96875
2018-03-14T17:45:18.207979: step 544, loss 0.112099, acc 0.984375
2018-03-14T17:45:19.007551: step 545, loss 0.111376, acc 0.96875
2018-03-14T17:45:19.798152: step 546, loss 0.0804134, acc 1
2018-03-14T17:45:20.588469: step 547, loss 0.113254, acc 1
2018-03-14T17:45:21.389988: step 548, loss 0.135973, acc 0.953125
2018-03-14T17:45:22.185352: step 549, loss 0.0921261, acc 0.984375
2018-03-14T17:45:22.988292: step 550, loss 0.156615, acc 0.96875
2018-03-14T17:45:23.790441: step 551, loss 0.183012, acc 0.984375
2018-03-14T17:45:24.579115: step 552, loss 0.0867558, acc 1
2018-03-14T17:45:25.377655: step 553, loss 0.133874, acc 0.96875
2018-03-14T17:45:26.171593: step 554, loss 0.231325, acc 0.953125
2018-03-14T17:45:26.975409: step 555, loss 0.12537, acc 0.953125
2018-03-14T17:45:27.768447: step 556, loss 0.131322, acc 0.984375
2018-03-14T17:45:28.563695: step 557, loss 0.141263, acc 1
2018-03-14T17:45:29.359110: step 558, loss 0.108348, acc 1
2018-03-14T17:45:30.151313: step 559, loss 0.131724, acc 0.96875
2018-03-14T17:45:30.956615: step 560, loss 0.0806145, acc 1
2018-03-14T17:45:31.753000: step 561, loss 0.110505, acc 0.984375
2018-03-14T17:45:32.554772: step 562, loss 0.0766219, acc 1
2018-03-14T17:45:33.349724: step 563, loss 0.214682, acc 0.90625
2018-03-14T17:45:34.147052: step 564, loss 0.133908, acc 0.984375
2018-03-14T17:45:34.946968: step 565, loss 0.0880256, acc 0.984375
2018-03-14T17:45:35.752287: step 566, loss 0.0967177, acc 0.96875
2018-03-14T17:45:35.974158: step 567, loss 0.154664, acc 1
2018-03-14T17:45:36.762569: step 568, loss 0.122254, acc 0.984375
2018-03-14T17:45:37.568394: step 569, loss 0.129776, acc 0.953125
2018-03-14T17:45:38.358099: step 570, loss 0.090663, acc 1
2018-03-14T17:45:39.148473: step 571, loss 0.128122, acc 0.984375
2018-03-14T17:45:39.941921: step 572, loss 0.120774, acc 0.984375
2018-03-14T17:45:40.733926: step 573, loss 0.125475, acc 0.96875
2018-03-14T17:45:41.532203: step 574, loss 0.129329, acc 0.96875
2018-03-14T17:45:42.331736: step 575, loss 0.13553, acc 0.984375
2018-03-14T17:45:43.124827: step 576, loss 0.1087, acc 0.984375
2018-03-14T17:45:43.921404: step 577, loss 0.132567, acc 0.96875
2018-03-14T17:45:44.711898: step 578, loss 0.131126, acc 1
2018-03-14T17:45:45.506346: step 579, loss 0.17945, acc 0.953125
2018-03-14T17:45:46.298786: step 580, loss 0.10026, acc 1
2018-03-14T17:45:47.089129: step 581, loss 0.138565, acc 0.96875
2018-03-14T17:45:47.886111: step 582, loss 0.133772, acc 0.96875
2018-03-14T17:45:48.673605: step 583, loss 0.108239, acc 0.96875
2018-03-14T17:45:49.459667: step 584, loss 0.0931699, acc 1
2018-03-14T17:45:50.258864: step 585, loss 0.128922, acc 0.984375
2018-03-14T17:45:51.044217: step 586, loss 0.198645, acc 0.953125
2018-03-14T17:45:51.835707: step 587, loss 0.106716, acc 0.984375
2018-03-14T17:45:52.635728: step 588, loss 0.108839, acc 1
2018-03-14T17:45:53.428150: step 589, loss 0.110452, acc 0.984375
2018-03-14T17:45:54.226080: step 590, loss 0.0991435, acc 0.984375
2018-03-14T17:45:55.016469: step 591, loss 0.108361, acc 0.96875
2018-03-14T17:45:55.812890: step 592, loss 0.109623, acc 0.984375
2018-03-14T17:45:56.607365: step 593, loss 0.130764, acc 0.984375
2018-03-14T17:45:56.825475: step 594, loss 0.0718031, acc 1
2018-03-14T17:45:57.617858: step 595, loss 0.0977711, acc 0.984375
2018-03-14T17:45:58.405375: step 596, loss 0.0905593, acc 0.984375
2018-03-14T17:45:59.203320: step 597, loss 0.0926815, acc 1
2018-03-14T17:46:00.000578: step 598, loss 0.0501081, acc 1
2018-03-14T17:46:00.798015: step 599, loss 0.114782, acc 1
2018-03-14T17:46:01.607734: step 600, loss 0.125066, acc 0.953125

Evaluation:
2018-03-14T17:46:03.097542: step 600, loss 0.449152, acc 0.852029

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-600

2018-03-14T17:46:04.111028: step 601, loss 0.0690654, acc 1
2018-03-14T17:46:04.905198: step 602, loss 0.094194, acc 0.984375
2018-03-14T17:46:05.710095: step 603, loss 0.130629, acc 0.984375
2018-03-14T17:46:06.514023: step 604, loss 0.113313, acc 0.984375
2018-03-14T17:46:07.309890: step 605, loss 0.105581, acc 0.96875
2018-03-14T17:46:08.108394: step 606, loss 0.0906652, acc 0.984375
2018-03-14T17:46:08.906072: step 607, loss 0.139165, acc 0.984375
2018-03-14T17:46:09.695872: step 608, loss 0.133413, acc 0.96875
2018-03-14T17:46:10.490504: step 609, loss 0.113205, acc 1
2018-03-14T17:46:11.280762: step 610, loss 0.0995854, acc 1
2018-03-14T17:46:12.067145: step 611, loss 0.0699183, acc 1
2018-03-14T17:46:12.859656: step 612, loss 0.0883968, acc 0.984375
2018-03-14T17:46:13.655463: step 613, loss 0.0789103, acc 1
2018-03-14T17:46:14.443560: step 614, loss 0.0856876, acc 0.984375
2018-03-14T17:46:15.230608: step 615, loss 0.159485, acc 0.953125
2018-03-14T17:46:16.028909: step 616, loss 0.0755035, acc 0.984375
2018-03-14T17:46:16.825050: step 617, loss 0.104865, acc 1
2018-03-14T17:46:17.621072: step 618, loss 0.0686791, acc 0.984375
2018-03-14T17:46:18.419943: step 619, loss 0.0740003, acc 1
2018-03-14T17:46:19.220583: step 620, loss 0.0789478, acc 1
2018-03-14T17:46:19.440182: step 621, loss 0.0450988, acc 1
2018-03-14T17:46:20.239927: step 622, loss 0.0882057, acc 1
2018-03-14T17:46:21.024270: step 623, loss 0.101361, acc 1
2018-03-14T17:46:21.816041: step 624, loss 0.0964721, acc 0.984375
2018-03-14T17:46:22.620109: step 625, loss 0.0617114, acc 1
2018-03-14T17:46:23.419533: step 626, loss 0.0748569, acc 0.984375
2018-03-14T17:46:24.211129: step 627, loss 0.105846, acc 0.984375
2018-03-14T17:46:25.007731: step 628, loss 0.0742792, acc 1
2018-03-14T17:46:25.803473: step 629, loss 0.0538294, acc 1
2018-03-14T17:46:26.597016: step 630, loss 0.139492, acc 0.96875
2018-03-14T17:46:27.396220: step 631, loss 0.0814825, acc 0.984375
2018-03-14T17:46:28.199376: step 632, loss 0.0765627, acc 1
2018-03-14T17:46:28.994364: step 633, loss 0.0796215, acc 1
2018-03-14T17:46:29.793598: step 634, loss 0.110728, acc 0.984375
2018-03-14T17:46:30.590220: step 635, loss 0.0794151, acc 1
2018-03-14T17:46:31.378581: step 636, loss 0.0715059, acc 0.984375
2018-03-14T17:46:32.174662: step 637, loss 0.0844846, acc 0.96875
2018-03-14T17:46:32.977797: step 638, loss 0.0813552, acc 1
2018-03-14T17:46:33.774740: step 639, loss 0.123407, acc 0.96875
2018-03-14T17:46:34.569563: step 640, loss 0.0668995, acc 1
2018-03-14T17:46:35.370829: step 641, loss 0.0702819, acc 1
2018-03-14T17:46:36.167049: step 642, loss 0.118538, acc 0.96875
2018-03-14T17:46:36.967467: step 643, loss 0.0876126, acc 1
2018-03-14T17:46:37.770119: step 644, loss 0.0860766, acc 1
2018-03-14T17:46:38.557835: step 645, loss 0.063459, acc 1
2018-03-14T17:46:39.345121: step 646, loss 0.120491, acc 0.96875
2018-03-14T17:46:40.142211: step 647, loss 0.0670363, acc 1
2018-03-14T17:46:40.362213: step 648, loss 0.126362, acc 1
2018-03-14T17:46:41.159903: step 649, loss 0.0806143, acc 1
2018-03-14T17:46:41.959811: step 650, loss 0.0714774, acc 1
2018-03-14T17:46:42.759437: step 651, loss 0.0960244, acc 0.96875
2018-03-14T17:46:43.559319: step 652, loss 0.0866768, acc 0.984375
2018-03-14T17:46:44.348507: step 653, loss 0.0648271, acc 1
2018-03-14T17:46:45.145780: step 654, loss 0.0735572, acc 1
2018-03-14T17:46:45.951730: step 655, loss 0.0841592, acc 1
2018-03-14T17:46:46.760605: step 656, loss 0.108399, acc 0.984375
2018-03-14T17:46:47.545398: step 657, loss 0.0660549, acc 1
2018-03-14T17:46:48.342455: step 658, loss 0.0819366, acc 0.984375
2018-03-14T17:46:49.141226: step 659, loss 0.0967119, acc 0.984375
2018-03-14T17:46:49.937572: step 660, loss 0.0640148, acc 1
2018-03-14T17:46:50.738466: step 661, loss 0.0828878, acc 0.984375
2018-03-14T17:46:51.532041: step 662, loss 0.114218, acc 0.984375
2018-03-14T17:46:52.323173: step 663, loss 0.0756368, acc 0.984375
2018-03-14T17:46:53.119768: step 664, loss 0.0656194, acc 1
2018-03-14T17:46:53.911351: step 665, loss 0.0917809, acc 0.984375
2018-03-14T17:46:54.741328: step 666, loss 0.104459, acc 0.984375
2018-03-14T17:46:55.570253: step 667, loss 0.111548, acc 0.984375
2018-03-14T17:46:56.378681: step 668, loss 0.0786116, acc 0.984375
2018-03-14T17:46:57.168952: step 669, loss 0.0743479, acc 1
2018-03-14T17:46:57.962662: step 670, loss 0.0459388, acc 1
2018-03-14T17:46:58.759801: step 671, loss 0.0822427, acc 1
2018-03-14T17:46:59.550042: step 672, loss 0.0776, acc 1
2018-03-14T17:47:00.345921: step 673, loss 0.142382, acc 0.96875
2018-03-14T17:47:01.149475: step 674, loss 0.0991156, acc 0.984375
2018-03-14T17:47:01.366923: step 675, loss 0.0222293, acc 1
2018-03-14T17:47:02.163673: step 676, loss 0.0957254, acc 0.984375
2018-03-14T17:47:02.955508: step 677, loss 0.0532674, acc 1
2018-03-14T17:47:03.746875: step 678, loss 0.0759984, acc 0.984375
2018-03-14T17:47:04.541196: step 679, loss 0.0592615, acc 0.984375
2018-03-14T17:47:05.344884: step 680, loss 0.103555, acc 1
2018-03-14T17:47:06.142761: step 681, loss 0.0721452, acc 0.984375
2018-03-14T17:47:06.939691: step 682, loss 0.0568168, acc 1
2018-03-14T17:47:07.737359: step 683, loss 0.073325, acc 1
2018-03-14T17:47:08.522306: step 684, loss 0.071939, acc 1
2018-03-14T17:47:09.315168: step 685, loss 0.0691419, acc 0.984375
2018-03-14T17:47:10.109215: step 686, loss 0.0847148, acc 1
2018-03-14T17:47:10.920101: step 687, loss 0.122147, acc 0.96875
2018-03-14T17:47:11.716150: step 688, loss 0.105176, acc 0.984375
2018-03-14T17:47:12.509396: step 689, loss 0.0536424, acc 0.984375
2018-03-14T17:47:13.303188: step 690, loss 0.0725044, acc 1
2018-03-14T17:47:14.094258: step 691, loss 0.058553, acc 1
2018-03-14T17:47:14.889710: step 692, loss 0.0667899, acc 1
2018-03-14T17:47:15.690068: step 693, loss 0.0563072, acc 1
2018-03-14T17:47:16.488821: step 694, loss 0.134196, acc 0.96875
2018-03-14T17:47:17.275322: step 695, loss 0.0593952, acc 1
2018-03-14T17:47:18.064130: step 696, loss 0.0845756, acc 1
2018-03-14T17:47:18.863673: step 697, loss 0.052156, acc 1
2018-03-14T17:47:19.654229: step 698, loss 0.0844963, acc 0.984375
2018-03-14T17:47:20.448827: step 699, loss 0.0932238, acc 0.984375
2018-03-14T17:47:21.244573: step 700, loss 0.0484492, acc 1

Evaluation:
2018-03-14T17:47:22.709534: step 700, loss 0.444047, acc 0.847255

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-700

2018-03-14T17:47:23.615019: step 701, loss 0.0857967, acc 1
2018-03-14T17:47:23.833165: step 702, loss 0.0490262, acc 1
2018-03-14T17:47:24.628469: step 703, loss 0.0486405, acc 1
2018-03-14T17:47:25.426687: step 704, loss 0.0741039, acc 1
2018-03-14T17:47:26.226408: step 705, loss 0.0917394, acc 0.984375
2018-03-14T17:47:27.025562: step 706, loss 0.151834, acc 0.953125
2018-03-14T17:47:27.821328: step 707, loss 0.0588607, acc 1
2018-03-14T17:47:28.620394: step 708, loss 0.060763, acc 0.984375
2018-03-14T17:47:29.419952: step 709, loss 0.0856649, acc 0.984375
2018-03-14T17:47:30.205894: step 710, loss 0.0489955, acc 1
2018-03-14T17:47:31.004821: step 711, loss 0.0738113, acc 1
2018-03-14T17:47:31.812439: step 712, loss 0.0934259, acc 0.96875
2018-03-14T17:47:32.598763: step 713, loss 0.0505275, acc 1
2018-03-14T17:47:33.393600: step 714, loss 0.0556517, acc 1
2018-03-14T17:47:34.201558: step 715, loss 0.0735486, acc 0.984375
2018-03-14T17:47:34.992718: step 716, loss 0.0436676, acc 1
2018-03-14T17:47:35.792779: step 717, loss 0.0593744, acc 1
2018-03-14T17:47:36.592213: step 718, loss 0.0534316, acc 1
2018-03-14T17:47:37.381251: step 719, loss 0.124785, acc 0.953125
2018-03-14T17:47:38.186445: step 720, loss 0.0606338, acc 0.984375
2018-03-14T17:47:38.979757: step 721, loss 0.0731018, acc 0.96875
2018-03-14T17:47:39.766577: step 722, loss 0.0483022, acc 1
2018-03-14T17:47:40.562571: step 723, loss 0.0927947, acc 0.96875
2018-03-14T17:47:41.369874: step 724, loss 0.0688298, acc 0.984375
2018-03-14T17:47:42.160509: step 725, loss 0.0828574, acc 0.984375
2018-03-14T17:47:42.948840: step 726, loss 0.0357164, acc 1
2018-03-14T17:47:43.748547: step 727, loss 0.0481063, acc 1
2018-03-14T17:47:44.540524: step 728, loss 0.136342, acc 0.953125
2018-03-14T17:47:44.759923: step 729, loss 0.0390244, acc 1
2018-03-14T17:47:45.557872: step 730, loss 0.0828927, acc 0.984375
2018-03-14T17:47:46.356534: step 731, loss 0.0435181, acc 1
2018-03-14T17:47:47.159785: step 732, loss 0.0548634, acc 1
2018-03-14T17:47:47.957149: step 733, loss 0.0981235, acc 0.984375
2018-03-14T17:47:48.745482: step 734, loss 0.0864372, acc 1
2018-03-14T17:47:49.534757: step 735, loss 0.080625, acc 0.984375
2018-03-14T17:47:50.336609: step 736, loss 0.0549031, acc 1
2018-03-14T17:47:51.133051: step 737, loss 0.0727452, acc 0.984375
2018-03-14T17:47:51.918085: step 738, loss 0.0920991, acc 0.984375
2018-03-14T17:47:52.713261: step 739, loss 0.0512173, acc 1
2018-03-14T17:47:53.504736: step 740, loss 0.0693357, acc 1
2018-03-14T17:47:54.299613: step 741, loss 0.0613984, acc 0.984375
2018-03-14T17:47:55.097816: step 742, loss 0.0920574, acc 1
2018-03-14T17:47:55.894155: step 743, loss 0.056653, acc 1
2018-03-14T17:47:56.682477: step 744, loss 0.0742349, acc 1
2018-03-14T17:47:57.472432: step 745, loss 0.0617624, acc 1
2018-03-14T17:47:58.267135: step 746, loss 0.0720004, acc 0.984375
2018-03-14T17:47:59.066805: step 747, loss 0.0646073, acc 1
2018-03-14T17:47:59.866441: step 748, loss 0.0772159, acc 0.984375
2018-03-14T17:48:00.657526: step 749, loss 0.0547788, acc 1
2018-03-14T17:48:01.443336: step 750, loss 0.0934767, acc 1
2018-03-14T17:48:02.235602: step 751, loss 0.0781964, acc 0.984375
2018-03-14T17:48:03.020928: step 752, loss 0.0631201, acc 1
2018-03-14T17:48:03.807151: step 753, loss 0.049829, acc 1
2018-03-14T17:48:04.596495: step 754, loss 0.0622955, acc 1
2018-03-14T17:48:05.391877: step 755, loss 0.0653844, acc 1
2018-03-14T17:48:05.613687: step 756, loss 0.0244371, acc 1
2018-03-14T17:48:06.408084: step 757, loss 0.0620761, acc 0.984375
2018-03-14T17:48:07.206332: step 758, loss 0.0556593, acc 1
2018-03-14T17:48:07.991089: step 759, loss 0.0583042, acc 0.984375
2018-03-14T17:48:08.784011: step 760, loss 0.0882948, acc 0.984375
2018-03-14T17:48:09.578670: step 761, loss 0.0762632, acc 0.984375
2018-03-14T17:48:10.367388: step 762, loss 0.046521, acc 1
2018-03-14T17:48:11.157843: step 763, loss 0.0698229, acc 0.984375
2018-03-14T17:48:11.963681: step 764, loss 0.0572945, acc 1
2018-03-14T17:48:12.764846: step 765, loss 0.0560993, acc 1
2018-03-14T17:48:13.553610: step 766, loss 0.0580005, acc 1
2018-03-14T17:48:14.348012: step 767, loss 0.0802914, acc 0.984375
2018-03-14T17:48:15.134996: step 768, loss 0.0993465, acc 0.984375
2018-03-14T17:48:15.934235: step 769, loss 0.0528914, acc 0.984375
2018-03-14T17:48:16.728984: step 770, loss 0.0423659, acc 1
2018-03-14T17:48:17.530573: step 771, loss 0.0481504, acc 1
2018-03-14T17:48:18.325518: step 772, loss 0.0666023, acc 1
2018-03-14T17:48:19.127710: step 773, loss 0.0706372, acc 1
2018-03-14T17:48:19.922556: step 774, loss 0.0492304, acc 1
2018-03-14T17:48:20.717331: step 775, loss 0.095343, acc 0.984375
2018-03-14T17:48:21.510521: step 776, loss 0.0814047, acc 0.984375
2018-03-14T17:48:22.305941: step 777, loss 0.0927161, acc 1
2018-03-14T17:48:23.098662: step 778, loss 0.0665933, acc 1
2018-03-14T17:48:23.895623: step 779, loss 0.0530467, acc 1
2018-03-14T17:48:24.689211: step 780, loss 0.0361845, acc 1
2018-03-14T17:48:25.484672: step 781, loss 0.0664695, acc 1
2018-03-14T17:48:26.281828: step 782, loss 0.0686097, acc 0.984375
2018-03-14T17:48:26.502042: step 783, loss 0.0832618, acc 1
2018-03-14T17:48:27.300123: step 784, loss 0.046161, acc 1
2018-03-14T17:48:28.096486: step 785, loss 0.0499134, acc 1
2018-03-14T17:48:28.881267: step 786, loss 0.0663847, acc 1
2018-03-14T17:48:29.668744: step 787, loss 0.0839967, acc 0.96875
2018-03-14T17:48:30.458706: step 788, loss 0.063418, acc 0.984375
2018-03-14T17:48:31.256345: step 789, loss 0.0793757, acc 1
2018-03-14T17:48:32.049369: step 790, loss 0.0561873, acc 1
2018-03-14T17:48:32.839365: step 791, loss 0.0581706, acc 1
2018-03-14T17:48:33.642761: step 792, loss 0.0575719, acc 1
2018-03-14T17:48:34.434798: step 793, loss 0.0715307, acc 0.984375
2018-03-14T17:48:35.233000: step 794, loss 0.0672935, acc 0.96875
2018-03-14T17:48:36.028790: step 795, loss 0.0313276, acc 1
2018-03-14T17:48:36.826099: step 796, loss 0.0620823, acc 1
2018-03-14T17:48:37.620896: step 797, loss 0.0563371, acc 1
2018-03-14T17:48:38.415605: step 798, loss 0.0381989, acc 1
2018-03-14T17:48:39.204575: step 799, loss 0.0626339, acc 1
2018-03-14T17:48:39.997425: step 800, loss 0.0672196, acc 1

Evaluation:
2018-03-14T17:48:43.997619: step 800, loss 0.408755, acc 0.859189

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-800

2018-03-14T17:48:44.904260: step 801, loss 0.0650561, acc 1
2018-03-14T17:48:45.700182: step 802, loss 0.0571024, acc 1
2018-03-14T17:48:46.495477: step 803, loss 0.0577394, acc 0.984375
2018-03-14T17:48:47.288180: step 804, loss 0.0671256, acc 0.984375
2018-03-14T17:48:48.090609: step 805, loss 0.050761, acc 1
2018-03-14T17:48:48.887188: step 806, loss 0.0585454, acc 1
2018-03-14T17:48:49.675807: step 807, loss 0.0472159, acc 1
2018-03-14T17:48:50.464339: step 808, loss 0.036002, acc 1
2018-03-14T17:48:51.259183: step 809, loss 0.0449189, acc 1
2018-03-14T17:48:51.478646: step 810, loss 0.0346822, acc 1
2018-03-14T17:48:52.274713: step 811, loss 0.0528321, acc 1
2018-03-14T17:48:53.064066: step 812, loss 0.0313418, acc 1
2018-03-14T17:48:53.855538: step 813, loss 0.0293687, acc 1
2018-03-14T17:48:54.646678: step 814, loss 0.0479686, acc 1
2018-03-14T17:48:55.429400: step 815, loss 0.0578034, acc 0.96875
2018-03-14T17:48:56.226750: step 816, loss 0.0560151, acc 0.984375
2018-03-14T17:48:57.031999: step 817, loss 0.0579092, acc 1
2018-03-14T17:48:57.817787: step 818, loss 0.0307177, acc 1
2018-03-14T17:48:58.603386: step 819, loss 0.0846796, acc 0.96875
2018-03-14T17:48:59.404358: step 820, loss 0.0304452, acc 1
2018-03-14T17:49:00.194835: step 821, loss 0.0324313, acc 0.984375
2018-03-14T17:49:00.992936: step 822, loss 0.0541827, acc 0.984375
2018-03-14T17:49:01.794690: step 823, loss 0.0570516, acc 0.984375
2018-03-14T17:49:02.582798: step 824, loss 0.0579699, acc 0.984375
2018-03-14T17:49:03.371980: step 825, loss 0.04695, acc 1
2018-03-14T17:49:04.173865: step 826, loss 0.0763382, acc 1
2018-03-14T17:49:04.966615: step 827, loss 0.0674456, acc 1
2018-03-14T17:49:05.766005: step 828, loss 0.0434468, acc 1
2018-03-14T17:49:06.555841: step 829, loss 0.0441482, acc 1
2018-03-14T17:49:07.349038: step 830, loss 0.0309327, acc 1
2018-03-14T17:49:08.140261: step 831, loss 0.0566526, acc 0.984375
2018-03-14T17:49:08.938815: step 832, loss 0.0647517, acc 0.984375
2018-03-14T17:49:09.723860: step 833, loss 0.0608207, acc 1
2018-03-14T17:49:10.511731: step 834, loss 0.0823301, acc 0.984375
2018-03-14T17:49:11.304437: step 835, loss 0.0301311, acc 1
2018-03-14T17:49:12.102605: step 836, loss 0.0618274, acc 0.984375
2018-03-14T17:49:12.323292: step 837, loss 0.0620867, acc 1
2018-03-14T17:49:13.119624: step 838, loss 0.0510492, acc 1
2018-03-14T17:49:13.922282: step 839, loss 0.082362, acc 0.984375
2018-03-14T17:49:14.712645: step 840, loss 0.0541868, acc 1
2018-03-14T17:49:15.502819: step 841, loss 0.0457014, acc 1
2018-03-14T17:49:16.297094: step 842, loss 0.0462536, acc 1
2018-03-14T17:49:17.091059: step 843, loss 0.0488812, acc 0.984375
2018-03-14T17:49:17.893351: step 844, loss 0.076333, acc 0.984375
2018-03-14T17:49:18.691337: step 845, loss 0.0641177, acc 0.984375
2018-03-14T17:49:19.481297: step 846, loss 0.0426045, acc 1
2018-03-14T17:49:20.284149: step 847, loss 0.101539, acc 0.96875
2018-03-14T17:49:21.078811: step 848, loss 0.0503297, acc 1
2018-03-14T17:49:21.866065: step 849, loss 0.0312655, acc 1
2018-03-14T17:49:22.661168: step 850, loss 0.0815174, acc 0.984375
2018-03-14T17:49:23.455988: step 851, loss 0.0285129, acc 1
2018-03-14T17:49:24.247422: step 852, loss 0.0444262, acc 1
2018-03-14T17:49:25.043423: step 853, loss 0.0701516, acc 0.984375
2018-03-14T17:49:25.831942: step 854, loss 0.0520404, acc 1
2018-03-14T17:49:26.627089: step 855, loss 0.0440867, acc 1
2018-03-14T17:49:27.416017: step 856, loss 0.0639352, acc 1
2018-03-14T17:49:28.203388: step 857, loss 0.0847491, acc 0.96875
2018-03-14T17:49:29.002608: step 858, loss 0.0460306, acc 1
2018-03-14T17:49:29.803768: step 859, loss 0.0383514, acc 1
2018-03-14T17:49:30.604512: step 860, loss 0.0552198, acc 1
2018-03-14T17:49:31.395955: step 861, loss 0.0471802, acc 1
2018-03-14T17:49:32.196046: step 862, loss 0.043989, acc 1
2018-03-14T17:49:32.992720: step 863, loss 0.0721149, acc 0.984375
2018-03-14T17:49:33.209914: step 864, loss 0.0988356, acc 1
2018-03-14T17:49:34.011145: step 865, loss 0.0495215, acc 1
2018-03-14T17:49:34.812090: step 866, loss 0.0355054, acc 1
2018-03-14T17:49:35.612335: step 867, loss 0.0300612, acc 1
2018-03-14T17:49:36.413661: step 868, loss 0.0622291, acc 1
2018-03-14T17:49:37.214836: step 869, loss 0.0371111, acc 1
2018-03-14T17:49:38.018059: step 870, loss 0.0479107, acc 1
2018-03-14T17:49:38.810906: step 871, loss 0.0472359, acc 1
2018-03-14T17:49:39.602815: step 872, loss 0.0322889, acc 1
2018-03-14T17:49:40.393575: step 873, loss 0.0364858, acc 1
2018-03-14T17:49:41.187938: step 874, loss 0.0447494, acc 1
2018-03-14T17:49:41.986676: step 875, loss 0.0639427, acc 0.984375
2018-03-14T17:49:42.780327: step 876, loss 0.0490515, acc 1
2018-03-14T17:49:43.575337: step 877, loss 0.0402105, acc 1
2018-03-14T17:49:44.371623: step 878, loss 0.0751506, acc 0.984375
2018-03-14T17:49:45.159126: step 879, loss 0.0572819, acc 1
2018-03-14T17:49:45.960996: step 880, loss 0.0429029, acc 1
2018-03-14T17:49:46.763447: step 881, loss 0.0338195, acc 1
2018-03-14T17:49:47.556226: step 882, loss 0.0330196, acc 1
2018-03-14T17:49:48.351986: step 883, loss 0.0436333, acc 0.984375
2018-03-14T17:49:49.147824: step 884, loss 0.0420672, acc 1
2018-03-14T17:49:49.945953: step 885, loss 0.0798787, acc 1
2018-03-14T17:49:50.740746: step 886, loss 0.0363154, acc 1
2018-03-14T17:49:51.531415: step 887, loss 0.0282021, acc 1
2018-03-14T17:49:52.322212: step 888, loss 0.0426546, acc 1
2018-03-14T17:49:53.123670: step 889, loss 0.0380987, acc 1
2018-03-14T17:49:53.926394: step 890, loss 0.0775911, acc 0.984375
2018-03-14T17:49:54.145816: step 891, loss 0.0100195, acc 1
2018-03-14T17:49:54.943749: step 892, loss 0.0508284, acc 1
2018-03-14T17:49:55.740885: step 893, loss 0.0374348, acc 1
2018-03-14T17:49:56.546386: step 894, loss 0.053532, acc 1
2018-03-14T17:49:57.346871: step 895, loss 0.0375246, acc 1
2018-03-14T17:49:58.146159: step 896, loss 0.0410759, acc 1
2018-03-14T17:49:58.945403: step 897, loss 0.0446111, acc 1
2018-03-14T17:49:59.744476: step 898, loss 0.0467602, acc 1
2018-03-14T17:50:00.546404: step 899, loss 0.0608909, acc 1
2018-03-14T17:50:01.341642: step 900, loss 0.042957, acc 1

Evaluation:
2018-03-14T17:50:03.106805: step 900, loss 0.416961, acc 0.859189

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-900

2018-03-14T17:50:03.984458: step 901, loss 0.0468859, acc 1
2018-03-14T17:50:04.785794: step 902, loss 0.0514661, acc 1
2018-03-14T17:50:05.577275: step 903, loss 0.0793965, acc 0.96875
2018-03-14T17:50:06.380961: step 904, loss 0.0475333, acc 1
2018-03-14T17:50:07.167818: step 905, loss 0.0678571, acc 1
2018-03-14T17:50:07.965754: step 906, loss 0.0409942, acc 0.984375
2018-03-14T17:50:08.774481: step 907, loss 0.0392086, acc 1
2018-03-14T17:50:09.567889: step 908, loss 0.0518625, acc 0.984375
2018-03-14T17:50:10.366540: step 909, loss 0.052525, acc 1
2018-03-14T17:50:11.166667: step 910, loss 0.0572318, acc 1
2018-03-14T17:50:11.963119: step 911, loss 0.0311122, acc 1
2018-03-14T17:50:12.757770: step 912, loss 0.0626659, acc 0.984375
2018-03-14T17:50:13.551158: step 913, loss 0.0663395, acc 0.984375
2018-03-14T17:50:14.346119: step 914, loss 0.0358635, acc 1
2018-03-14T17:50:15.137088: step 915, loss 0.0954455, acc 0.96875
2018-03-14T17:50:15.929451: step 916, loss 0.0492928, acc 1
2018-03-14T17:50:16.723981: step 917, loss 0.0800546, acc 0.984375
2018-03-14T17:50:16.942318: step 918, loss 0.0432717, acc 1
2018-03-14T17:50:17.734424: step 919, loss 0.0624756, acc 0.984375
2018-03-14T17:50:18.532465: step 920, loss 0.0575123, acc 1
2018-03-14T17:50:19.331998: step 921, loss 0.0410597, acc 1
2018-03-14T17:50:20.130916: step 922, loss 0.0402746, acc 1
2018-03-14T17:50:20.930120: step 923, loss 0.0455199, acc 0.984375
2018-03-14T17:50:21.721569: step 924, loss 0.0355637, acc 1
2018-03-14T17:50:22.516531: step 925, loss 0.0278552, acc 1
2018-03-14T17:50:23.307856: step 926, loss 0.0423014, acc 1
2018-03-14T17:50:24.103250: step 927, loss 0.0427114, acc 1
2018-03-14T17:50:24.897724: step 928, loss 0.0491575, acc 1
2018-03-14T17:50:25.691706: step 929, loss 0.0471134, acc 1
2018-03-14T17:50:26.486917: step 930, loss 0.0554415, acc 1
2018-03-14T17:50:27.283919: step 931, loss 0.0661534, acc 0.984375
2018-03-14T17:50:28.090911: step 932, loss 0.0490574, acc 1
2018-03-14T17:50:28.882371: step 933, loss 0.0593691, acc 0.984375
2018-03-14T17:50:29.687712: step 934, loss 0.039837, acc 1
2018-03-14T17:50:30.482556: step 935, loss 0.0318683, acc 1
2018-03-14T17:50:31.269799: step 936, loss 0.0268263, acc 1
2018-03-14T17:50:32.064470: step 937, loss 0.0434119, acc 1
2018-03-14T17:50:32.855762: step 938, loss 0.0490064, acc 1
2018-03-14T17:50:33.648877: step 939, loss 0.0482014, acc 1
2018-03-14T17:50:34.442882: step 940, loss 0.0341597, acc 1
2018-03-14T17:50:35.234004: step 941, loss 0.0306403, acc 1
2018-03-14T17:50:36.032782: step 942, loss 0.0407532, acc 1
2018-03-14T17:50:36.828405: step 943, loss 0.030414, acc 1
2018-03-14T17:50:37.618066: step 944, loss 0.0311708, acc 1
2018-03-14T17:50:37.842735: step 945, loss 0.030352, acc 1
2018-03-14T17:50:38.633271: step 946, loss 0.0430428, acc 1
2018-03-14T17:50:39.429619: step 947, loss 0.0247748, acc 1
2018-03-14T17:50:40.223247: step 948, loss 0.0191401, acc 1
2018-03-14T17:50:41.012474: step 949, loss 0.0474827, acc 1
2018-03-14T17:50:41.810943: step 950, loss 0.0185905, acc 1
2018-03-14T17:50:42.611419: step 951, loss 0.0150711, acc 1
2018-03-14T17:50:43.402930: step 952, loss 0.0294223, acc 1
2018-03-14T17:50:44.199429: step 953, loss 0.0455992, acc 1
2018-03-14T17:50:44.990336: step 954, loss 0.0361402, acc 1
2018-03-14T17:50:45.784733: step 955, loss 0.0279438, acc 1
2018-03-14T17:50:46.586408: step 956, loss 0.0481306, acc 0.984375
2018-03-14T17:50:47.390491: step 957, loss 0.0213738, acc 1
2018-03-14T17:50:48.180883: step 958, loss 0.0292296, acc 1
2018-03-14T17:50:48.983385: step 959, loss 0.0596779, acc 0.984375
2018-03-14T17:50:49.781303: step 960, loss 0.038313, acc 1
2018-03-14T17:50:50.582040: step 961, loss 0.0323969, acc 1
2018-03-14T17:50:51.378930: step 962, loss 0.0283894, acc 1
2018-03-14T17:50:52.174968: step 963, loss 0.0391977, acc 1
2018-03-14T17:50:52.971342: step 964, loss 0.0456903, acc 0.984375
2018-03-14T17:50:53.766105: step 965, loss 0.0282829, acc 1
2018-03-14T17:50:54.569980: step 966, loss 0.0749958, acc 0.984375
2018-03-14T17:50:55.353663: step 967, loss 0.0501743, acc 0.984375
2018-03-14T17:50:56.141445: step 968, loss 0.0466942, acc 1
2018-03-14T17:50:56.938782: step 969, loss 0.0394461, acc 1
2018-03-14T17:50:57.738451: step 970, loss 0.0257684, acc 1
2018-03-14T17:50:58.535202: step 971, loss 0.0613433, acc 0.984375
2018-03-14T17:50:58.759896: step 972, loss 0.0212573, acc 1
2018-03-14T17:50:59.553220: step 973, loss 0.0338502, acc 1
2018-03-14T17:51:00.347423: step 974, loss 0.0225551, acc 1
2018-03-14T17:51:01.149484: step 975, loss 0.0474103, acc 0.984375
2018-03-14T17:51:01.939166: step 976, loss 0.0411012, acc 1
2018-03-14T17:51:02.729291: step 977, loss 0.0241622, acc 1
2018-03-14T17:51:03.530576: step 978, loss 0.0383302, acc 1
2018-03-14T17:51:04.323808: step 979, loss 0.0280806, acc 1
2018-03-14T17:51:05.116409: step 980, loss 0.050214, acc 0.984375
2018-03-14T17:51:05.916295: step 981, loss 0.0210111, acc 1
2018-03-14T17:51:06.713390: step 982, loss 0.041867, acc 1
2018-03-14T17:51:07.505423: step 983, loss 0.0553334, acc 1
2018-03-14T17:51:08.305350: step 984, loss 0.0617081, acc 0.984375
2018-03-14T17:51:09.105325: step 985, loss 0.0477502, acc 0.984375
2018-03-14T17:51:09.907641: step 986, loss 0.0378735, acc 1
2018-03-14T17:51:10.702310: step 987, loss 0.0497916, acc 0.984375
2018-03-14T17:51:11.496146: step 988, loss 0.0310375, acc 1
2018-03-14T17:51:12.287777: step 989, loss 0.046939, acc 1
2018-03-14T17:51:13.085799: step 990, loss 0.0371051, acc 1
2018-03-14T17:51:13.878291: step 991, loss 0.0304001, acc 1
2018-03-14T17:51:14.674659: step 992, loss 0.0243617, acc 1
2018-03-14T17:51:15.464284: step 993, loss 0.0431224, acc 1
2018-03-14T17:51:16.262078: step 994, loss 0.0361391, acc 1
2018-03-14T17:51:17.050244: step 995, loss 0.0276506, acc 1
2018-03-14T17:51:17.857921: step 996, loss 0.0315879, acc 1
2018-03-14T17:51:18.647243: step 997, loss 0.0306079, acc 1
2018-03-14T17:51:19.444858: step 998, loss 0.0350848, acc 1
2018-03-14T17:51:19.664872: step 999, loss 0.0319174, acc 1
2018-03-14T17:51:20.460058: step 1000, loss 0.0410787, acc 1

Evaluation:
2018-03-14T17:51:21.945537: step 1000, loss 0.401799, acc 0.861575

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-1000

2018-03-14T17:51:22.826690: step 1001, loss 0.0444736, acc 1
2018-03-14T17:51:23.620292: step 1002, loss 0.0278617, acc 1
2018-03-14T17:51:24.411880: step 1003, loss 0.0332942, acc 1
2018-03-14T17:51:25.207672: step 1004, loss 0.0634303, acc 0.96875
2018-03-14T17:51:26.011263: step 1005, loss 0.036877, acc 1
2018-03-14T17:51:26.808784: step 1006, loss 0.0667932, acc 0.984375
2018-03-14T17:51:27.600801: step 1007, loss 0.0383998, acc 0.984375
2018-03-14T17:51:28.400047: step 1008, loss 0.025406, acc 1
2018-03-14T17:51:29.198978: step 1009, loss 0.0444305, acc 0.984375
2018-03-14T17:51:29.998547: step 1010, loss 0.023021, acc 1
2018-03-14T17:51:30.792316: step 1011, loss 0.0499891, acc 1
2018-03-14T17:51:31.595765: step 1012, loss 0.0458843, acc 1
2018-03-14T17:51:32.397678: step 1013, loss 0.0256277, acc 1
2018-03-14T17:51:33.190216: step 1014, loss 0.0336003, acc 1
2018-03-14T17:51:33.998208: step 1015, loss 0.0374808, acc 1
2018-03-14T17:51:34.796257: step 1016, loss 0.0290064, acc 1
2018-03-14T17:51:35.592431: step 1017, loss 0.0341397, acc 1
2018-03-14T17:51:36.393569: step 1018, loss 0.0376638, acc 1
2018-03-14T17:51:37.192138: step 1019, loss 0.0614573, acc 0.96875
2018-03-14T17:51:37.993867: step 1020, loss 0.0342357, acc 1
2018-03-14T17:51:38.788375: step 1021, loss 0.0283199, acc 1
2018-03-14T17:51:39.597234: step 1022, loss 0.047674, acc 1
2018-03-14T17:51:40.386061: step 1023, loss 0.030859, acc 1
2018-03-14T17:51:41.180537: step 1024, loss 0.0269101, acc 1
2018-03-14T17:51:41.977377: step 1025, loss 0.0725585, acc 1
2018-03-14T17:51:42.195405: step 1026, loss 0.0421655, acc 1
2018-03-14T17:51:42.991519: step 1027, loss 0.0285899, acc 1
2018-03-14T17:51:43.788021: step 1028, loss 0.0453131, acc 1
2018-03-14T17:51:44.580407: step 1029, loss 0.0450077, acc 1
2018-03-14T17:51:45.374401: step 1030, loss 0.0248449, acc 1
2018-03-14T17:51:46.170190: step 1031, loss 0.0362255, acc 1
2018-03-14T17:51:46.968039: step 1032, loss 0.0359103, acc 0.984375
2018-03-14T17:51:47.764984: step 1033, loss 0.0374067, acc 0.984375
2018-03-14T17:51:48.565315: step 1034, loss 0.0479985, acc 1
2018-03-14T17:51:49.360117: step 1035, loss 0.0411227, acc 1
2018-03-14T17:51:50.158316: step 1036, loss 0.0339664, acc 1
2018-03-14T17:51:50.960898: step 1037, loss 0.034544, acc 1
2018-03-14T17:51:51.748452: step 1038, loss 0.0241869, acc 1
2018-03-14T17:51:52.542809: step 1039, loss 0.0338644, acc 1
2018-03-14T17:51:53.348059: step 1040, loss 0.0343561, acc 1
2018-03-14T17:51:54.135915: step 1041, loss 0.0600293, acc 0.984375
2018-03-14T17:51:54.937857: step 1042, loss 0.0192097, acc 1
2018-03-14T17:51:55.748400: step 1043, loss 0.0369543, acc 1
2018-03-14T17:51:56.580160: step 1044, loss 0.0294112, acc 1
2018-03-14T17:51:57.401017: step 1045, loss 0.0246241, acc 1
2018-03-14T17:51:58.216059: step 1046, loss 0.0284846, acc 1
2018-03-14T17:51:59.013584: step 1047, loss 0.0224005, acc 1
2018-03-14T17:51:59.809637: step 1048, loss 0.0359668, acc 1
2018-03-14T17:52:00.607564: step 1049, loss 0.0315336, acc 1
2018-03-14T17:52:01.400291: step 1050, loss 0.0298913, acc 1
2018-03-14T17:52:02.191899: step 1051, loss 0.0397821, acc 1
2018-03-14T17:52:02.988494: step 1052, loss 0.0253824, acc 1
2018-03-14T17:52:03.204024: step 1053, loss 0.013902, acc 1
2018-03-14T17:52:04.003967: step 1054, loss 0.0230915, acc 1
2018-03-14T17:52:04.804006: step 1055, loss 0.0316594, acc 1
2018-03-14T17:52:05.592598: step 1056, loss 0.0506081, acc 0.984375
2018-03-14T17:52:06.396587: step 1057, loss 0.0296503, acc 1
2018-03-14T17:52:07.198901: step 1058, loss 0.0429088, acc 0.984375
2018-03-14T17:52:07.991333: step 1059, loss 0.0278337, acc 1
2018-03-14T17:52:08.788074: step 1060, loss 0.0422163, acc 1
2018-03-14T17:52:09.596493: step 1061, loss 0.0131683, acc 1
2018-03-14T17:52:10.390680: step 1062, loss 0.0323016, acc 1
2018-03-14T17:52:11.188019: step 1063, loss 0.0338389, acc 1
2018-03-14T17:52:11.990518: step 1064, loss 0.0337985, acc 1
2018-03-14T17:52:12.783986: step 1065, loss 0.0260708, acc 1
2018-03-14T17:52:13.580108: step 1066, loss 0.0240804, acc 1
2018-03-14T17:52:14.380564: step 1067, loss 0.0428429, acc 1
2018-03-14T17:52:15.180313: step 1068, loss 0.0266315, acc 1
2018-03-14T17:52:15.978018: step 1069, loss 0.0807259, acc 0.96875
2018-03-14T17:52:16.774344: step 1070, loss 0.0382868, acc 1
2018-03-14T17:52:17.569139: step 1071, loss 0.0356987, acc 1
2018-03-14T17:52:18.366644: step 1072, loss 0.0291959, acc 1
2018-03-14T17:52:19.163235: step 1073, loss 0.0250776, acc 1
2018-03-14T17:52:19.970082: step 1074, loss 0.0259568, acc 1
2018-03-14T17:52:20.768616: step 1075, loss 0.019743, acc 1
2018-03-14T17:52:21.562539: step 1076, loss 0.0276897, acc 1
2018-03-14T17:52:22.355442: step 1077, loss 0.0259964, acc 1
2018-03-14T17:52:23.146570: step 1078, loss 0.0307094, acc 1
2018-03-14T17:52:23.940314: step 1079, loss 0.0282473, acc 1
2018-03-14T17:52:24.156283: step 1080, loss 0.033815, acc 1
2018-03-14T17:52:24.953261: step 1081, loss 0.0261073, acc 1
2018-03-14T17:52:25.758048: step 1082, loss 0.0198486, acc 1
2018-03-14T17:52:26.555126: step 1083, loss 0.0274134, acc 1
2018-03-14T17:52:27.352673: step 1084, loss 0.0181646, acc 1
2018-03-14T17:52:28.151819: step 1085, loss 0.0243283, acc 1
2018-03-14T17:52:28.939800: step 1086, loss 0.0421452, acc 1
2018-03-14T17:52:29.732055: step 1087, loss 0.0232457, acc 1
2018-03-14T17:52:30.525389: step 1088, loss 0.0256, acc 1
2018-03-14T17:52:31.320001: step 1089, loss 0.0193914, acc 1
2018-03-14T17:52:32.118479: step 1090, loss 0.0529936, acc 0.984375
2018-03-14T17:52:32.916587: step 1091, loss 0.0817303, acc 0.984375
2018-03-14T17:52:33.714044: step 1092, loss 0.0283243, acc 1
2018-03-14T17:52:34.510859: step 1093, loss 0.0214764, acc 1
2018-03-14T17:52:35.311911: step 1094, loss 0.0464452, acc 0.984375
2018-03-14T17:52:36.106093: step 1095, loss 0.0175374, acc 1
2018-03-14T17:52:36.904901: step 1096, loss 0.0467073, acc 0.984375
2018-03-14T17:52:37.703331: step 1097, loss 0.0276417, acc 1
2018-03-14T17:52:38.500643: step 1098, loss 0.0113401, acc 1
2018-03-14T17:52:39.302882: step 1099, loss 0.0279865, acc 1
2018-03-14T17:52:40.104152: step 1100, loss 0.0464115, acc 1

Evaluation:
2018-03-14T17:52:42.037248: step 1100, loss 0.379588, acc 0.875895

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-1100

2018-03-14T17:52:42.925220: step 1101, loss 0.0275419, acc 1
2018-03-14T17:52:43.716652: step 1102, loss 0.0343826, acc 1
2018-03-14T17:52:44.507492: step 1103, loss 0.0230211, acc 1
2018-03-14T17:52:45.308564: step 1104, loss 0.0460247, acc 1
2018-03-14T17:52:46.099081: step 1105, loss 0.0414669, acc 0.984375
2018-03-14T17:52:46.899179: step 1106, loss 0.036513, acc 1
2018-03-14T17:52:47.118417: step 1107, loss 0.0192936, acc 1
2018-03-14T17:52:47.928704: step 1108, loss 0.0329748, acc 1
2018-03-14T17:52:48.715237: step 1109, loss 0.0174905, acc 1
2018-03-14T17:52:49.511315: step 1110, loss 0.0442206, acc 1
2018-03-14T17:52:50.312743: step 1111, loss 0.0211298, acc 1
2018-03-14T17:52:51.106500: step 1112, loss 0.0304243, acc 1
2018-03-14T17:52:51.900314: step 1113, loss 0.0370244, acc 1
2018-03-14T17:52:52.700376: step 1114, loss 0.0172927, acc 1
2018-03-14T17:52:53.495904: step 1115, loss 0.0152425, acc 1
2018-03-14T17:52:54.326722: step 1116, loss 0.0243963, acc 1
2018-03-14T17:52:55.130569: step 1117, loss 0.0279497, acc 1
2018-03-14T17:52:55.937886: step 1118, loss 0.028245, acc 1
2018-03-14T17:52:56.732247: step 1119, loss 0.0259578, acc 1
2018-03-14T17:52:57.536723: step 1120, loss 0.0393907, acc 1
2018-03-14T17:52:58.336599: step 1121, loss 0.0217009, acc 1
2018-03-14T17:52:59.134159: step 1122, loss 0.0155371, acc 1
2018-03-14T17:52:59.931597: step 1123, loss 0.0259671, acc 1
2018-03-14T17:53:00.730653: step 1124, loss 0.0255409, acc 1
2018-03-14T17:53:01.522826: step 1125, loss 0.0246008, acc 1
2018-03-14T17:53:02.311310: step 1126, loss 0.0198663, acc 1
2018-03-14T17:53:03.099324: step 1127, loss 0.0320828, acc 1
2018-03-14T17:53:03.890144: step 1128, loss 0.0183117, acc 1
2018-03-14T17:53:04.696214: step 1129, loss 0.0315275, acc 1
2018-03-14T17:53:05.485340: step 1130, loss 0.029157, acc 1
2018-03-14T17:53:06.283052: step 1131, loss 0.0217427, acc 1
2018-03-14T17:53:07.072660: step 1132, loss 0.0429672, acc 0.984375
2018-03-14T17:53:07.867516: step 1133, loss 0.029576, acc 1
2018-03-14T17:53:08.089210: step 1134, loss 0.0566819, acc 1
2018-03-14T17:53:08.890938: step 1135, loss 0.0308043, acc 1
2018-03-14T17:53:09.679589: step 1136, loss 0.0360727, acc 1
2018-03-14T17:53:10.468984: step 1137, loss 0.0341017, acc 1
2018-03-14T17:53:11.261792: step 1138, loss 0.0261395, acc 1
2018-03-14T17:53:12.051283: step 1139, loss 0.0190577, acc 1
2018-03-14T17:53:12.847028: step 1140, loss 0.0231835, acc 1
2018-03-14T17:53:13.644687: step 1141, loss 0.0298319, acc 1
2018-03-14T17:53:14.441245: step 1142, loss 0.0310541, acc 1
2018-03-14T17:53:15.238237: step 1143, loss 0.0455033, acc 1
2018-03-14T17:53:16.041415: step 1144, loss 0.0343734, acc 1
2018-03-14T17:53:16.835482: step 1145, loss 0.0251132, acc 1
2018-03-14T17:53:17.627701: step 1146, loss 0.0272579, acc 1
2018-03-14T17:53:18.428984: step 1147, loss 0.0220062, acc 1
2018-03-14T17:53:19.229867: step 1148, loss 0.0545185, acc 0.984375
2018-03-14T17:53:20.019361: step 1149, loss 0.027243, acc 1
2018-03-14T17:53:20.811549: step 1150, loss 0.0259311, acc 1
2018-03-14T17:53:21.612404: step 1151, loss 0.0257303, acc 1
2018-03-14T17:53:22.398164: step 1152, loss 0.0252508, acc 1
2018-03-14T17:53:23.205558: step 1153, loss 0.0244085, acc 1
2018-03-14T17:53:23.993510: step 1154, loss 0.0180193, acc 1
2018-03-14T17:53:24.795554: step 1155, loss 0.0309093, acc 1
2018-03-14T17:53:25.591054: step 1156, loss 0.0278648, acc 0.984375
2018-03-14T17:53:26.384351: step 1157, loss 0.0186042, acc 1
2018-03-14T17:53:27.188705: step 1158, loss 0.0273961, acc 1
2018-03-14T17:53:27.987079: step 1159, loss 0.0330867, acc 1
2018-03-14T17:53:28.787682: step 1160, loss 0.0243013, acc 1
2018-03-14T17:53:29.004725: step 1161, loss 0.020126, acc 1
2018-03-14T17:53:29.807500: step 1162, loss 0.0171656, acc 1
2018-03-14T17:53:30.603478: step 1163, loss 0.0291418, acc 1
2018-03-14T17:53:31.398715: step 1164, loss 0.019176, acc 1
2018-03-14T17:53:32.191365: step 1165, loss 0.0189048, acc 1
2018-03-14T17:53:32.993233: step 1166, loss 0.0280398, acc 1
2018-03-14T17:53:33.780244: step 1167, loss 0.0347175, acc 1
2018-03-14T17:53:34.576862: step 1168, loss 0.0227946, acc 1
2018-03-14T17:53:35.361299: step 1169, loss 0.0166039, acc 1
2018-03-14T17:53:36.153231: step 1170, loss 0.0204018, acc 1
2018-03-14T17:53:36.949859: step 1171, loss 0.0245678, acc 1
2018-03-14T17:53:37.758746: step 1172, loss 0.0528708, acc 1
2018-03-14T17:53:38.548320: step 1173, loss 0.0260581, acc 1
2018-03-14T17:53:39.341534: step 1174, loss 0.0222621, acc 1
2018-03-14T17:53:40.136390: step 1175, loss 0.0347861, acc 0.984375
2018-03-14T17:53:40.928083: step 1176, loss 0.0289716, acc 0.984375
2018-03-14T17:53:41.721031: step 1177, loss 0.0140385, acc 1
2018-03-14T17:53:42.513237: step 1178, loss 0.0259636, acc 1
2018-03-14T17:53:43.297604: step 1179, loss 0.018617, acc 1
2018-03-14T17:53:44.094504: step 1180, loss 0.0495243, acc 0.984375
2018-03-14T17:53:44.887745: step 1181, loss 0.0378993, acc 1
2018-03-14T17:53:45.677046: step 1182, loss 0.0283051, acc 1
2018-03-14T17:53:46.471886: step 1183, loss 0.0189233, acc 1
2018-03-14T17:53:47.271717: step 1184, loss 0.0187165, acc 1
2018-03-14T17:53:48.062534: step 1185, loss 0.0259369, acc 1
2018-03-14T17:53:48.848981: step 1186, loss 0.0211139, acc 1
2018-03-14T17:53:49.646530: step 1187, loss 0.0433369, acc 0.984375
2018-03-14T17:53:49.864269: step 1188, loss 0.0103265, acc 1
2018-03-14T17:53:50.661775: step 1189, loss 0.0206328, acc 1
2018-03-14T17:53:51.454671: step 1190, loss 0.0310519, acc 0.984375
2018-03-14T17:53:52.240542: step 1191, loss 0.0277362, acc 1
2018-03-14T17:53:53.036081: step 1192, loss 0.0166829, acc 1
2018-03-14T17:53:53.834666: step 1193, loss 0.0318366, acc 1
2018-03-14T17:53:54.624511: step 1194, loss 0.0228043, acc 1
2018-03-14T17:53:55.416784: step 1195, loss 0.0290045, acc 1
2018-03-14T17:53:56.213859: step 1196, loss 0.0185461, acc 1
2018-03-14T17:53:57.006667: step 1197, loss 0.0314222, acc 1
2018-03-14T17:53:57.797302: step 1198, loss 0.0194268, acc 1
2018-03-14T17:53:58.591824: step 1199, loss 0.0236612, acc 1
2018-03-14T17:53:59.389846: step 1200, loss 0.0232322, acc 1

Evaluation:
2018-03-14T17:54:00.968249: step 1200, loss 0.384279, acc 0.873508

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-1200

2018-03-14T17:54:01.854211: step 1201, loss 0.0242424, acc 1
2018-03-14T17:54:02.644051: step 1202, loss 0.0222808, acc 1
2018-03-14T17:54:03.439947: step 1203, loss 0.0193831, acc 1
2018-03-14T17:54:04.231756: step 1204, loss 0.0391651, acc 1
2018-03-14T17:54:05.019671: step 1205, loss 0.0141387, acc 1
2018-03-14T17:54:05.824676: step 1206, loss 0.0291287, acc 1
2018-03-14T17:54:06.627802: step 1207, loss 0.0228587, acc 1
2018-03-14T17:54:07.423971: step 1208, loss 0.0187673, acc 1
2018-03-14T17:54:08.211759: step 1209, loss 0.0235122, acc 1
2018-03-14T17:54:09.010122: step 1210, loss 0.0192095, acc 1
2018-03-14T17:54:09.804942: step 1211, loss 0.0202066, acc 1
2018-03-14T17:54:10.604514: step 1212, loss 0.0569959, acc 0.984375
2018-03-14T17:54:11.395386: step 1213, loss 0.01268, acc 1
2018-03-14T17:54:12.189097: step 1214, loss 0.014119, acc 1
2018-03-14T17:54:12.412891: step 1215, loss 0.0237036, acc 1
2018-03-14T17:54:13.213650: step 1216, loss 0.0351887, acc 0.984375
2018-03-14T17:54:14.015459: step 1217, loss 0.0179451, acc 1
2018-03-14T17:54:14.819482: step 1218, loss 0.0213812, acc 1
2018-03-14T17:54:15.617993: step 1219, loss 0.0168448, acc 1
2018-03-14T17:54:16.420000: step 1220, loss 0.0213396, acc 1
2018-03-14T17:54:17.218286: step 1221, loss 0.0170673, acc 1
2018-03-14T17:54:18.016227: step 1222, loss 0.02021, acc 1
2018-03-14T17:54:18.809846: step 1223, loss 0.0175663, acc 1
2018-03-14T17:54:19.612611: step 1224, loss 0.0227131, acc 1
2018-03-14T17:54:20.417402: step 1225, loss 0.0233317, acc 1
2018-03-14T17:54:21.207169: step 1226, loss 0.0164509, acc 1
2018-03-14T17:54:22.005921: step 1227, loss 0.0273023, acc 1
2018-03-14T17:54:22.811449: step 1228, loss 0.0297777, acc 1
2018-03-14T17:54:23.618993: step 1229, loss 0.0255066, acc 1
2018-03-14T17:54:24.415439: step 1230, loss 0.0195342, acc 1
2018-03-14T17:54:25.209264: step 1231, loss 0.0274517, acc 1
2018-03-14T17:54:25.998785: step 1232, loss 0.0213464, acc 1
2018-03-14T17:54:26.797589: step 1233, loss 0.0334835, acc 0.984375
2018-03-14T17:54:27.585853: step 1234, loss 0.0379268, acc 1
2018-03-14T17:54:28.374733: step 1235, loss 0.0172744, acc 1
2018-03-14T17:54:29.172267: step 1236, loss 0.00931321, acc 1
2018-03-14T17:54:29.975599: step 1237, loss 0.0266982, acc 1
2018-03-14T17:54:30.762069: step 1238, loss 0.020531, acc 1
2018-03-14T17:54:31.581087: step 1239, loss 0.0184866, acc 1
2018-03-14T17:54:32.377804: step 1240, loss 0.0161588, acc 1
2018-03-14T17:54:33.174329: step 1241, loss 0.0212688, acc 1
2018-03-14T17:54:33.390259: step 1242, loss 0.00809993, acc 1
2018-03-14T17:54:34.190763: step 1243, loss 0.0151859, acc 1
2018-03-14T17:54:34.982783: step 1244, loss 0.0226099, acc 1
2018-03-14T17:54:35.781294: step 1245, loss 0.0224939, acc 1
2018-03-14T17:54:36.585032: step 1246, loss 0.034099, acc 1
2018-03-14T17:54:37.381291: step 1247, loss 0.0263459, acc 1
2018-03-14T17:54:38.180110: step 1248, loss 0.0096249, acc 1
2018-03-14T17:54:38.978937: step 1249, loss 0.0323509, acc 1
2018-03-14T17:54:39.760389: step 1250, loss 0.0193478, acc 1
2018-03-14T17:54:40.558169: step 1251, loss 0.0144656, acc 1
2018-03-14T17:54:41.358949: step 1252, loss 0.0552137, acc 0.984375
2018-03-14T17:54:42.147919: step 1253, loss 0.0242159, acc 1
2018-03-14T17:54:42.938008: step 1254, loss 0.0212525, acc 1
2018-03-14T17:54:43.734031: step 1255, loss 0.0219781, acc 1
2018-03-14T17:54:44.520704: step 1256, loss 0.0275116, acc 1
2018-03-14T17:54:45.306834: step 1257, loss 0.0252272, acc 1
2018-03-14T17:54:46.102558: step 1258, loss 0.0173498, acc 1
2018-03-14T17:54:46.899815: step 1259, loss 0.021859, acc 1
2018-03-14T17:54:47.689757: step 1260, loss 0.0214305, acc 1
2018-03-14T17:54:48.483407: step 1261, loss 0.0206641, acc 1
2018-03-14T17:54:49.275164: step 1262, loss 0.0361238, acc 1
2018-03-14T17:54:50.073326: step 1263, loss 0.0222266, acc 1
2018-03-14T17:54:50.868237: step 1264, loss 0.0314719, acc 1
2018-03-14T17:54:51.655822: step 1265, loss 0.0252816, acc 1
2018-03-14T17:54:52.447556: step 1266, loss 0.0247537, acc 1
2018-03-14T17:54:53.239677: step 1267, loss 0.0219922, acc 1
2018-03-14T17:54:54.031279: step 1268, loss 0.0324676, acc 1
2018-03-14T17:54:54.249799: step 1269, loss 0.0497069, acc 1
2018-03-14T17:54:55.041324: step 1270, loss 0.014711, acc 1
2018-03-14T17:54:55.844121: step 1271, loss 0.0154903, acc 1
2018-03-14T17:54:56.634586: step 1272, loss 0.0243105, acc 1
2018-03-14T17:54:57.422962: step 1273, loss 0.0199102, acc 1
2018-03-14T17:54:58.218649: step 1274, loss 0.0238097, acc 1
2018-03-14T17:54:59.011465: step 1275, loss 0.0193149, acc 1
2018-03-14T17:54:59.804876: step 1276, loss 0.0225992, acc 1
2018-03-14T17:55:00.608935: step 1277, loss 0.012725, acc 1
2018-03-14T17:55:01.400484: step 1278, loss 0.0162325, acc 1
2018-03-14T17:55:02.199825: step 1279, loss 0.02012, acc 1
2018-03-14T17:55:02.997672: step 1280, loss 0.0146654, acc 1
2018-03-14T17:55:03.785251: step 1281, loss 0.0136578, acc 1
2018-03-14T17:55:04.592627: step 1282, loss 0.0170236, acc 1
2018-03-14T17:55:05.388870: step 1283, loss 0.0569111, acc 0.96875
2018-03-14T17:55:06.185751: step 1284, loss 0.0332346, acc 0.984375
2018-03-14T17:55:06.978788: step 1285, loss 0.0254779, acc 1
2018-03-14T17:55:07.768705: step 1286, loss 0.0147566, acc 1
2018-03-14T17:55:08.553664: step 1287, loss 0.0112063, acc 1
2018-03-14T17:55:09.350100: step 1288, loss 0.0232803, acc 1
2018-03-14T17:55:10.145397: step 1289, loss 0.0212819, acc 1
2018-03-14T17:55:10.935796: step 1290, loss 0.0324239, acc 1
2018-03-14T17:55:11.730671: step 1291, loss 0.0193324, acc 1
2018-03-14T17:55:12.543207: step 1292, loss 0.0277304, acc 1
2018-03-14T17:55:13.349548: step 1293, loss 0.013123, acc 1
2018-03-14T17:55:14.140184: step 1294, loss 0.0397805, acc 0.984375
2018-03-14T17:55:14.937046: step 1295, loss 0.0145365, acc 1
2018-03-14T17:55:15.156356: step 1296, loss 0.0134101, acc 1
2018-03-14T17:55:15.951486: step 1297, loss 0.0275087, acc 1
2018-03-14T17:55:16.752265: step 1298, loss 0.013412, acc 1
2018-03-14T17:55:17.547318: step 1299, loss 0.0129466, acc 1
2018-03-14T17:55:18.341674: step 1300, loss 0.0232481, acc 1

Evaluation:
2018-03-14T17:55:19.898460: step 1300, loss 0.386661, acc 0.863962

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-1300

2018-03-14T17:55:20.773786: step 1301, loss 0.01429, acc 1
2018-03-14T17:55:21.570777: step 1302, loss 0.0193756, acc 1
2018-03-14T17:55:22.360467: step 1303, loss 0.0256484, acc 1
2018-03-14T17:55:23.150124: step 1304, loss 0.0101514, acc 1
2018-03-14T17:55:23.944515: step 1305, loss 0.025229, acc 0.984375
2018-03-14T17:55:24.735666: step 1306, loss 0.0241287, acc 1
2018-03-14T17:55:25.534712: step 1307, loss 0.0292359, acc 0.984375
2018-03-14T17:55:26.335865: step 1308, loss 0.0268412, acc 1
2018-03-14T17:55:27.125977: step 1309, loss 0.0214491, acc 1
2018-03-14T17:55:27.925768: step 1310, loss 0.0177502, acc 1
2018-03-14T17:55:28.720912: step 1311, loss 0.0330316, acc 1
2018-03-14T17:55:29.513094: step 1312, loss 0.0208826, acc 1
2018-03-14T17:55:30.312442: step 1313, loss 0.00948045, acc 1
2018-03-14T17:55:31.109732: step 1314, loss 0.0224079, acc 1
2018-03-14T17:55:31.898996: step 1315, loss 0.0211703, acc 1
2018-03-14T17:55:32.691723: step 1316, loss 0.0168604, acc 1
2018-03-14T17:55:33.494885: step 1317, loss 0.0158647, acc 1
2018-03-14T17:55:34.283552: step 1318, loss 0.0198633, acc 1
2018-03-14T17:55:35.077832: step 1319, loss 0.0148689, acc 1
2018-03-14T17:55:35.871426: step 1320, loss 0.0160467, acc 1
2018-03-14T17:55:36.661843: step 1321, loss 0.0241943, acc 1
2018-03-14T17:55:37.459429: step 1322, loss 0.0148293, acc 1
2018-03-14T17:55:37.684395: step 1323, loss 0.02094, acc 1
2018-03-14T17:55:38.480238: step 1324, loss 0.0156867, acc 1
2018-03-14T17:55:39.275068: step 1325, loss 0.00933008, acc 1
2018-03-14T17:55:40.069510: step 1326, loss 0.0154994, acc 1
2018-03-14T17:55:40.857260: step 1327, loss 0.0145805, acc 1
2018-03-14T17:55:41.651556: step 1328, loss 0.0536748, acc 0.96875
2018-03-14T17:55:42.451589: step 1329, loss 0.0132735, acc 1
2018-03-14T17:55:43.242511: step 1330, loss 0.0259413, acc 1
2018-03-14T17:55:44.029511: step 1331, loss 0.0131336, acc 1
2018-03-14T17:55:44.822301: step 1332, loss 0.0157447, acc 1
2018-03-14T17:55:45.620367: step 1333, loss 0.00977941, acc 1
2018-03-14T17:55:46.423326: step 1334, loss 0.0168403, acc 1
2018-03-14T17:55:47.216991: step 1335, loss 0.0186359, acc 1
2018-03-14T17:55:48.027764: step 1336, loss 0.0167989, acc 1
2018-03-14T17:55:48.820241: step 1337, loss 0.0156739, acc 1
2018-03-14T17:55:49.610211: step 1338, loss 0.0414691, acc 0.984375
2018-03-14T17:55:50.407720: step 1339, loss 0.0140571, acc 1
2018-03-14T17:55:51.202255: step 1340, loss 0.0151498, acc 1
2018-03-14T17:55:52.006780: step 1341, loss 0.0182629, acc 1
2018-03-14T17:55:52.804905: step 1342, loss 0.0211188, acc 1
2018-03-14T17:55:53.609255: step 1343, loss 0.0138229, acc 1
2018-03-14T17:55:54.406753: step 1344, loss 0.0124029, acc 1
2018-03-14T17:55:55.222801: step 1345, loss 0.0132588, acc 1
2018-03-14T17:55:56.020276: step 1346, loss 0.0304816, acc 1
2018-03-14T17:55:56.808152: step 1347, loss 0.0165719, acc 1
2018-03-14T17:55:57.609232: step 1348, loss 0.0477367, acc 0.984375
2018-03-14T17:55:58.409258: step 1349, loss 0.0198374, acc 1
2018-03-14T17:55:58.626011: step 1350, loss 0.00428336, acc 1
2018-03-14T17:55:59.416888: step 1351, loss 0.020042, acc 1
2018-03-14T17:56:00.213977: step 1352, loss 0.0128318, acc 1
2018-03-14T17:56:01.020288: step 1353, loss 0.0145353, acc 1
2018-03-14T17:56:01.816529: step 1354, loss 0.0118511, acc 1
2018-03-14T17:56:02.610668: step 1355, loss 0.0171249, acc 1
2018-03-14T17:56:03.411234: step 1356, loss 0.0194767, acc 1
2018-03-14T17:56:04.208283: step 1357, loss 0.0205281, acc 1
2018-03-14T17:56:05.008314: step 1358, loss 0.010578, acc 1
2018-03-14T17:56:05.802544: step 1359, loss 0.00586262, acc 1
2018-03-14T17:56:06.604944: step 1360, loss 0.0165188, acc 1
2018-03-14T17:56:07.399593: step 1361, loss 0.0210246, acc 1
2018-03-14T17:56:08.198412: step 1362, loss 0.0208625, acc 1
2018-03-14T17:56:08.988226: step 1363, loss 0.0228594, acc 1
2018-03-14T17:56:09.781873: step 1364, loss 0.0137258, acc 1
2018-03-14T17:56:10.574508: step 1365, loss 0.0118155, acc 1
2018-03-14T17:56:11.375012: step 1366, loss 0.0169634, acc 1
2018-03-14T17:56:12.164226: step 1367, loss 0.028115, acc 1
2018-03-14T17:56:12.963333: step 1368, loss 0.00999445, acc 1
2018-03-14T17:56:13.775172: step 1369, loss 0.00703162, acc 1
2018-03-14T17:56:14.561133: step 1370, loss 0.0264154, acc 1
2018-03-14T17:56:15.361968: step 1371, loss 0.0108169, acc 1
2018-03-14T17:56:16.163156: step 1372, loss 0.0129029, acc 1
2018-03-14T17:56:16.959632: step 1373, loss 0.0340612, acc 1
2018-03-14T17:56:17.747201: step 1374, loss 0.0187907, acc 1
2018-03-14T17:56:18.547313: step 1375, loss 0.0105436, acc 1
2018-03-14T17:56:19.341326: step 1376, loss 0.028268, acc 1
2018-03-14T17:56:19.557236: step 1377, loss 0.0164962, acc 1
2018-03-14T17:56:20.358317: step 1378, loss 0.0111784, acc 1
2018-03-14T17:56:21.143263: step 1379, loss 0.0112423, acc 1
2018-03-14T17:56:21.944813: step 1380, loss 0.0203921, acc 1
2018-03-14T17:56:22.745673: step 1381, loss 0.00817407, acc 1
2018-03-14T17:56:23.538721: step 1382, loss 0.0201394, acc 1
2018-03-14T17:56:24.330405: step 1383, loss 0.0205809, acc 1
2018-03-14T17:56:25.127452: step 1384, loss 0.0180897, acc 1
2018-03-14T17:56:25.922597: step 1385, loss 0.0111109, acc 1
2018-03-14T17:56:26.720616: step 1386, loss 0.0346456, acc 0.984375
2018-03-14T17:56:27.515244: step 1387, loss 0.0286541, acc 1
2018-03-14T17:56:28.311618: step 1388, loss 0.0116723, acc 1
2018-03-14T17:56:29.108582: step 1389, loss 0.0179621, acc 1
2018-03-14T17:56:29.910023: step 1390, loss 0.0124197, acc 1
2018-03-14T17:56:30.713356: step 1391, loss 0.00940195, acc 1
2018-03-14T17:56:31.511340: step 1392, loss 0.0211812, acc 1
2018-03-14T17:56:32.309056: step 1393, loss 0.0232162, acc 1
2018-03-14T17:56:33.101984: step 1394, loss 0.0159206, acc 1
2018-03-14T17:56:33.901954: step 1395, loss 0.0223943, acc 0.984375
2018-03-14T17:56:34.696004: step 1396, loss 0.0167704, acc 1
2018-03-14T17:56:35.492798: step 1397, loss 0.0213777, acc 1
2018-03-14T17:56:36.290417: step 1398, loss 0.0125345, acc 1
2018-03-14T17:56:37.084756: step 1399, loss 0.0136664, acc 1
2018-03-14T17:56:37.871797: step 1400, loss 0.0158046, acc 1

Evaluation:
2018-03-14T17:56:39.401932: step 1400, loss 0.358785, acc 0.880668

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-1400

2018-03-14T17:56:40.306839: step 1401, loss 0.0222153, acc 1
2018-03-14T17:56:41.102975: step 1402, loss 0.0168469, acc 1
2018-03-14T17:56:41.899014: step 1403, loss 0.0147488, acc 1
2018-03-14T17:56:42.117143: step 1404, loss 0.0102423, acc 1
2018-03-14T17:56:42.913341: step 1405, loss 0.0110213, acc 1
2018-03-14T17:56:43.706113: step 1406, loss 0.0102064, acc 1
2018-03-14T17:56:44.497905: step 1407, loss 0.0176939, acc 1
2018-03-14T17:56:45.296090: step 1408, loss 0.0177255, acc 1
2018-03-14T17:56:46.099658: step 1409, loss 0.0114952, acc 1
2018-03-14T17:56:46.890643: step 1410, loss 0.014986, acc 1
2018-03-14T17:56:47.685924: step 1411, loss 0.0140024, acc 1
2018-03-14T17:56:48.476699: step 1412, loss 0.0584562, acc 0.984375
2018-03-14T17:56:49.264458: step 1413, loss 0.0153642, acc 1
2018-03-14T17:56:50.057167: step 1414, loss 0.0222123, acc 0.984375
2018-03-14T17:56:50.847536: step 1415, loss 0.01359, acc 1
2018-03-14T17:56:51.642235: step 1416, loss 0.0205824, acc 1
2018-03-14T17:56:52.429318: step 1417, loss 0.0161693, acc 1
2018-03-14T17:56:53.222270: step 1418, loss 0.00823362, acc 1
2018-03-14T17:56:54.022278: step 1419, loss 0.0163729, acc 1
2018-03-14T17:56:54.822234: step 1420, loss 0.0128856, acc 1
2018-03-14T17:56:55.648171: step 1421, loss 0.105891, acc 0.96875
2018-03-14T17:56:56.445554: step 1422, loss 0.0109368, acc 1
2018-03-14T17:56:57.249842: step 1423, loss 0.00684967, acc 1
2018-03-14T17:56:58.041935: step 1424, loss 0.0103374, acc 1
2018-03-14T17:56:58.830857: step 1425, loss 0.0120339, acc 1
2018-03-14T17:56:59.622326: step 1426, loss 0.0199739, acc 1
2018-03-14T17:57:00.422014: step 1427, loss 0.00579477, acc 1
2018-03-14T17:57:01.219187: step 1428, loss 0.0136965, acc 1
2018-03-14T17:57:02.011677: step 1429, loss 0.0212398, acc 1
2018-03-14T17:57:02.805163: step 1430, loss 0.0143535, acc 1
2018-03-14T17:57:03.030433: step 1431, loss 0.00801615, acc 1
2018-03-14T17:57:03.821725: step 1432, loss 0.0150501, acc 1
2018-03-14T17:57:04.609481: step 1433, loss 0.0228383, acc 1
2018-03-14T17:57:05.407085: step 1434, loss 0.0121414, acc 1
2018-03-14T17:57:06.194669: step 1435, loss 0.00887723, acc 1
2018-03-14T17:57:06.994403: step 1436, loss 0.0108777, acc 1
2018-03-14T17:57:07.795833: step 1437, loss 0.0186717, acc 1
2018-03-14T17:57:08.588506: step 1438, loss 0.0219068, acc 1
2018-03-14T17:57:09.394305: step 1439, loss 0.0180085, acc 1
2018-03-14T17:57:10.201373: step 1440, loss 0.0150603, acc 1
2018-03-14T17:57:11.006688: step 1441, loss 0.0227357, acc 1
2018-03-14T17:57:11.805073: step 1442, loss 0.0162849, acc 1
2018-03-14T17:57:12.604766: step 1443, loss 0.0172965, acc 1
2018-03-14T17:57:13.393306: step 1444, loss 0.0167186, acc 1
2018-03-14T17:57:14.194998: step 1445, loss 0.0135143, acc 1
2018-03-14T17:57:15.007835: step 1446, loss 0.00953366, acc 1
2018-03-14T17:57:15.800107: step 1447, loss 0.014104, acc 1
2018-03-14T17:57:16.599598: step 1448, loss 0.0131428, acc 1
2018-03-14T17:57:17.407456: step 1449, loss 0.0176632, acc 1
2018-03-14T17:57:18.198885: step 1450, loss 0.0233586, acc 1
2018-03-14T17:57:18.998204: step 1451, loss 0.052186, acc 0.984375
2018-03-14T17:57:19.798358: step 1452, loss 0.0138851, acc 1
2018-03-14T17:57:20.593116: step 1453, loss 0.0792976, acc 0.984375
2018-03-14T17:57:21.391105: step 1454, loss 0.0296453, acc 0.984375
2018-03-14T17:57:22.191981: step 1455, loss 0.0250564, acc 0.984375
2018-03-14T17:57:22.981086: step 1456, loss 0.0108657, acc 1
2018-03-14T17:57:23.776725: step 1457, loss 0.0160197, acc 1
2018-03-14T17:57:24.001990: step 1458, loss 0.0128649, acc 1
2018-03-14T17:57:24.788250: step 1459, loss 0.017422, acc 1
2018-03-14T17:57:25.589880: step 1460, loss 0.0144093, acc 1
2018-03-14T17:57:26.387667: step 1461, loss 0.0846752, acc 0.96875
2018-03-14T17:57:27.190218: step 1462, loss 0.00865596, acc 1
2018-03-14T17:57:27.997923: step 1463, loss 0.0326139, acc 0.984375
2018-03-14T17:57:28.805291: step 1464, loss 0.028482, acc 0.984375
2018-03-14T17:57:29.599304: step 1465, loss 0.00775514, acc 1
2018-03-14T17:57:30.402963: step 1466, loss 0.0138551, acc 1
2018-03-14T17:57:31.203171: step 1467, loss 0.00924594, acc 1
2018-03-14T17:57:32.000804: step 1468, loss 0.00813051, acc 1
2018-03-14T17:57:32.794380: step 1469, loss 0.0157809, acc 1
2018-03-14T17:57:33.597072: step 1470, loss 0.0327162, acc 0.984375
2018-03-14T17:57:34.397719: step 1471, loss 0.00913946, acc 1
2018-03-14T17:57:35.196519: step 1472, loss 0.0129064, acc 1
2018-03-14T17:57:35.993456: step 1473, loss 0.0163554, acc 1
2018-03-14T17:57:36.778903: step 1474, loss 0.0110698, acc 1
2018-03-14T17:57:37.576157: step 1475, loss 0.0210711, acc 1
2018-03-14T17:57:38.372510: step 1476, loss 0.0155753, acc 1
2018-03-14T17:57:39.171285: step 1477, loss 0.0076657, acc 1
2018-03-14T17:57:39.963665: step 1478, loss 0.0136955, acc 1
2018-03-14T17:57:40.768697: step 1479, loss 0.0155667, acc 1
2018-03-14T17:57:41.560137: step 1480, loss 0.0237002, acc 1
2018-03-14T17:57:42.347736: step 1481, loss 0.0157489, acc 1
2018-03-14T17:57:43.145016: step 1482, loss 0.0143285, acc 1
2018-03-14T17:57:43.936853: step 1483, loss 0.025256, acc 1
2018-03-14T17:57:44.732024: step 1484, loss 0.0155626, acc 1
2018-03-14T17:57:44.959996: step 1485, loss 0.0201597, acc 1
2018-03-14T17:57:45.745443: step 1486, loss 0.0131485, acc 1
2018-03-14T17:57:46.545380: step 1487, loss 0.0271331, acc 0.984375
2018-03-14T17:57:47.348197: step 1488, loss 0.0144764, acc 1
2018-03-14T17:57:48.140473: step 1489, loss 0.0171691, acc 1
2018-03-14T17:57:48.943290: step 1490, loss 0.0180678, acc 1
2018-03-14T17:57:49.735291: step 1491, loss 0.00969154, acc 1
2018-03-14T17:57:50.525294: step 1492, loss 0.0133667, acc 1
2018-03-14T17:57:51.316871: step 1493, loss 0.0111678, acc 1
2018-03-14T17:57:52.112195: step 1494, loss 0.0222567, acc 1
2018-03-14T17:57:52.910523: step 1495, loss 0.0106028, acc 1
2018-03-14T17:57:53.703204: step 1496, loss 0.0151114, acc 1
2018-03-14T17:57:54.493548: step 1497, loss 0.0475437, acc 0.96875
2018-03-14T17:57:55.286199: step 1498, loss 0.020357, acc 1
2018-03-14T17:57:56.086557: step 1499, loss 0.0142741, acc 1
2018-03-14T17:57:56.882330: step 1500, loss 0.0324522, acc 0.984375

Evaluation:
2018-03-14T17:57:58.427429: step 1500, loss 0.375256, acc 0.875895

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-1500

2018-03-14T17:57:59.355166: step 1501, loss 0.0129508, acc 1
2018-03-14T17:58:00.148730: step 1502, loss 0.0189316, acc 1
2018-03-14T17:58:00.945314: step 1503, loss 0.0182843, acc 1
2018-03-14T17:58:01.749268: step 1504, loss 0.013131, acc 1
2018-03-14T17:58:02.537975: step 1505, loss 0.0106969, acc 1
2018-03-14T17:58:03.330771: step 1506, loss 0.0171875, acc 1
2018-03-14T17:58:04.133111: step 1507, loss 0.0205945, acc 1
2018-03-14T17:58:04.922108: step 1508, loss 0.0254194, acc 1
2018-03-14T17:58:05.718531: step 1509, loss 0.0150681, acc 1
2018-03-14T17:58:06.516600: step 1510, loss 0.00970231, acc 1
2018-03-14T17:58:07.308557: step 1511, loss 0.00839115, acc 1
2018-03-14T17:58:07.526731: step 1512, loss 0.0471571, acc 1
2018-03-14T17:58:08.319092: step 1513, loss 0.00927472, acc 1
2018-03-14T17:58:09.113831: step 1514, loss 0.00862474, acc 1
2018-03-14T17:58:09.901715: step 1515, loss 0.0154449, acc 1
2018-03-14T17:58:10.694216: step 1516, loss 0.0135781, acc 1
2018-03-14T17:58:11.488224: step 1517, loss 0.0119226, acc 1
2018-03-14T17:58:12.279565: step 1518, loss 0.0138132, acc 1
2018-03-14T17:58:13.088395: step 1519, loss 0.0223271, acc 1
2018-03-14T17:58:13.876464: step 1520, loss 0.0245306, acc 1
2018-03-14T17:58:14.666050: step 1521, loss 0.0452054, acc 0.984375
2018-03-14T17:58:15.464673: step 1522, loss 0.0134042, acc 1
2018-03-14T17:58:16.253284: step 1523, loss 0.0101018, acc 1
2018-03-14T17:58:17.039317: step 1524, loss 0.0261478, acc 1
2018-03-14T17:58:17.831021: step 1525, loss 0.0288613, acc 0.984375
2018-03-14T17:58:18.628824: step 1526, loss 0.0126279, acc 1
2018-03-14T17:58:19.426955: step 1527, loss 0.0102832, acc 1
2018-03-14T17:58:20.217018: step 1528, loss 0.0170516, acc 1
2018-03-14T17:58:21.028686: step 1529, loss 0.0107715, acc 1
2018-03-14T17:58:21.821608: step 1530, loss 0.0173197, acc 1
2018-03-14T17:58:22.616252: step 1531, loss 0.0173422, acc 1
2018-03-14T17:58:23.415980: step 1532, loss 0.0144688, acc 1
2018-03-14T17:58:24.201807: step 1533, loss 0.0110794, acc 1
2018-03-14T17:58:24.999945: step 1534, loss 0.0124751, acc 1
2018-03-14T17:58:25.801661: step 1535, loss 0.00836894, acc 1
2018-03-14T17:58:26.602231: step 1536, loss 0.013561, acc 1
2018-03-14T17:58:27.399478: step 1537, loss 0.0180604, acc 1
2018-03-14T17:58:28.201538: step 1538, loss 0.0125255, acc 1
2018-03-14T17:58:28.420311: step 1539, loss 0.0393397, acc 1
2018-03-14T17:58:29.218100: step 1540, loss 0.00768328, acc 1
2018-03-14T17:58:30.013761: step 1541, loss 0.0196743, acc 1
2018-03-14T17:58:30.814204: step 1542, loss 0.00901623, acc 1
2018-03-14T17:58:31.619821: step 1543, loss 0.0133656, acc 1
2018-03-14T17:58:32.418821: step 1544, loss 0.00960947, acc 1
2018-03-14T17:58:33.206113: step 1545, loss 0.0164405, acc 1
2018-03-14T17:58:34.009177: step 1546, loss 0.015917, acc 1
2018-03-14T17:58:34.814688: step 1547, loss 0.0180587, acc 1
2018-03-14T17:58:35.615881: step 1548, loss 0.00660049, acc 1
2018-03-14T17:58:36.409979: step 1549, loss 0.0169321, acc 1
2018-03-14T17:58:37.214908: step 1550, loss 0.00844471, acc 1
2018-03-14T17:58:38.003795: step 1551, loss 0.0187868, acc 1
2018-03-14T17:58:38.806962: step 1552, loss 0.00833745, acc 1
2018-03-14T17:58:39.605092: step 1553, loss 0.0113369, acc 1
2018-03-14T17:58:40.400833: step 1554, loss 0.0135492, acc 1
2018-03-14T17:58:41.192438: step 1555, loss 0.00686754, acc 1
2018-03-14T17:58:41.988952: step 1556, loss 0.00932303, acc 1
2018-03-14T17:58:42.776655: step 1557, loss 0.0107207, acc 1
2018-03-14T17:58:43.571614: step 1558, loss 0.0219188, acc 1
2018-03-14T17:58:44.368880: step 1559, loss 0.0322928, acc 1
2018-03-14T17:58:45.160047: step 1560, loss 0.00900717, acc 1
2018-03-14T17:58:45.959322: step 1561, loss 0.0125334, acc 1
2018-03-14T17:58:46.767727: step 1562, loss 0.0170885, acc 1
2018-03-14T17:58:47.565439: step 1563, loss 0.00824592, acc 1
2018-03-14T17:58:48.363277: step 1564, loss 0.0180389, acc 1
2018-03-14T17:58:49.154144: step 1565, loss 0.0106322, acc 1
2018-03-14T17:58:49.375047: step 1566, loss 0.00932497, acc 1
2018-03-14T17:58:50.175410: step 1567, loss 0.0240367, acc 1
2018-03-14T17:58:50.969509: step 1568, loss 0.0130781, acc 1
2018-03-14T17:58:51.763467: step 1569, loss 0.0138214, acc 1
2018-03-14T17:58:52.554535: step 1570, loss 0.0178441, acc 1
2018-03-14T17:58:53.357845: step 1571, loss 0.00733507, acc 1
2018-03-14T17:58:54.151007: step 1572, loss 0.0132599, acc 1
2018-03-14T17:58:54.947586: step 1573, loss 0.0427872, acc 0.984375
2018-03-14T17:58:55.746691: step 1574, loss 0.00749008, acc 1
2018-03-14T17:58:56.542781: step 1575, loss 0.00621796, acc 1
2018-03-14T17:58:57.339992: step 1576, loss 0.0132917, acc 1
2018-03-14T17:58:58.134444: step 1577, loss 0.00779462, acc 1
2018-03-14T17:58:58.924705: step 1578, loss 0.0160201, acc 1
2018-03-14T17:58:59.715744: step 1579, loss 0.00826985, acc 1
2018-03-14T17:59:00.517707: step 1580, loss 0.0213534, acc 1
2018-03-14T17:59:01.309140: step 1581, loss 0.00949219, acc 1
2018-03-14T17:59:02.102913: step 1582, loss 0.00787916, acc 1
2018-03-14T17:59:02.898218: step 1583, loss 0.0263221, acc 1
2018-03-14T17:59:03.695923: step 1584, loss 0.0144138, acc 1
2018-03-14T17:59:04.486265: step 1585, loss 0.0219445, acc 1
2018-03-14T17:59:05.296964: step 1586, loss 0.00835907, acc 1
2018-03-14T17:59:06.091354: step 1587, loss 0.0114635, acc 1
2018-03-14T17:59:06.887928: step 1588, loss 0.028919, acc 1
2018-03-14T17:59:07.681703: step 1589, loss 0.0249759, acc 1
2018-03-14T17:59:08.478487: step 1590, loss 0.0197595, acc 1
2018-03-14T17:59:09.268108: step 1591, loss 0.0300348, acc 0.984375
2018-03-14T17:59:10.067039: step 1592, loss 0.0292923, acc 1
2018-03-14T17:59:10.282975: step 1593, loss 0.0297612, acc 1
2018-03-14T17:59:11.072538: step 1594, loss 0.00971665, acc 1
2018-03-14T17:59:11.875378: step 1595, loss 0.0192348, acc 1
2018-03-14T17:59:12.664617: step 1596, loss 0.00767459, acc 1
2018-03-14T17:59:13.458646: step 1597, loss 0.0145152, acc 1
2018-03-14T17:59:14.254230: step 1598, loss 0.00840445, acc 1
2018-03-14T17:59:15.049352: step 1599, loss 0.00829922, acc 1
2018-03-14T17:59:15.843137: step 1600, loss 0.0136684, acc 1

Evaluation:
2018-03-14T17:59:17.382977: step 1600, loss 0.354882, acc 0.890215

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-1600

2018-03-14T17:59:18.265452: step 1601, loss 0.00852964, acc 1
2018-03-14T17:59:19.057281: step 1602, loss 0.0209042, acc 1
2018-03-14T17:59:19.856432: step 1603, loss 0.0110917, acc 1
2018-03-14T17:59:20.657177: step 1604, loss 0.00947962, acc 1
2018-03-14T17:59:21.448108: step 1605, loss 0.00990122, acc 1
2018-03-14T17:59:22.235375: step 1606, loss 0.0169075, acc 1
2018-03-14T17:59:23.032129: step 1607, loss 0.014255, acc 1
2018-03-14T17:59:23.823960: step 1608, loss 0.0106461, acc 1
2018-03-14T17:59:24.619663: step 1609, loss 0.00884803, acc 1
2018-03-14T17:59:25.415237: step 1610, loss 0.0151712, acc 1
2018-03-14T17:59:26.211680: step 1611, loss 0.0307018, acc 0.984375
2018-03-14T17:59:27.015393: step 1612, loss 0.011552, acc 1
2018-03-14T17:59:27.796469: step 1613, loss 0.0134495, acc 1
2018-03-14T17:59:28.591571: step 1614, loss 0.0114124, acc 1
2018-03-14T17:59:29.386679: step 1615, loss 0.0205556, acc 1
2018-03-14T17:59:30.182378: step 1616, loss 0.00976201, acc 1
2018-03-14T17:59:30.977237: step 1617, loss 0.0128372, acc 1
2018-03-14T17:59:31.771963: step 1618, loss 0.0119735, acc 1
2018-03-14T17:59:32.567175: step 1619, loss 0.0133853, acc 1
2018-03-14T17:59:32.784716: step 1620, loss 0.0107705, acc 1
2018-03-14T17:59:33.584568: step 1621, loss 0.0117076, acc 1
2018-03-14T17:59:34.372580: step 1622, loss 0.0656946, acc 0.984375
2018-03-14T17:59:35.174680: step 1623, loss 0.00968321, acc 1
2018-03-14T17:59:35.971891: step 1624, loss 0.00903455, acc 1
2018-03-14T17:59:36.760131: step 1625, loss 0.00899937, acc 1
2018-03-14T17:59:37.548787: step 1626, loss 0.0116266, acc 1
2018-03-14T17:59:38.344042: step 1627, loss 0.0131406, acc 1
2018-03-14T17:59:39.135059: step 1628, loss 0.00616769, acc 1
2018-03-14T17:59:39.924256: step 1629, loss 0.00969652, acc 1
2018-03-14T17:59:40.712072: step 1630, loss 0.0177122, acc 1
2018-03-14T17:59:41.506982: step 1631, loss 0.0146277, acc 1
2018-03-14T17:59:42.299454: step 1632, loss 0.0125882, acc 1
2018-03-14T17:59:43.098832: step 1633, loss 0.0124431, acc 1
2018-03-14T17:59:43.887422: step 1634, loss 0.0105748, acc 1
2018-03-14T17:59:44.686654: step 1635, loss 0.0111586, acc 1
2018-03-14T17:59:45.482699: step 1636, loss 0.0119303, acc 1
2018-03-14T17:59:46.274463: step 1637, loss 0.014144, acc 1
2018-03-14T17:59:47.065987: step 1638, loss 0.00811295, acc 1
2018-03-14T17:59:47.871827: step 1639, loss 0.0126426, acc 1
2018-03-14T17:59:48.661886: step 1640, loss 0.0123826, acc 1
2018-03-14T17:59:49.452313: step 1641, loss 0.0149561, acc 1
2018-03-14T17:59:50.248012: step 1642, loss 0.00697763, acc 1
2018-03-14T17:59:51.036283: step 1643, loss 0.0218312, acc 1
2018-03-14T17:59:51.827225: step 1644, loss 0.0129363, acc 1
2018-03-14T17:59:52.622865: step 1645, loss 0.0138515, acc 1
2018-03-14T17:59:53.420507: step 1646, loss 0.0255267, acc 0.984375
2018-03-14T17:59:53.635172: step 1647, loss 0.0157431, acc 1
2018-03-14T17:59:54.421742: step 1648, loss 0.0123428, acc 1
2018-03-14T17:59:55.217986: step 1649, loss 0.0117814, acc 1
2018-03-14T17:59:56.010318: step 1650, loss 0.00710354, acc 1
2018-03-14T17:59:56.806905: step 1651, loss 0.0145032, acc 1
2018-03-14T17:59:57.602495: step 1652, loss 0.00701335, acc 1
2018-03-14T17:59:58.400284: step 1653, loss 0.0171339, acc 1
2018-03-14T17:59:59.202710: step 1654, loss 0.0222462, acc 1
2018-03-14T18:00:00.005495: step 1655, loss 0.0144396, acc 1
2018-03-14T18:00:00.798139: step 1656, loss 0.00894711, acc 1
2018-03-14T18:00:01.596723: step 1657, loss 0.00819387, acc 1
2018-03-14T18:00:02.396588: step 1658, loss 0.0148884, acc 1
2018-03-14T18:00:03.199350: step 1659, loss 0.0111432, acc 1
2018-03-14T18:00:03.995970: step 1660, loss 0.0153565, acc 1
2018-03-14T18:00:04.786608: step 1661, loss 0.0137242, acc 1
2018-03-14T18:00:05.577280: step 1662, loss 0.0129459, acc 1
2018-03-14T18:00:06.371879: step 1663, loss 0.00929837, acc 1
2018-03-14T18:00:07.175709: step 1664, loss 0.0123485, acc 1
2018-03-14T18:00:07.981088: step 1665, loss 0.00921045, acc 1
2018-03-14T18:00:08.771774: step 1666, loss 0.0102568, acc 1
2018-03-14T18:00:09.568823: step 1667, loss 0.0152413, acc 1
2018-03-14T18:00:10.369946: step 1668, loss 0.0113839, acc 1
2018-03-14T18:00:11.167946: step 1669, loss 0.0122134, acc 1
2018-03-14T18:00:11.956268: step 1670, loss 0.0244006, acc 1
2018-03-14T18:00:12.747718: step 1671, loss 0.00864713, acc 1
2018-03-14T18:00:13.540499: step 1672, loss 0.0235394, acc 0.984375
2018-03-14T18:00:14.335421: step 1673, loss 0.0130757, acc 1
2018-03-14T18:00:14.551945: step 1674, loss 0.0123546, acc 1
2018-03-14T18:00:15.350430: step 1675, loss 0.0115218, acc 1
2018-03-14T18:00:16.145298: step 1676, loss 0.00617797, acc 1
2018-03-14T18:00:16.944069: step 1677, loss 0.0108087, acc 1
2018-03-14T18:00:17.744088: step 1678, loss 0.0267062, acc 0.984375
2018-03-14T18:00:18.548079: step 1679, loss 0.0120324, acc 1
2018-03-14T18:00:19.340810: step 1680, loss 0.00557147, acc 1
2018-03-14T18:00:20.133412: step 1681, loss 0.0118531, acc 1
2018-03-14T18:00:20.942782: step 1682, loss 0.0142999, acc 1
2018-03-14T18:00:21.740976: step 1683, loss 0.0293796, acc 0.984375
2018-03-14T18:00:22.537640: step 1684, loss 0.00766676, acc 1
2018-03-14T18:00:23.340465: step 1685, loss 0.0258593, acc 0.984375
2018-03-14T18:00:24.140497: step 1686, loss 0.0220754, acc 1
2018-03-14T18:00:24.934455: step 1687, loss 0.0106637, acc 1
2018-03-14T18:00:25.733937: step 1688, loss 0.0134629, acc 1
2018-03-14T18:00:26.534377: step 1689, loss 0.00857118, acc 1
2018-03-14T18:00:27.340310: step 1690, loss 0.00770115, acc 1
2018-03-14T18:00:28.140434: step 1691, loss 0.00625567, acc 1
2018-03-14T18:00:28.933199: step 1692, loss 0.0176317, acc 1
2018-03-14T18:00:29.721545: step 1693, loss 0.00671143, acc 1
2018-03-14T18:00:30.520535: step 1694, loss 0.0133051, acc 1
2018-03-14T18:00:31.319005: step 1695, loss 0.00946125, acc 1
2018-03-14T18:00:32.113582: step 1696, loss 0.0148402, acc 1
2018-03-14T18:00:32.910447: step 1697, loss 0.0111263, acc 1
2018-03-14T18:00:33.704444: step 1698, loss 0.0129925, acc 1
2018-03-14T18:00:34.502556: step 1699, loss 0.00620495, acc 1
2018-03-14T18:00:35.297590: step 1700, loss 0.00702041, acc 1

Evaluation:
2018-03-14T18:00:36.930965: step 1700, loss 0.351147, acc 0.883055

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-1700

2018-03-14T18:00:37.248893: step 1701, loss 0.00999624, acc 1
2018-03-14T18:00:38.045189: step 1702, loss 0.0222621, acc 1
2018-03-14T18:00:38.843329: step 1703, loss 0.0093098, acc 1
2018-03-14T18:00:39.644550: step 1704, loss 0.00742108, acc 1
2018-03-14T18:00:40.447349: step 1705, loss 0.00628157, acc 1
2018-03-14T18:00:41.242344: step 1706, loss 0.0122052, acc 1
2018-03-14T18:00:42.038155: step 1707, loss 0.0093032, acc 1
2018-03-14T18:00:42.838171: step 1708, loss 0.0185559, acc 1
2018-03-14T18:00:43.631019: step 1709, loss 0.0153076, acc 1
2018-03-14T18:00:44.424989: step 1710, loss 0.00836902, acc 1
2018-03-14T18:00:45.225257: step 1711, loss 0.0187015, acc 1
2018-03-14T18:00:46.029367: step 1712, loss 0.0118877, acc 1
2018-03-14T18:00:46.838859: step 1713, loss 0.0195288, acc 0.984375
2018-03-14T18:00:47.637774: step 1714, loss 0.0284095, acc 1
2018-03-14T18:00:48.434602: step 1715, loss 0.00880856, acc 1
2018-03-14T18:00:49.232657: step 1716, loss 0.0102452, acc 1
2018-03-14T18:00:50.031079: step 1717, loss 0.00750002, acc 1
2018-03-14T18:00:50.824031: step 1718, loss 0.0212, acc 1
2018-03-14T18:00:51.631816: step 1719, loss 0.00675668, acc 1
2018-03-14T18:00:52.429805: step 1720, loss 0.0107479, acc 1
2018-03-14T18:00:53.222021: step 1721, loss 0.00679046, acc 1
2018-03-14T18:00:54.026740: step 1722, loss 0.0201706, acc 1
2018-03-14T18:00:54.823206: step 1723, loss 0.0129081, acc 1
2018-03-14T18:00:55.621247: step 1724, loss 0.0129455, acc 1
2018-03-14T18:00:56.414779: step 1725, loss 0.00742158, acc 1
2018-03-14T18:00:57.208947: step 1726, loss 0.00652082, acc 1
2018-03-14T18:00:58.006453: step 1727, loss 0.00726917, acc 1
2018-03-14T18:00:58.230670: step 1728, loss 0.0100025, acc 1
2018-03-14T18:00:59.030727: step 1729, loss 0.0149649, acc 1
2018-03-14T18:00:59.822298: step 1730, loss 0.0168023, acc 1
2018-03-14T18:01:00.630082: step 1731, loss 0.00701769, acc 1
2018-03-14T18:01:01.420646: step 1732, loss 0.00868548, acc 1
2018-03-14T18:01:02.223225: step 1733, loss 0.0100327, acc 1
2018-03-14T18:01:03.032043: step 1734, loss 0.0159287, acc 1
2018-03-14T18:01:03.823932: step 1735, loss 0.0105567, acc 1
2018-03-14T18:01:04.614602: step 1736, loss 0.00474379, acc 1
2018-03-14T18:01:05.419684: step 1737, loss 0.011525, acc 1
2018-03-14T18:01:06.215434: step 1738, loss 0.0177176, acc 1
2018-03-14T18:01:07.015644: step 1739, loss 0.0124531, acc 1
2018-03-14T18:01:07.811730: step 1740, loss 0.0109317, acc 1
2018-03-14T18:01:08.608921: step 1741, loss 0.0074027, acc 1
2018-03-14T18:01:09.405274: step 1742, loss 0.00624363, acc 1
2018-03-14T18:01:10.210516: step 1743, loss 0.00807417, acc 1
2018-03-14T18:01:11.000212: step 1744, loss 0.00866276, acc 1
2018-03-14T18:01:11.796415: step 1745, loss 0.00860419, acc 1
2018-03-14T18:01:12.584344: step 1746, loss 0.0323381, acc 0.984375
2018-03-14T18:01:13.375074: step 1747, loss 0.0155188, acc 1
2018-03-14T18:01:14.173820: step 1748, loss 0.00764045, acc 1
2018-03-14T18:01:14.971790: step 1749, loss 0.00902107, acc 1
2018-03-14T18:01:15.771202: step 1750, loss 0.0154174, acc 1
2018-03-14T18:01:16.570939: step 1751, loss 0.00536945, acc 1
2018-03-14T18:01:17.365935: step 1752, loss 0.00882387, acc 1
2018-03-14T18:01:18.159524: step 1753, loss 0.00939023, acc 1
2018-03-14T18:01:18.948805: step 1754, loss 0.007901, acc 1
2018-03-14T18:01:19.175008: step 1755, loss 0.0126815, acc 1
2018-03-14T18:01:19.964950: step 1756, loss 0.00453138, acc 1
2018-03-14T18:01:20.758267: step 1757, loss 0.0081602, acc 1
2018-03-14T18:01:21.563203: step 1758, loss 0.00766024, acc 1
2018-03-14T18:01:22.357426: step 1759, loss 0.0120483, acc 1
2018-03-14T18:01:23.153474: step 1760, loss 0.00880558, acc 1
2018-03-14T18:01:23.949432: step 1761, loss 0.0105348, acc 1
2018-03-14T18:01:24.741877: step 1762, loss 0.00496223, acc 1
2018-03-14T18:01:25.533518: step 1763, loss 0.00691213, acc 1
2018-03-14T18:01:26.325425: step 1764, loss 0.00702871, acc 1
2018-03-14T18:01:27.113893: step 1765, loss 0.0054987, acc 1
2018-03-14T18:01:27.904027: step 1766, loss 0.0114954, acc 1
2018-03-14T18:01:28.697820: step 1767, loss 0.00773252, acc 1
2018-03-14T18:01:29.495194: step 1768, loss 0.00454535, acc 1
2018-03-14T18:01:30.280111: step 1769, loss 0.0146627, acc 1
2018-03-14T18:01:31.087548: step 1770, loss 0.00731494, acc 1
2018-03-14T18:01:31.875012: step 1771, loss 0.00702246, acc 1
2018-03-14T18:01:32.671185: step 1772, loss 0.0105382, acc 1
2018-03-14T18:01:33.456996: step 1773, loss 0.00709832, acc 1
2018-03-14T18:01:34.274988: step 1774, loss 0.0168468, acc 1
2018-03-14T18:01:35.063986: step 1775, loss 0.0102295, acc 1
2018-03-14T18:01:35.870813: step 1776, loss 0.00580346, acc 1
2018-03-14T18:01:36.661610: step 1777, loss 0.0147105, acc 1
2018-03-14T18:01:37.451965: step 1778, loss 0.00997953, acc 1
2018-03-14T18:01:38.257218: step 1779, loss 0.00817969, acc 1
2018-03-14T18:01:39.054384: step 1780, loss 0.00771736, acc 1
2018-03-14T18:01:39.848159: step 1781, loss 0.00342657, acc 1
2018-03-14T18:01:40.067490: step 1782, loss 0.00586689, acc 1
2018-03-14T18:01:40.862193: step 1783, loss 0.00981432, acc 1
2018-03-14T18:01:41.658032: step 1784, loss 0.00876627, acc 1
2018-03-14T18:01:42.464786: step 1785, loss 0.00804547, acc 1
2018-03-14T18:01:43.253112: step 1786, loss 0.025887, acc 0.984375
2018-03-14T18:01:44.050987: step 1787, loss 0.00906267, acc 1
2018-03-14T18:01:44.848852: step 1788, loss 0.0202776, acc 1
2018-03-14T18:01:45.640107: step 1789, loss 0.0151715, acc 1
2018-03-14T18:01:46.436737: step 1790, loss 0.0219199, acc 1
2018-03-14T18:01:47.230634: step 1791, loss 0.00756419, acc 1
2018-03-14T18:01:48.024032: step 1792, loss 0.0107693, acc 1
2018-03-14T18:01:48.826416: step 1793, loss 0.00832126, acc 1
2018-03-14T18:01:49.630268: step 1794, loss 0.0093554, acc 1
2018-03-14T18:01:50.434879: step 1795, loss 0.0104611, acc 1
2018-03-14T18:01:51.234455: step 1796, loss 0.0101989, acc 1
2018-03-14T18:01:52.026149: step 1797, loss 0.00682488, acc 1
2018-03-14T18:01:52.818054: step 1798, loss 0.00950594, acc 1
2018-03-14T18:01:53.614059: step 1799, loss 0.00718276, acc 1
2018-03-14T18:01:54.419156: step 1800, loss 0.0113806, acc 1

Evaluation:
2018-03-14T18:01:55.963682: step 1800, loss 0.357866, acc 0.878282

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-1800

2018-03-14T18:01:56.868299: step 1801, loss 0.00622798, acc 1
2018-03-14T18:01:57.693319: step 1802, loss 0.0134835, acc 1
2018-03-14T18:01:58.506876: step 1803, loss 0.00674228, acc 1
2018-03-14T18:01:59.316150: step 1804, loss 0.00491287, acc 1
2018-03-14T18:02:00.185677: step 1805, loss 0.00478309, acc 1
2018-03-14T18:02:01.013727: step 1806, loss 0.0132212, acc 1
2018-03-14T18:02:01.811833: step 1807, loss 0.0254243, acc 1
2018-03-14T18:02:02.603566: step 1808, loss 0.0339498, acc 0.984375
2018-03-14T18:02:02.820632: step 1809, loss 0.0373684, acc 1
2018-03-14T18:02:03.610643: step 1810, loss 0.0137526, acc 1
2018-03-14T18:02:04.410919: step 1811, loss 0.00492095, acc 1
2018-03-14T18:02:05.207624: step 1812, loss 0.00746518, acc 1
2018-03-14T18:02:06.006120: step 1813, loss 0.00967733, acc 1
2018-03-14T18:02:06.804634: step 1814, loss 0.0060363, acc 1
2018-03-14T18:02:07.606443: step 1815, loss 0.00975086, acc 1
2018-03-14T18:02:08.407385: step 1816, loss 0.00338042, acc 1
2018-03-14T18:02:09.192844: step 1817, loss 0.00763078, acc 1
2018-03-14T18:02:09.992071: step 1818, loss 0.00557321, acc 1
2018-03-14T18:02:10.789517: step 1819, loss 0.00813064, acc 1
2018-03-14T18:02:11.582378: step 1820, loss 0.0101199, acc 1
2018-03-14T18:02:12.373809: step 1821, loss 0.00942443, acc 1
2018-03-14T18:02:13.172053: step 1822, loss 0.00755762, acc 1
2018-03-14T18:02:13.964998: step 1823, loss 0.00955894, acc 1
2018-03-14T18:02:14.761771: step 1824, loss 0.0108022, acc 1
2018-03-14T18:02:15.568530: step 1825, loss 0.0131591, acc 1
2018-03-14T18:02:16.366437: step 1826, loss 0.00743482, acc 1
2018-03-14T18:02:17.158624: step 1827, loss 0.0101722, acc 1
2018-03-14T18:02:17.964064: step 1828, loss 0.00722741, acc 1
2018-03-14T18:02:18.751853: step 1829, loss 0.00347415, acc 1
2018-03-14T18:02:19.550971: step 1830, loss 0.0231177, acc 0.984375
2018-03-14T18:02:20.350200: step 1831, loss 0.0202275, acc 1
2018-03-14T18:02:21.140245: step 1832, loss 0.0112031, acc 1
2018-03-14T18:02:21.936153: step 1833, loss 0.00750003, acc 1
2018-03-14T18:02:22.738606: step 1834, loss 0.00972698, acc 1
2018-03-14T18:02:23.532862: step 1835, loss 0.0131715, acc 1
2018-03-14T18:02:23.750495: step 1836, loss 0.00939713, acc 1
2018-03-14T18:02:24.556423: step 1837, loss 0.00896444, acc 1
2018-03-14T18:02:25.345729: step 1838, loss 0.00770741, acc 1
2018-03-14T18:02:26.145290: step 1839, loss 0.00555041, acc 1
2018-03-14T18:02:26.942776: step 1840, loss 0.0258932, acc 0.984375
2018-03-14T18:02:27.739146: step 1841, loss 0.00789608, acc 1
2018-03-14T18:02:28.542212: step 1842, loss 0.0122837, acc 1
2018-03-14T18:02:29.827094: step 1843, loss 0.00966955, acc 1
2018-03-14T18:02:30.616925: step 1844, loss 0.00727524, acc 1
2018-03-14T18:02:31.414092: step 1845, loss 0.0069389, acc 1
2018-03-14T18:02:32.217798: step 1846, loss 0.00816973, acc 1
2018-03-14T18:02:33.013248: step 1847, loss 0.00850672, acc 1
2018-03-14T18:02:33.803589: step 1848, loss 0.0119821, acc 1
2018-03-14T18:02:34.601602: step 1849, loss 0.00543994, acc 1
2018-03-14T18:02:35.394026: step 1850, loss 0.005787, acc 1
2018-03-14T18:02:36.184345: step 1851, loss 0.00562397, acc 1
2018-03-14T18:02:36.991505: step 1852, loss 0.00518855, acc 1
2018-03-14T18:02:37.795799: step 1853, loss 0.00615702, acc 1
2018-03-14T18:02:38.585810: step 1854, loss 0.00643885, acc 1
2018-03-14T18:02:39.379900: step 1855, loss 0.00700702, acc 1
2018-03-14T18:02:40.178683: step 1856, loss 0.0064184, acc 1
2018-03-14T18:02:40.967257: step 1857, loss 0.00871932, acc 1
2018-03-14T18:02:41.768519: step 1858, loss 0.00650531, acc 1
2018-03-14T18:02:42.556295: step 1859, loss 0.00738876, acc 1
2018-03-14T18:02:43.343993: step 1860, loss 0.0219083, acc 0.984375
2018-03-14T18:02:44.142484: step 1861, loss 0.013023, acc 1
2018-03-14T18:02:44.939954: step 1862, loss 0.0063746, acc 1
2018-03-14T18:02:45.157437: step 1863, loss 0.00161467, acc 1
2018-03-14T18:02:45.952166: step 1864, loss 0.00375031, acc 1
2018-03-14T18:02:46.747502: step 1865, loss 0.00374245, acc 1
2018-03-14T18:02:47.537139: step 1866, loss 0.0110239, acc 1
2018-03-14T18:02:48.331906: step 1867, loss 0.00618542, acc 1
2018-03-14T18:02:49.127401: step 1868, loss 0.00989903, acc 1
2018-03-14T18:02:49.926693: step 1869, loss 0.0054391, acc 1
2018-03-14T18:02:50.720367: step 1870, loss 0.00922606, acc 1
2018-03-14T18:02:51.508289: step 1871, loss 0.00851359, acc 1
2018-03-14T18:02:52.300089: step 1872, loss 0.00871574, acc 1
2018-03-14T18:02:53.098505: step 1873, loss 0.00820794, acc 1
2018-03-14T18:02:53.892787: step 1874, loss 0.00415468, acc 1
2018-03-14T18:02:54.680203: step 1875, loss 0.00436088, acc 1
2018-03-14T18:02:55.463203: step 1876, loss 0.00420284, acc 1
2018-03-14T18:02:56.254251: step 1877, loss 0.0043496, acc 1
2018-03-14T18:02:57.049947: step 1878, loss 0.00604116, acc 1
2018-03-14T18:02:57.837221: step 1879, loss 0.00604456, acc 1
2018-03-14T18:02:58.635993: step 1880, loss 0.01042, acc 1
2018-03-14T18:02:59.423183: step 1881, loss 0.00779965, acc 1
2018-03-14T18:03:00.220667: step 1882, loss 0.00565976, acc 1
2018-03-14T18:03:01.023036: step 1883, loss 0.00554219, acc 1
2018-03-14T18:03:01.816703: step 1884, loss 0.0121186, acc 1
2018-03-14T18:03:02.612044: step 1885, loss 0.00753124, acc 1
2018-03-14T18:03:03.401246: step 1886, loss 0.00767078, acc 1
2018-03-14T18:03:04.208989: step 1887, loss 0.00507463, acc 1
2018-03-14T18:03:05.000760: step 1888, loss 0.0146101, acc 1
2018-03-14T18:03:05.801051: step 1889, loss 0.0119699, acc 1
2018-03-14T18:03:06.028972: step 1890, loss 0.04361, acc 1
2018-03-14T18:03:06.818575: step 1891, loss 0.00418102, acc 1
2018-03-14T18:03:07.622049: step 1892, loss 0.0122856, acc 1
2018-03-14T18:03:08.423757: step 1893, loss 0.00508209, acc 1
2018-03-14T18:03:09.213730: step 1894, loss 0.0113433, acc 1
2018-03-14T18:03:10.006314: step 1895, loss 0.00510655, acc 1
2018-03-14T18:03:10.800777: step 1896, loss 0.0113471, acc 1
2018-03-14T18:03:11.596325: step 1897, loss 0.0102687, acc 1
2018-03-14T18:03:12.388600: step 1898, loss 0.00439792, acc 1
2018-03-14T18:03:13.187964: step 1899, loss 0.012321, acc 1
2018-03-14T18:03:13.986605: step 1900, loss 0.0116633, acc 1

Evaluation:
2018-03-14T18:03:15.492493: step 1900, loss 0.344191, acc 0.883055

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-1900

2018-03-14T18:03:16.367381: step 1901, loss 0.00569986, acc 1
2018-03-14T18:03:17.186129: step 1902, loss 0.006346, acc 1
2018-03-14T18:03:17.989010: step 1903, loss 0.00778018, acc 1
2018-03-14T18:03:18.778713: step 1904, loss 0.00771627, acc 1
2018-03-14T18:03:19.578380: step 1905, loss 0.0172824, acc 1
2018-03-14T18:03:20.374096: step 1906, loss 0.00397632, acc 1
2018-03-14T18:03:21.164792: step 1907, loss 0.00402384, acc 1
2018-03-14T18:03:21.963039: step 1908, loss 0.00923155, acc 1
2018-03-14T18:03:22.756854: step 1909, loss 0.00536059, acc 1
2018-03-14T18:03:23.546533: step 1910, loss 0.00781312, acc 1
2018-03-14T18:03:24.332110: step 1911, loss 0.0086396, acc 1
2018-03-14T18:03:25.123286: step 1912, loss 0.0051238, acc 1
2018-03-14T18:03:25.913289: step 1913, loss 0.00985351, acc 1
2018-03-14T18:03:26.704122: step 1914, loss 0.00593527, acc 1
2018-03-14T18:03:27.492872: step 1915, loss 0.00838841, acc 1
2018-03-14T18:03:28.282449: step 1916, loss 0.00566154, acc 1
2018-03-14T18:03:28.504477: step 1917, loss 0.0073134, acc 1
2018-03-14T18:03:29.297937: step 1918, loss 0.00787975, acc 1
2018-03-14T18:03:30.095194: step 1919, loss 0.0058421, acc 1
2018-03-14T18:03:30.879940: step 1920, loss 0.00359461, acc 1
2018-03-14T18:03:31.674480: step 1921, loss 0.00618786, acc 1
2018-03-14T18:03:32.474137: step 1922, loss 0.0186981, acc 1
2018-03-14T18:03:33.265790: step 1923, loss 0.0204361, acc 1
2018-03-14T18:03:34.061157: step 1924, loss 0.00551013, acc 1
2018-03-14T18:03:34.861609: step 1925, loss 0.00445636, acc 1
2018-03-14T18:03:35.662077: step 1926, loss 0.00905263, acc 1
2018-03-14T18:03:36.460863: step 1927, loss 0.0066731, acc 1
2018-03-14T18:03:37.248631: step 1928, loss 0.00468355, acc 1
2018-03-14T18:03:38.041704: step 1929, loss 0.00692175, acc 1
2018-03-14T18:03:38.838355: step 1930, loss 0.00461973, acc 1
2018-03-14T18:03:39.640246: step 1931, loss 0.00956729, acc 1
2018-03-14T18:03:40.432424: step 1932, loss 0.00758986, acc 1
2018-03-14T18:03:41.226058: step 1933, loss 0.0176388, acc 1
2018-03-14T18:03:42.025375: step 1934, loss 0.00747336, acc 1
2018-03-14T18:03:42.841496: step 1935, loss 0.00986567, acc 1
2018-03-14T18:03:43.631967: step 1936, loss 0.00397463, acc 1
2018-03-14T18:03:44.422436: step 1937, loss 0.00585985, acc 1
2018-03-14T18:03:45.219929: step 1938, loss 0.00893967, acc 1
2018-03-14T18:03:46.017817: step 1939, loss 0.00342114, acc 1
2018-03-14T18:03:46.821420: step 1940, loss 0.0207517, acc 1
2018-03-14T18:03:47.618393: step 1941, loss 0.0104465, acc 1
2018-03-14T18:03:48.412602: step 1942, loss 0.0197874, acc 1
2018-03-14T18:03:49.211278: step 1943, loss 0.00354861, acc 1
2018-03-14T18:03:49.429258: step 1944, loss 0.00587916, acc 1
2018-03-14T18:03:50.217815: step 1945, loss 0.0031834, acc 1
2018-03-14T18:03:51.020870: step 1946, loss 0.00989001, acc 1
2018-03-14T18:03:51.816727: step 1947, loss 0.0066742, acc 1
2018-03-14T18:03:52.615010: step 1948, loss 0.00829445, acc 1
2018-03-14T18:03:53.423569: step 1949, loss 0.00483708, acc 1
2018-03-14T18:03:54.215960: step 1950, loss 0.00791394, acc 1
2018-03-14T18:03:55.019461: step 1951, loss 0.00609767, acc 1
2018-03-14T18:03:55.814268: step 1952, loss 0.0056961, acc 1
2018-03-14T18:03:56.604325: step 1953, loss 0.00928318, acc 1
2018-03-14T18:03:57.405526: step 1954, loss 0.00822998, acc 1
2018-03-14T18:03:58.206661: step 1955, loss 0.0050537, acc 1
2018-03-14T18:03:59.002979: step 1956, loss 0.0133994, acc 1
2018-03-14T18:03:59.797665: step 1957, loss 0.00749433, acc 1
2018-03-14T18:04:00.603888: step 1958, loss 0.00699067, acc 1
2018-03-14T18:04:01.395885: step 1959, loss 0.0111829, acc 1
2018-03-14T18:04:02.195042: step 1960, loss 0.00546723, acc 1
2018-03-14T18:04:02.985272: step 1961, loss 0.00460153, acc 1
2018-03-14T18:04:03.767103: step 1962, loss 0.0135778, acc 1
2018-03-14T18:04:04.565158: step 1963, loss 0.00748066, acc 1
2018-03-14T18:04:05.358341: step 1964, loss 0.00506292, acc 1
2018-03-14T18:04:06.145689: step 1965, loss 0.00962818, acc 1
2018-03-14T18:04:06.935795: step 1966, loss 0.00438205, acc 1
2018-03-14T18:04:07.734880: step 1967, loss 0.00926863, acc 1
2018-03-14T18:04:08.544629: step 1968, loss 0.00900386, acc 1
2018-03-14T18:04:09.342028: step 1969, loss 0.00841253, acc 1
2018-03-14T18:04:10.138022: step 1970, loss 0.00745536, acc 1
2018-03-14T18:04:10.358487: step 1971, loss 0.0236476, acc 1
2018-03-14T18:04:11.154435: step 1972, loss 0.00705811, acc 1
2018-03-14T18:04:11.948466: step 1973, loss 0.0107401, acc 1
2018-03-14T18:04:12.742007: step 1974, loss 0.00496957, acc 1
2018-03-14T18:04:13.537915: step 1975, loss 0.010198, acc 1
2018-03-14T18:04:14.324152: step 1976, loss 0.00634762, acc 1
2018-03-14T18:04:15.116449: step 1977, loss 0.00804457, acc 1
2018-03-14T18:04:15.912097: step 1978, loss 0.00448542, acc 1
2018-03-14T18:04:16.709690: step 1979, loss 0.00406349, acc 1
2018-03-14T18:04:17.507741: step 1980, loss 0.00465575, acc 1
2018-03-14T18:04:18.296882: step 1981, loss 0.0127331, acc 1
2018-03-14T18:04:19.094566: step 1982, loss 0.00798577, acc 1
2018-03-14T18:04:19.883861: step 1983, loss 0.00725075, acc 1
2018-03-14T18:04:20.675679: step 1984, loss 0.00785704, acc 1
2018-03-14T18:04:21.471461: step 1985, loss 0.00518959, acc 1
2018-03-14T18:04:22.277033: step 1986, loss 0.010773, acc 1
2018-03-14T18:04:23.076136: step 1987, loss 0.00518237, acc 1
2018-03-14T18:04:23.870487: step 1988, loss 0.0188271, acc 1
2018-03-14T18:04:24.662450: step 1989, loss 0.0101743, acc 1
2018-03-14T18:04:25.445300: step 1990, loss 0.0063951, acc 1
2018-03-14T18:04:26.240797: step 1991, loss 0.0129834, acc 1
2018-03-14T18:04:27.029779: step 1992, loss 0.0115923, acc 1
2018-03-14T18:04:27.827341: step 1993, loss 0.0103866, acc 1
2018-03-14T18:04:28.625876: step 1994, loss 0.00588958, acc 1
2018-03-14T18:04:29.422918: step 1995, loss 0.00429876, acc 1
2018-03-14T18:04:30.213806: step 1996, loss 0.00545721, acc 1
2018-03-14T18:04:31.010200: step 1997, loss 0.00566422, acc 1
2018-03-14T18:04:31.235685: step 1998, loss 0.00138661, acc 1
2018-03-14T18:04:32.026626: step 1999, loss 0.0145514, acc 1
2018-03-14T18:04:32.818185: step 2000, loss 0.00510912, acc 1

Evaluation:
2018-03-14T18:04:34.283404: step 2000, loss 0.343256, acc 0.887828

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-2000

2018-03-14T18:04:35.175022: step 2001, loss 0.00386515, acc 1
2018-03-14T18:04:35.982996: step 2002, loss 0.00451125, acc 1
2018-03-14T18:04:36.774932: step 2003, loss 0.00493395, acc 1
2018-03-14T18:04:37.569408: step 2004, loss 0.00700259, acc 1
2018-03-14T18:04:38.358589: step 2005, loss 0.00614003, acc 1
2018-03-14T18:04:39.160288: step 2006, loss 0.00565519, acc 1
2018-03-14T18:04:39.949803: step 2007, loss 0.00577389, acc 1
2018-03-14T18:04:40.750866: step 2008, loss 0.00911497, acc 1
2018-03-14T18:04:41.542629: step 2009, loss 0.00626436, acc 1
2018-03-14T18:04:42.340471: step 2010, loss 0.0422147, acc 0.984375
2018-03-14T18:04:43.143656: step 2011, loss 0.0149746, acc 1
2018-03-14T18:04:43.934832: step 2012, loss 0.00823334, acc 1
2018-03-14T18:04:44.723744: step 2013, loss 0.00730385, acc 1
2018-03-14T18:04:45.523145: step 2014, loss 0.00789266, acc 1
2018-03-14T18:04:46.326804: step 2015, loss 0.00223716, acc 1
2018-03-14T18:04:47.124264: step 2016, loss 0.00486811, acc 1
2018-03-14T18:04:47.922063: step 2017, loss 0.0055487, acc 1
2018-03-14T18:04:48.722949: step 2018, loss 0.00603393, acc 1
2018-03-14T18:04:49.516232: step 2019, loss 0.00617185, acc 1
2018-03-14T18:04:50.323245: step 2020, loss 0.0039971, acc 1
2018-03-14T18:04:51.122701: step 2021, loss 0.011953, acc 1
2018-03-14T18:04:51.919074: step 2022, loss 0.012375, acc 1
2018-03-14T18:04:52.707990: step 2023, loss 0.00457382, acc 1
2018-03-14T18:04:53.507003: step 2024, loss 0.00971745, acc 1
2018-03-14T18:04:53.726533: step 2025, loss 0.00265932, acc 1
2018-03-14T18:04:54.528876: step 2026, loss 0.00442995, acc 1
2018-03-14T18:04:55.331260: step 2027, loss 0.0107329, acc 1
2018-03-14T18:04:56.123026: step 2028, loss 0.012043, acc 1
2018-03-14T18:04:56.919549: step 2029, loss 0.00346085, acc 1
2018-03-14T18:04:57.710077: step 2030, loss 0.00893445, acc 1
2018-03-14T18:04:58.500847: step 2031, loss 0.00200378, acc 1
2018-03-14T18:04:59.300618: step 2032, loss 0.00815198, acc 1
2018-03-14T18:05:00.122356: step 2033, loss 0.00564958, acc 1
2018-03-14T18:05:00.919268: step 2034, loss 0.010553, acc 1
2018-03-14T18:05:01.715824: step 2035, loss 0.00608344, acc 1
2018-03-14T18:05:02.501868: step 2036, loss 0.00628977, acc 1
2018-03-14T18:05:03.302321: step 2037, loss 0.0305412, acc 0.984375
2018-03-14T18:05:04.102723: step 2038, loss 0.00822699, acc 1
2018-03-14T18:05:04.903479: step 2039, loss 0.00784191, acc 1
2018-03-14T18:05:05.701715: step 2040, loss 0.01892, acc 1
2018-03-14T18:05:06.502339: step 2041, loss 0.00621874, acc 1
2018-03-14T18:05:07.291491: step 2042, loss 0.00515167, acc 1
2018-03-14T18:05:08.086670: step 2043, loss 0.00650603, acc 1
2018-03-14T18:05:08.881928: step 2044, loss 0.00572615, acc 1
2018-03-14T18:05:09.674740: step 2045, loss 0.0150401, acc 1
2018-03-14T18:05:10.468185: step 2046, loss 0.00645979, acc 1
2018-03-14T18:05:11.254644: step 2047, loss 0.00550727, acc 1
2018-03-14T18:05:12.044332: step 2048, loss 0.00746314, acc 1
2018-03-14T18:05:12.841333: step 2049, loss 0.00590485, acc 1
2018-03-14T18:05:13.638387: step 2050, loss 0.00585013, acc 1
2018-03-14T18:05:14.430369: step 2051, loss 0.00714682, acc 1
2018-03-14T18:05:14.648993: step 2052, loss 0.0105642, acc 1
2018-03-14T18:05:15.442393: step 2053, loss 0.00626639, acc 1
2018-03-14T18:05:16.233313: step 2054, loss 0.00596048, acc 1
2018-03-14T18:05:17.023931: step 2055, loss 0.0053433, acc 1
2018-03-14T18:05:17.817051: step 2056, loss 0.0295698, acc 0.984375
2018-03-14T18:05:18.620481: step 2057, loss 0.00762896, acc 1
2018-03-14T18:05:19.418432: step 2058, loss 0.00598274, acc 1
2018-03-14T18:05:20.224891: step 2059, loss 0.00568188, acc 1
2018-03-14T18:05:21.029628: step 2060, loss 0.0120867, acc 1
2018-03-14T18:05:21.820901: step 2061, loss 0.00454513, acc 1
2018-03-14T18:05:22.620891: step 2062, loss 0.00649754, acc 1
2018-03-14T18:05:23.413719: step 2063, loss 0.00495665, acc 1
2018-03-14T18:05:24.207298: step 2064, loss 0.0036114, acc 1
2018-03-14T18:05:25.000641: step 2065, loss 0.00336381, acc 1
2018-03-14T18:05:25.807908: step 2066, loss 0.0500281, acc 0.984375
2018-03-14T18:05:26.600696: step 2067, loss 0.0102561, acc 1
2018-03-14T18:05:27.396728: step 2068, loss 0.0101185, acc 1
2018-03-14T18:05:28.193429: step 2069, loss 0.00436872, acc 1
2018-03-14T18:05:28.990658: step 2070, loss 0.00743597, acc 1
2018-03-14T18:05:29.787753: step 2071, loss 0.00682861, acc 1
2018-03-14T18:05:30.585316: step 2072, loss 0.00838321, acc 1
2018-03-14T18:05:31.371963: step 2073, loss 0.00844731, acc 1
2018-03-14T18:05:32.171181: step 2074, loss 0.00773182, acc 1
2018-03-14T18:05:32.969917: step 2075, loss 0.00603379, acc 1
2018-03-14T18:05:33.760054: step 2076, loss 0.00490664, acc 1
2018-03-14T18:05:34.562274: step 2077, loss 0.0136248, acc 1
2018-03-14T18:05:35.359450: step 2078, loss 0.00533343, acc 1
2018-03-14T18:05:35.583068: step 2079, loss 0.0052935, acc 1
2018-03-14T18:05:36.375154: step 2080, loss 0.0128589, acc 1
2018-03-14T18:05:37.167559: step 2081, loss 0.0154889, acc 1
2018-03-14T18:05:37.962704: step 2082, loss 0.0086718, acc 1
2018-03-14T18:05:38.756542: step 2083, loss 0.00365065, acc 1
2018-03-14T18:05:39.563063: step 2084, loss 0.0156769, acc 1
2018-03-14T18:05:40.356864: step 2085, loss 0.00552671, acc 1
2018-03-14T18:05:41.149824: step 2086, loss 0.0125875, acc 1
2018-03-14T18:05:41.956374: step 2087, loss 0.00820757, acc 1
2018-03-14T18:05:42.751806: step 2088, loss 0.00776185, acc 1
2018-03-14T18:05:43.552185: step 2089, loss 0.00469454, acc 1
2018-03-14T18:05:44.362467: step 2090, loss 0.0035028, acc 1
2018-03-14T18:05:45.148590: step 2091, loss 0.0077478, acc 1
2018-03-14T18:05:45.952895: step 2092, loss 0.0120716, acc 1
2018-03-14T18:05:46.753258: step 2093, loss 0.00894209, acc 1
2018-03-14T18:05:47.546923: step 2094, loss 0.008288, acc 1
2018-03-14T18:05:48.342282: step 2095, loss 0.00915128, acc 1
2018-03-14T18:05:49.142335: step 2096, loss 0.00722131, acc 1
2018-03-14T18:05:49.929442: step 2097, loss 0.00623435, acc 1
2018-03-14T18:05:50.722113: step 2098, loss 0.00488778, acc 1
2018-03-14T18:05:51.517555: step 2099, loss 0.0058447, acc 1
2018-03-14T18:05:52.308420: step 2100, loss 0.00380606, acc 1

Evaluation:
2018-03-14T18:05:53.796332: step 2100, loss 0.348832, acc 0.887828

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-2100

2018-03-14T18:05:55.052524: step 2101, loss 0.00610418, acc 1
2018-03-14T18:05:55.847673: step 2102, loss 0.0106153, acc 1
2018-03-14T18:05:56.638052: step 2103, loss 0.00430019, acc 1
2018-03-14T18:05:57.432015: step 2104, loss 0.00320851, acc 1
2018-03-14T18:05:58.222505: step 2105, loss 0.00607057, acc 1
2018-03-14T18:05:58.444292: step 2106, loss 0.00365327, acc 1
2018-03-14T18:05:59.237429: step 2107, loss 0.00608769, acc 1
2018-03-14T18:06:00.037825: step 2108, loss 0.0102914, acc 1
2018-03-14T18:06:00.833206: step 2109, loss 0.00342255, acc 1
2018-03-14T18:06:01.629381: step 2110, loss 0.00612969, acc 1
2018-03-14T18:06:02.425168: step 2111, loss 0.00366545, acc 1
2018-03-14T18:06:03.220406: step 2112, loss 0.0105211, acc 1
2018-03-14T18:06:04.027973: step 2113, loss 0.00337293, acc 1
2018-03-14T18:06:04.816707: step 2114, loss 0.00478215, acc 1
2018-03-14T18:06:05.608264: step 2115, loss 0.00912201, acc 1
2018-03-14T18:06:06.413528: step 2116, loss 0.00644238, acc 1
2018-03-14T18:06:07.221866: step 2117, loss 0.00533047, acc 1
2018-03-14T18:06:08.024803: step 2118, loss 0.00580902, acc 1
2018-03-14T18:06:08.819228: step 2119, loss 0.0105108, acc 1
2018-03-14T18:06:09.612093: step 2120, loss 0.0127238, acc 1
2018-03-14T18:06:10.403993: step 2121, loss 0.00309821, acc 1
2018-03-14T18:06:11.201035: step 2122, loss 0.00580199, acc 1
2018-03-14T18:06:12.001247: step 2123, loss 0.00563983, acc 1
2018-03-14T18:06:12.797213: step 2124, loss 0.0048231, acc 1
2018-03-14T18:06:13.590662: step 2125, loss 0.0158858, acc 1
2018-03-14T18:06:14.389390: step 2126, loss 0.00292999, acc 1
2018-03-14T18:06:15.178963: step 2127, loss 0.0071997, acc 1
2018-03-14T18:06:15.986465: step 2128, loss 0.00296154, acc 1
2018-03-14T18:06:16.776718: step 2129, loss 0.00302121, acc 1
2018-03-14T18:06:17.573817: step 2130, loss 0.00741938, acc 1
2018-03-14T18:06:18.364637: step 2131, loss 0.0069093, acc 1
2018-03-14T18:06:19.161891: step 2132, loss 0.00365586, acc 1
2018-03-14T18:06:19.378691: step 2133, loss 0.00756095, acc 1
2018-03-14T18:06:20.170725: step 2134, loss 0.00669194, acc 1
2018-03-14T18:06:20.969370: step 2135, loss 0.00497132, acc 1
2018-03-14T18:06:21.754207: step 2136, loss 0.00272137, acc 1
2018-03-14T18:06:22.546829: step 2137, loss 0.00552632, acc 1
2018-03-14T18:06:23.344849: step 2138, loss 0.00739509, acc 1
2018-03-14T18:06:24.137719: step 2139, loss 0.00781491, acc 1
2018-03-14T18:06:24.934125: step 2140, loss 0.00621665, acc 1
2018-03-14T18:06:25.722284: step 2141, loss 0.00830905, acc 1
2018-03-14T18:06:26.527621: step 2142, loss 0.00959205, acc 1
2018-03-14T18:06:27.319004: step 2143, loss 0.0121843, acc 1
2018-03-14T18:06:28.111092: step 2144, loss 0.00516362, acc 1
2018-03-14T18:06:28.908052: step 2145, loss 0.00984391, acc 1
2018-03-14T18:06:29.702479: step 2146, loss 0.0036739, acc 1
2018-03-14T18:06:30.497567: step 2147, loss 0.00561923, acc 1
2018-03-14T18:06:31.294775: step 2148, loss 0.00674441, acc 1
2018-03-14T18:06:32.085259: step 2149, loss 0.00623757, acc 1
2018-03-14T18:06:32.880158: step 2150, loss 0.00523585, acc 1
2018-03-14T18:06:33.683629: step 2151, loss 0.00457876, acc 1
2018-03-14T18:06:34.478984: step 2152, loss 0.0130072, acc 1
2018-03-14T18:06:35.267470: step 2153, loss 0.00344652, acc 1
2018-03-14T18:06:36.064608: step 2154, loss 0.00648229, acc 1
2018-03-14T18:06:36.864826: step 2155, loss 0.00551121, acc 1
2018-03-14T18:06:37.653899: step 2156, loss 0.0062992, acc 1
2018-03-14T18:06:38.452467: step 2157, loss 0.0158107, acc 1
2018-03-14T18:06:39.240986: step 2158, loss 0.00770255, acc 1
2018-03-14T18:06:40.037732: step 2159, loss 0.00770705, acc 1
2018-03-14T18:06:40.257559: step 2160, loss 0.00389418, acc 1
2018-03-14T18:06:41.054527: step 2161, loss 0.0040104, acc 1
2018-03-14T18:06:41.839026: step 2162, loss 0.0119968, acc 1
2018-03-14T18:06:42.633684: step 2163, loss 0.00222032, acc 1
2018-03-14T18:06:43.430072: step 2164, loss 0.00589691, acc 1
2018-03-14T18:06:44.235228: step 2165, loss 0.0143301, acc 0.984375
2018-03-14T18:06:45.023515: step 2166, loss 0.00726043, acc 1
2018-03-14T18:06:45.816435: step 2167, loss 0.0109771, acc 1
2018-03-14T18:06:46.606655: step 2168, loss 0.00587117, acc 1
2018-03-14T18:06:47.414220: step 2169, loss 0.00531817, acc 1
2018-03-14T18:06:48.215832: step 2170, loss 0.00282798, acc 1
2018-03-14T18:06:49.014421: step 2171, loss 0.00934679, acc 1
2018-03-14T18:06:49.822937: step 2172, loss 0.00530625, acc 1
2018-03-14T18:06:50.622045: step 2173, loss 0.00638845, acc 1
2018-03-14T18:06:51.419829: step 2174, loss 0.00760901, acc 1
2018-03-14T18:06:52.217624: step 2175, loss 0.00472068, acc 1
2018-03-14T18:06:53.009590: step 2176, loss 0.0121022, acc 1
2018-03-14T18:06:53.812457: step 2177, loss 0.00527642, acc 1
2018-03-14T18:06:54.669775: step 2178, loss 0.00744783, acc 1
2018-03-14T18:06:55.465182: step 2179, loss 0.00666587, acc 1
2018-03-14T18:06:56.272280: step 2180, loss 0.00343995, acc 1
2018-03-14T18:06:57.066836: step 2181, loss 0.00375174, acc 1
2018-03-14T18:06:57.862222: step 2182, loss 0.00950377, acc 1
2018-03-14T18:06:58.661149: step 2183, loss 0.00498361, acc 1
2018-03-14T18:06:59.455399: step 2184, loss 0.00392718, acc 1
2018-03-14T18:07:00.251170: step 2185, loss 0.0151401, acc 1
2018-03-14T18:07:01.051850: step 2186, loss 0.00832269, acc 1
2018-03-14T18:07:01.267757: step 2187, loss 0.00125116, acc 1
2018-03-14T18:07:02.059847: step 2188, loss 0.00443547, acc 1
2018-03-14T18:07:02.854170: step 2189, loss 0.00463185, acc 1
2018-03-14T18:07:03.640551: step 2190, loss 0.00715785, acc 1
2018-03-14T18:07:04.426544: step 2191, loss 0.00780771, acc 1
2018-03-14T18:07:05.218083: step 2192, loss 0.00477438, acc 1
2018-03-14T18:07:06.011267: step 2193, loss 0.00422819, acc 1
2018-03-14T18:07:06.813417: step 2194, loss 0.00551338, acc 1
2018-03-14T18:07:07.610112: step 2195, loss 0.00742083, acc 1
2018-03-14T18:07:08.404599: step 2196, loss 0.00363626, acc 1
2018-03-14T18:07:09.200386: step 2197, loss 0.00478229, acc 1
2018-03-14T18:07:10.005885: step 2198, loss 0.00429028, acc 1
2018-03-14T18:07:10.797844: step 2199, loss 0.00297546, acc 1
2018-03-14T18:07:11.595534: step 2200, loss 0.0033755, acc 1

Evaluation:
2018-03-14T18:07:13.158911: step 2200, loss 0.355055, acc 0.880668

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-2200

2018-03-14T18:07:14.051377: step 2201, loss 0.0166968, acc 1
2018-03-14T18:07:14.847280: step 2202, loss 0.00418992, acc 1
2018-03-14T18:07:15.648878: step 2203, loss 0.00340795, acc 1
2018-03-14T18:07:16.440315: step 2204, loss 0.00798242, acc 1
2018-03-14T18:07:17.231311: step 2205, loss 0.00547614, acc 1
2018-03-14T18:07:18.022592: step 2206, loss 0.0122159, acc 1
2018-03-14T18:07:18.813855: step 2207, loss 0.00589695, acc 1
2018-03-14T18:07:19.615153: step 2208, loss 0.00520763, acc 1
2018-03-14T18:07:20.415703: step 2209, loss 0.00569073, acc 1
2018-03-14T18:07:21.209217: step 2210, loss 0.00511341, acc 1
2018-03-14T18:07:22.009625: step 2211, loss 0.00744097, acc 1
2018-03-14T18:07:22.799912: step 2212, loss 0.0035243, acc 1
2018-03-14T18:07:23.593557: step 2213, loss 0.0106182, acc 1
2018-03-14T18:07:23.811561: step 2214, loss 0.00180148, acc 1
2018-03-14T18:07:24.611094: step 2215, loss 0.0045583, acc 1
2018-03-14T18:07:25.404971: step 2216, loss 0.00374802, acc 1
2018-03-14T18:07:26.203013: step 2217, loss 0.00900909, acc 1
2018-03-14T18:07:26.995763: step 2218, loss 0.00327126, acc 1
2018-03-14T18:07:27.786524: step 2219, loss 0.00598732, acc 1
2018-03-14T18:07:28.576746: step 2220, loss 0.00631466, acc 1
2018-03-14T18:07:29.372369: step 2221, loss 0.00487737, acc 1
2018-03-14T18:07:30.171961: step 2222, loss 0.00796696, acc 1
2018-03-14T18:07:30.973040: step 2223, loss 0.00479365, acc 1
2018-03-14T18:07:31.774907: step 2224, loss 0.00249851, acc 1
2018-03-14T18:07:32.571985: step 2225, loss 0.00404056, acc 1
2018-03-14T18:07:33.372267: step 2226, loss 0.00543091, acc 1
2018-03-14T18:07:34.176961: step 2227, loss 0.0049958, acc 1
2018-03-14T18:07:34.975940: step 2228, loss 0.00605187, acc 1
2018-03-14T18:07:35.784589: step 2229, loss 0.00327862, acc 1
2018-03-14T18:07:36.580865: step 2230, loss 0.0122922, acc 1
2018-03-14T18:07:37.382439: step 2231, loss 0.00503864, acc 1
2018-03-14T18:07:38.176325: step 2232, loss 0.0193808, acc 0.984375
2018-03-14T18:07:38.972233: step 2233, loss 0.00782447, acc 1
2018-03-14T18:07:39.767427: step 2234, loss 0.00366071, acc 1
2018-03-14T18:07:40.557734: step 2235, loss 0.00450446, acc 1
2018-03-14T18:07:41.349887: step 2236, loss 0.0057994, acc 1
2018-03-14T18:07:42.145041: step 2237, loss 0.00290193, acc 1
2018-03-14T18:07:42.931928: step 2238, loss 0.00397738, acc 1
2018-03-14T18:07:43.730300: step 2239, loss 0.00185533, acc 1
2018-03-14T18:07:44.526724: step 2240, loss 0.00476793, acc 1
2018-03-14T18:07:44.755248: step 2241, loss 0.00380988, acc 1
2018-03-14T18:07:45.549690: step 2242, loss 0.00493586, acc 1
2018-03-14T18:07:46.347104: step 2243, loss 0.00816876, acc 1
2018-03-14T18:07:47.143123: step 2244, loss 0.00745187, acc 1
2018-03-14T18:07:47.949746: step 2245, loss 0.00197197, acc 1
2018-03-14T18:07:48.751740: step 2246, loss 0.00277833, acc 1
2018-03-14T18:07:49.544373: step 2247, loss 0.00437533, acc 1
2018-03-14T18:07:50.346279: step 2248, loss 0.00671031, acc 1
2018-03-14T18:07:51.138241: step 2249, loss 0.00835608, acc 1
2018-03-14T18:07:51.940943: step 2250, loss 0.00598594, acc 1
2018-03-14T18:07:52.736687: step 2251, loss 0.00639654, acc 1
2018-03-14T18:07:53.532189: step 2252, loss 0.010109, acc 1
2018-03-14T18:07:54.326990: step 2253, loss 0.00485771, acc 1
2018-03-14T18:07:55.132345: step 2254, loss 0.0112447, acc 1
2018-03-14T18:07:55.931509: step 2255, loss 0.00474234, acc 1
2018-03-14T18:07:56.724339: step 2256, loss 0.00703225, acc 1
2018-03-14T18:07:57.521724: step 2257, loss 0.0102405, acc 1
2018-03-14T18:07:58.314464: step 2258, loss 0.0282578, acc 0.984375
2018-03-14T18:07:59.113841: step 2259, loss 0.0105782, acc 1
2018-03-14T18:07:59.918265: step 2260, loss 0.00719523, acc 1
2018-03-14T18:08:00.707566: step 2261, loss 0.00682625, acc 1
2018-03-14T18:08:01.494584: step 2262, loss 0.0164251, acc 1
2018-03-14T18:08:02.290050: step 2263, loss 0.00729825, acc 1
2018-03-14T18:08:03.088313: step 2264, loss 0.00268431, acc 1
2018-03-14T18:08:03.881129: step 2265, loss 0.00547384, acc 1
2018-03-14T18:08:04.673162: step 2266, loss 0.00499007, acc 1
2018-03-14T18:08:05.466165: step 2267, loss 0.00540183, acc 1
2018-03-14T18:08:05.687265: step 2268, loss 0.0078448, acc 1
2018-03-14T18:08:06.484106: step 2269, loss 0.00240162, acc 1
2018-03-14T18:08:07.280698: step 2270, loss 0.00618194, acc 1
2018-03-14T18:08:08.069899: step 2271, loss 0.0150787, acc 1
2018-03-14T18:08:08.867802: step 2272, loss 0.0040563, acc 1
2018-03-14T18:08:09.661660: step 2273, loss 0.00358557, acc 1
2018-03-14T18:08:10.449681: step 2274, loss 0.00738661, acc 1
2018-03-14T18:08:11.250486: step 2275, loss 0.00351269, acc 1
2018-03-14T18:08:12.068619: step 2276, loss 0.00344318, acc 1
2018-03-14T18:08:12.886336: step 2277, loss 0.00632369, acc 1
2018-03-14T18:08:13.692057: step 2278, loss 0.00253478, acc 1
2018-03-14T18:08:14.497040: step 2279, loss 0.00387262, acc 1
2018-03-14T18:08:15.284242: step 2280, loss 0.00468801, acc 1
2018-03-14T18:08:16.093248: step 2281, loss 0.00946482, acc 1
2018-03-14T18:08:16.887493: step 2282, loss 0.00759894, acc 1
2018-03-14T18:08:17.680197: step 2283, loss 0.00554795, acc 1
2018-03-14T18:08:18.476856: step 2284, loss 0.00798998, acc 1
2018-03-14T18:08:19.266681: step 2285, loss 0.00562062, acc 1
2018-03-14T18:08:20.054395: step 2286, loss 0.00640035, acc 1
2018-03-14T18:08:20.849198: step 2287, loss 0.00373003, acc 1
2018-03-14T18:08:21.645728: step 2288, loss 0.0090661, acc 1
2018-03-14T18:08:22.439207: step 2289, loss 0.00549732, acc 1
2018-03-14T18:08:23.236065: step 2290, loss 0.0035924, acc 1
2018-03-14T18:08:24.031686: step 2291, loss 0.0120325, acc 1
2018-03-14T18:08:24.828471: step 2292, loss 0.00403283, acc 1
2018-03-14T18:08:25.619180: step 2293, loss 0.0127712, acc 1
2018-03-14T18:08:26.413753: step 2294, loss 0.00622554, acc 1
2018-03-14T18:08:26.632136: step 2295, loss 0.00368464, acc 1
2018-03-14T18:08:27.434889: step 2296, loss 0.00526452, acc 1
2018-03-14T18:08:28.229524: step 2297, loss 0.00713034, acc 1
2018-03-14T18:08:29.025483: step 2298, loss 0.00465155, acc 1
2018-03-14T18:08:29.830193: step 2299, loss 0.00761793, acc 1
2018-03-14T18:08:30.625404: step 2300, loss 0.00498739, acc 1

Evaluation:
2018-03-14T18:08:32.117014: step 2300, loss 0.345438, acc 0.885442

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-2300

2018-03-14T18:08:33.026792: step 2301, loss 0.00531854, acc 1
2018-03-14T18:08:33.821659: step 2302, loss 0.00286886, acc 1
2018-03-14T18:08:34.614270: step 2303, loss 0.00285506, acc 1
2018-03-14T18:08:35.409859: step 2304, loss 0.0029405, acc 1
2018-03-14T18:08:36.201786: step 2305, loss 0.0111619, acc 1
2018-03-14T18:08:36.993570: step 2306, loss 0.00605935, acc 1
2018-03-14T18:08:37.790219: step 2307, loss 0.00260621, acc 1
2018-03-14T18:08:38.579664: step 2308, loss 0.00230116, acc 1
2018-03-14T18:08:39.378213: step 2309, loss 0.0096877, acc 1
2018-03-14T18:08:40.173639: step 2310, loss 0.0148678, acc 0.984375
2018-03-14T18:08:40.971752: step 2311, loss 0.0146363, acc 1
2018-03-14T18:08:41.776367: step 2312, loss 0.0112499, acc 1
2018-03-14T18:08:42.574637: step 2313, loss 0.00398343, acc 1
2018-03-14T18:08:43.369273: step 2314, loss 0.00392931, acc 1
2018-03-14T18:08:44.183077: step 2315, loss 0.0133805, acc 1
2018-03-14T18:08:44.973547: step 2316, loss 0.00498513, acc 1
2018-03-14T18:08:45.762426: step 2317, loss 0.00570922, acc 1
2018-03-14T18:08:46.566825: step 2318, loss 0.00515369, acc 1
2018-03-14T18:08:47.371859: step 2319, loss 0.00579182, acc 1
2018-03-14T18:08:48.158483: step 2320, loss 0.00573364, acc 1
2018-03-14T18:08:48.948515: step 2321, loss 0.0027075, acc 1
2018-03-14T18:08:49.171691: step 2322, loss 0.00162087, acc 1
2018-03-14T18:08:49.962096: step 2323, loss 0.00221558, acc 1
2018-03-14T18:08:50.759113: step 2324, loss 0.00479193, acc 1
2018-03-14T18:08:51.558617: step 2325, loss 0.00244894, acc 1
2018-03-14T18:08:52.349187: step 2326, loss 0.00280715, acc 1
2018-03-14T18:08:53.143097: step 2327, loss 0.00850281, acc 1
2018-03-14T18:08:53.941834: step 2328, loss 0.00543766, acc 1
2018-03-14T18:08:54.728154: step 2329, loss 0.0166556, acc 0.984375
2018-03-14T18:08:55.525419: step 2330, loss 0.00506143, acc 1
2018-03-14T18:08:56.319662: step 2331, loss 0.00333365, acc 1
2018-03-14T18:08:57.116816: step 2332, loss 0.00309914, acc 1
2018-03-14T18:08:57.913265: step 2333, loss 0.00367296, acc 1
2018-03-14T18:08:58.709958: step 2334, loss 0.00411682, acc 1
2018-03-14T18:08:59.501322: step 2335, loss 0.00300733, acc 1
2018-03-14T18:09:00.294185: step 2336, loss 0.00402484, acc 1
2018-03-14T18:09:01.091332: step 2337, loss 0.00641614, acc 1
2018-03-14T18:09:01.886086: step 2338, loss 0.00619367, acc 1
2018-03-14T18:09:02.681739: step 2339, loss 0.00503623, acc 1
2018-03-14T18:09:03.472891: step 2340, loss 0.00356443, acc 1
2018-03-14T18:09:04.264450: step 2341, loss 0.00393394, acc 1
2018-03-14T18:09:05.058419: step 2342, loss 0.00829867, acc 1
2018-03-14T18:09:05.864123: step 2343, loss 0.00665065, acc 1
2018-03-14T18:09:06.652360: step 2344, loss 0.00813241, acc 1
2018-03-14T18:09:07.444147: step 2345, loss 0.00478199, acc 1
2018-03-14T18:09:08.241843: step 2346, loss 0.00442767, acc 1
2018-03-14T18:09:09.031890: step 2347, loss 0.00776391, acc 1
2018-03-14T18:09:09.819196: step 2348, loss 0.00432514, acc 1
2018-03-14T18:09:10.041345: step 2349, loss 0.00286239, acc 1
2018-03-14T18:09:10.845234: step 2350, loss 0.0105987, acc 1
2018-03-14T18:09:11.632069: step 2351, loss 0.00376132, acc 1
2018-03-14T18:09:12.432700: step 2352, loss 0.00198464, acc 1
2018-03-14T18:09:13.220590: step 2353, loss 0.00452208, acc 1
2018-03-14T18:09:14.016074: step 2354, loss 0.00572935, acc 1
2018-03-14T18:09:14.807479: step 2355, loss 0.00789779, acc 1
2018-03-14T18:09:15.601434: step 2356, loss 0.00289464, acc 1
2018-03-14T18:09:16.386349: step 2357, loss 0.00438331, acc 1
2018-03-14T18:09:17.179162: step 2358, loss 0.00511859, acc 1
2018-03-14T18:09:17.975801: step 2359, loss 0.0215626, acc 1
2018-03-14T18:09:18.774029: step 2360, loss 0.00267849, acc 1
2018-03-14T18:09:19.565008: step 2361, loss 0.00258373, acc 1
2018-03-14T18:09:20.369714: step 2362, loss 0.00562002, acc 1
2018-03-14T18:09:21.159185: step 2363, loss 0.00316816, acc 1
2018-03-14T18:09:21.958659: step 2364, loss 0.00722381, acc 1
2018-03-14T18:09:22.747298: step 2365, loss 0.00798135, acc 1
2018-03-14T18:09:23.534835: step 2366, loss 0.00289812, acc 1
2018-03-14T18:09:24.334175: step 2367, loss 0.00346192, acc 1
2018-03-14T18:09:25.143436: step 2368, loss 0.00539592, acc 1
2018-03-14T18:09:25.941653: step 2369, loss 0.00392967, acc 1
2018-03-14T18:09:26.731845: step 2370, loss 0.0128755, acc 1
2018-03-14T18:09:27.531161: step 2371, loss 0.00302776, acc 1
2018-03-14T18:09:28.313695: step 2372, loss 0.00689413, acc 1
2018-03-14T18:09:29.107032: step 2373, loss 0.00361258, acc 1
2018-03-14T18:09:29.902072: step 2374, loss 0.00299491, acc 1
2018-03-14T18:09:30.694344: step 2375, loss 0.00437036, acc 1
2018-03-14T18:09:30.916957: step 2376, loss 0.00138835, acc 1
2018-03-14T18:09:31.717407: step 2377, loss 0.0195307, acc 0.984375
2018-03-14T18:09:32.500799: step 2378, loss 0.0118466, acc 1
2018-03-14T18:09:33.301487: step 2379, loss 0.00343327, acc 1
2018-03-14T18:09:34.101697: step 2380, loss 0.00610658, acc 1
2018-03-14T18:09:34.895965: step 2381, loss 0.00429257, acc 1
2018-03-14T18:09:35.700511: step 2382, loss 0.00411726, acc 1
2018-03-14T18:09:36.508624: step 2383, loss 0.00517153, acc 1
2018-03-14T18:09:37.308681: step 2384, loss 0.00268644, acc 1
2018-03-14T18:09:38.102410: step 2385, loss 0.00225252, acc 1
2018-03-14T18:09:38.894534: step 2386, loss 0.00505994, acc 1
2018-03-14T18:09:39.694660: step 2387, loss 0.00408071, acc 1
2018-03-14T18:09:40.488274: step 2388, loss 0.0100588, acc 1
2018-03-14T18:09:41.287530: step 2389, loss 0.00388449, acc 1
2018-03-14T18:09:42.086278: step 2390, loss 0.00239371, acc 1
2018-03-14T18:09:42.886548: step 2391, loss 0.00613036, acc 1
2018-03-14T18:09:43.685385: step 2392, loss 0.00382473, acc 1
2018-03-14T18:09:44.481281: step 2393, loss 0.0130303, acc 1
2018-03-14T18:09:45.287143: step 2394, loss 0.00844109, acc 1
2018-03-14T18:09:46.079876: step 2395, loss 0.00314645, acc 1
2018-03-14T18:09:46.873515: step 2396, loss 0.0145262, acc 1
2018-03-14T18:09:47.667667: step 2397, loss 0.00629181, acc 1
2018-03-14T18:09:48.458146: step 2398, loss 0.00431003, acc 1
2018-03-14T18:09:49.247265: step 2399, loss 0.00498324, acc 1
2018-03-14T18:09:50.040259: step 2400, loss 0.00264471, acc 1

Evaluation:
2018-03-14T18:09:51.550050: step 2400, loss 0.332332, acc 0.885442

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-2400

2018-03-14T18:09:52.432781: step 2401, loss 0.00770465, acc 1
2018-03-14T18:09:53.219473: step 2402, loss 0.00552029, acc 1
2018-03-14T18:09:53.440331: step 2403, loss 0.00118133, acc 1
2018-03-14T18:09:54.232598: step 2404, loss 0.00360424, acc 1
2018-03-14T18:09:55.030679: step 2405, loss 0.00154553, acc 1
2018-03-14T18:09:55.826856: step 2406, loss 0.00409692, acc 1
2018-03-14T18:09:56.623605: step 2407, loss 0.00575276, acc 1
2018-03-14T18:09:57.421818: step 2408, loss 0.0027208, acc 1
2018-03-14T18:09:58.221207: step 2409, loss 0.00520094, acc 1
2018-03-14T18:09:59.017239: step 2410, loss 0.00410461, acc 1
2018-03-14T18:09:59.812258: step 2411, loss 0.0032172, acc 1
2018-03-14T18:10:00.617202: step 2412, loss 0.00484402, acc 1
2018-03-14T18:10:01.407763: step 2413, loss 0.00350376, acc 1
2018-03-14T18:10:02.199969: step 2414, loss 0.00417085, acc 1
2018-03-14T18:10:02.994273: step 2415, loss 0.0292956, acc 0.984375
2018-03-14T18:10:03.782249: step 2416, loss 0.00883979, acc 1
2018-03-14T18:10:04.577247: step 2417, loss 0.0135434, acc 0.984375
2018-03-14T18:10:05.365980: step 2418, loss 0.00302266, acc 1
2018-03-14T18:10:06.160405: step 2419, loss 0.00433374, acc 1
2018-03-14T18:10:06.955091: step 2420, loss 0.0041274, acc 1
2018-03-14T18:10:07.753008: step 2421, loss 0.00949735, acc 1
2018-03-14T18:10:08.553040: step 2422, loss 0.00567841, acc 1
2018-03-14T18:10:09.349034: step 2423, loss 0.0185342, acc 1
2018-03-14T18:10:10.148530: step 2424, loss 0.00651971, acc 1
2018-03-14T18:10:10.946506: step 2425, loss 0.00331775, acc 1
2018-03-14T18:10:11.750109: step 2426, loss 0.0111322, acc 1
2018-03-14T18:10:12.544092: step 2427, loss 0.00436018, acc 1
2018-03-14T18:10:13.332311: step 2428, loss 0.00677344, acc 1
2018-03-14T18:10:14.124540: step 2429, loss 0.00629066, acc 1
2018-03-14T18:10:14.351159: step 2430, loss 0.00461272, acc 1
2018-03-14T18:10:15.142089: step 2431, loss 0.00695316, acc 1
2018-03-14T18:10:15.931630: step 2432, loss 0.00946737, acc 1
2018-03-14T18:10:16.728289: step 2433, loss 0.0026473, acc 1
2018-03-14T18:10:17.523850: step 2434, loss 0.00419438, acc 1
2018-03-14T18:10:18.313473: step 2435, loss 0.0061166, acc 1
2018-03-14T18:10:19.110896: step 2436, loss 0.010827, acc 1
2018-03-14T18:10:19.907973: step 2437, loss 0.00622197, acc 1
2018-03-14T18:10:20.699427: step 2438, loss 0.00657407, acc 1
2018-03-14T18:10:21.504744: step 2439, loss 0.00367605, acc 1
2018-03-14T18:10:22.290409: step 2440, loss 0.00429293, acc 1
2018-03-14T18:10:23.085803: step 2441, loss 0.00590983, acc 1
2018-03-14T18:10:23.889792: step 2442, loss 0.00695237, acc 1
2018-03-14T18:10:24.694462: step 2443, loss 0.00577202, acc 1
2018-03-14T18:10:25.736685: step 2444, loss 0.00596547, acc 1
2018-03-14T18:10:26.530558: step 2445, loss 0.00422229, acc 1
2018-03-14T18:10:27.321019: step 2446, loss 0.00410845, acc 1
2018-03-14T18:10:28.108134: step 2447, loss 0.0107946, acc 1
2018-03-14T18:10:28.903192: step 2448, loss 0.0118612, acc 1
2018-03-14T18:10:29.693919: step 2449, loss 0.00444488, acc 1
2018-03-14T18:10:30.493657: step 2450, loss 0.00600303, acc 1
2018-03-14T18:10:31.291500: step 2451, loss 0.00421037, acc 1
2018-03-14T18:10:32.084326: step 2452, loss 0.00244212, acc 1
2018-03-14T18:10:32.876845: step 2453, loss 0.00376109, acc 1
2018-03-14T18:10:33.663183: step 2454, loss 0.0039935, acc 1
2018-03-14T18:10:34.459256: step 2455, loss 0.00319775, acc 1
2018-03-14T18:10:35.256902: step 2456, loss 0.00397879, acc 1
2018-03-14T18:10:35.479674: step 2457, loss 0.00273332, acc 1
2018-03-14T18:10:36.273644: step 2458, loss 0.00189564, acc 1
2018-03-14T18:10:37.076269: step 2459, loss 0.00225546, acc 1
2018-03-14T18:10:37.863324: step 2460, loss 0.00398962, acc 1
2018-03-14T18:10:38.654104: step 2461, loss 0.00438745, acc 1
2018-03-14T18:10:39.446018: step 2462, loss 0.00446091, acc 1
2018-03-14T18:10:40.245984: step 2463, loss 0.00298415, acc 1
2018-03-14T18:10:41.036771: step 2464, loss 0.00493371, acc 1
2018-03-14T18:10:41.838767: step 2465, loss 0.0133076, acc 1
2018-03-14T18:10:42.635604: step 2466, loss 0.00294064, acc 1
2018-03-14T18:10:43.427505: step 2467, loss 0.00456287, acc 1
2018-03-14T18:10:44.231915: step 2468, loss 0.00561385, acc 1
2018-03-14T18:10:45.026128: step 2469, loss 0.00240318, acc 1
2018-03-14T18:10:45.814182: step 2470, loss 0.00478931, acc 1
2018-03-14T18:10:46.614334: step 2471, loss 0.00466437, acc 1
2018-03-14T18:10:47.413289: step 2472, loss 0.00405388, acc 1
2018-03-14T18:10:48.209357: step 2473, loss 0.0018011, acc 1
2018-03-14T18:10:49.002835: step 2474, loss 0.00493766, acc 1
2018-03-14T18:10:49.792846: step 2475, loss 0.00564458, acc 1
2018-03-14T18:10:50.587002: step 2476, loss 0.00401947, acc 1
2018-03-14T18:10:51.381044: step 2477, loss 0.0031791, acc 1
2018-03-14T18:10:52.171701: step 2478, loss 0.00239402, acc 1
2018-03-14T18:10:52.964583: step 2479, loss 0.00309128, acc 1
2018-03-14T18:10:53.769768: step 2480, loss 0.00729795, acc 1
2018-03-14T18:10:54.576272: step 2481, loss 0.00303221, acc 1
2018-03-14T18:10:55.370790: step 2482, loss 0.00460551, acc 1
2018-03-14T18:10:56.163791: step 2483, loss 0.00689122, acc 1
2018-03-14T18:10:56.387982: step 2484, loss 0.0021607, acc 1
2018-03-14T18:10:57.185999: step 2485, loss 0.00487726, acc 1
2018-03-14T18:10:57.991383: step 2486, loss 0.00500104, acc 1
2018-03-14T18:10:58.780561: step 2487, loss 0.0022389, acc 1
2018-03-14T18:10:59.569120: step 2488, loss 0.0106279, acc 1
2018-03-14T18:11:00.366452: step 2489, loss 0.00269904, acc 1
2018-03-14T18:11:01.162866: step 2490, loss 0.00223158, acc 1
2018-03-14T18:11:01.946936: step 2491, loss 0.00357442, acc 1
2018-03-14T18:11:02.738520: step 2492, loss 0.00373592, acc 1
2018-03-14T18:11:03.532300: step 2493, loss 0.00411198, acc 1
2018-03-14T18:11:04.325158: step 2494, loss 0.00410742, acc 1
2018-03-14T18:11:05.112945: step 2495, loss 0.00436659, acc 1
2018-03-14T18:11:05.907421: step 2496, loss 0.00332623, acc 1
2018-03-14T18:11:06.701437: step 2497, loss 0.00792547, acc 1
2018-03-14T18:11:07.498750: step 2498, loss 0.00394681, acc 1
2018-03-14T18:11:08.284189: step 2499, loss 0.00394402, acc 1
2018-03-14T18:11:09.075088: step 2500, loss 0.00568023, acc 1

Evaluation:
2018-03-14T18:11:10.558829: step 2500, loss 0.326765, acc 0.892601

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-2500

2018-03-14T18:11:11.449570: step 2501, loss 0.00572691, acc 1
2018-03-14T18:11:12.244108: step 2502, loss 0.00467687, acc 1
2018-03-14T18:11:13.034721: step 2503, loss 0.00277119, acc 1
2018-03-14T18:11:13.832188: step 2504, loss 0.00230506, acc 1
2018-03-14T18:11:14.627279: step 2505, loss 0.0150325, acc 1
2018-03-14T18:11:15.427428: step 2506, loss 0.00285796, acc 1
2018-03-14T18:11:16.221683: step 2507, loss 0.00545384, acc 1
2018-03-14T18:11:17.013005: step 2508, loss 0.00183052, acc 1
2018-03-14T18:11:17.810755: step 2509, loss 0.000971468, acc 1
2018-03-14T18:11:18.612866: step 2510, loss 0.00516325, acc 1
2018-03-14T18:11:18.829434: step 2511, loss 0.00671289, acc 1
2018-03-14T18:11:19.624573: step 2512, loss 0.00253463, acc 1
2018-03-14T18:11:20.419727: step 2513, loss 0.00692119, acc 1
2018-03-14T18:11:21.219774: step 2514, loss 0.00389799, acc 1
2018-03-14T18:11:22.008639: step 2515, loss 0.00333498, acc 1
2018-03-14T18:11:22.804284: step 2516, loss 0.0025793, acc 1
2018-03-14T18:11:23.589618: step 2517, loss 0.00336907, acc 1
2018-03-14T18:11:24.394930: step 2518, loss 0.00431991, acc 1
2018-03-14T18:11:25.180402: step 2519, loss 0.00571716, acc 1
2018-03-14T18:11:25.976717: step 2520, loss 0.00486647, acc 1
2018-03-14T18:11:26.769619: step 2521, loss 0.00257384, acc 1
2018-03-14T18:11:27.565593: step 2522, loss 0.00374027, acc 1
2018-03-14T18:11:28.354291: step 2523, loss 0.00450373, acc 1
2018-03-14T18:11:29.146132: step 2524, loss 0.00500211, acc 1
2018-03-14T18:11:29.945747: step 2525, loss 0.00292048, acc 1
2018-03-14T18:11:30.745698: step 2526, loss 0.00356848, acc 1
2018-03-14T18:11:31.546183: step 2527, loss 0.00800056, acc 1
2018-03-14T18:11:32.339117: step 2528, loss 0.00324296, acc 1
2018-03-14T18:11:33.133874: step 2529, loss 0.00352018, acc 1
2018-03-14T18:11:33.925594: step 2530, loss 0.00348302, acc 1
2018-03-14T18:11:34.726620: step 2531, loss 0.00372563, acc 1
2018-03-14T18:11:35.522600: step 2532, loss 0.00303525, acc 1
2018-03-14T18:11:36.320261: step 2533, loss 0.00212033, acc 1
2018-03-14T18:11:37.119118: step 2534, loss 0.00347415, acc 1
2018-03-14T18:11:37.911759: step 2535, loss 0.00207312, acc 1
2018-03-14T18:11:38.702934: step 2536, loss 0.0163086, acc 1
2018-03-14T18:11:39.500934: step 2537, loss 0.00444352, acc 1
2018-03-14T18:11:39.718237: step 2538, loss 0.00374688, acc 1
2018-03-14T18:11:40.521033: step 2539, loss 0.00363454, acc 1
2018-03-14T18:11:41.321246: step 2540, loss 0.00323216, acc 1
2018-03-14T18:11:42.117011: step 2541, loss 0.00271897, acc 1
2018-03-14T18:11:42.907130: step 2542, loss 0.00234672, acc 1
2018-03-14T18:11:43.704577: step 2543, loss 0.00482602, acc 1
2018-03-14T18:11:44.494483: step 2544, loss 0.00553204, acc 1
2018-03-14T18:11:45.293002: step 2545, loss 0.00591411, acc 1
2018-03-14T18:11:46.094913: step 2546, loss 0.0029498, acc 1
2018-03-14T18:11:46.891495: step 2547, loss 0.00330673, acc 1
2018-03-14T18:11:47.687631: step 2548, loss 0.00433741, acc 1
2018-03-14T18:11:48.482609: step 2549, loss 0.00145368, acc 1
2018-03-14T18:11:49.274051: step 2550, loss 0.00349616, acc 1
2018-03-14T18:11:50.065025: step 2551, loss 0.00403198, acc 1
2018-03-14T18:11:50.851719: step 2552, loss 0.00544001, acc 1
2018-03-14T18:11:51.642811: step 2553, loss 0.0063963, acc 1
2018-03-14T18:11:52.435286: step 2554, loss 0.00478876, acc 1
2018-03-14T18:11:53.220645: step 2555, loss 0.00567278, acc 1
2018-03-14T18:11:54.018759: step 2556, loss 0.00623806, acc 1
2018-03-14T18:11:54.863152: step 2557, loss 0.0018292, acc 1
2018-03-14T18:11:55.702993: step 2558, loss 0.00618618, acc 1
2018-03-14T18:11:56.513163: step 2559, loss 0.00237115, acc 1
2018-03-14T18:11:57.331816: step 2560, loss 0.00271512, acc 1
2018-03-14T18:11:58.132452: step 2561, loss 0.00137651, acc 1
2018-03-14T18:11:58.958047: step 2562, loss 0.00152105, acc 1
2018-03-14T18:11:59.769956: step 2563, loss 0.00185686, acc 1
2018-03-14T18:12:00.584025: step 2564, loss 0.00327024, acc 1
2018-03-14T18:12:00.805264: step 2565, loss 0.00169749, acc 1
2018-03-14T18:12:01.626910: step 2566, loss 0.00315675, acc 1
2018-03-14T18:12:02.443081: step 2567, loss 0.00334742, acc 1
2018-03-14T18:12:03.232770: step 2568, loss 0.00405525, acc 1
2018-03-14T18:12:04.020390: step 2569, loss 0.00717836, acc 1
2018-03-14T18:12:04.824670: step 2570, loss 0.00513437, acc 1
2018-03-14T18:12:05.624527: step 2571, loss 0.00548994, acc 1
2018-03-14T18:12:06.412544: step 2572, loss 0.00131696, acc 1
2018-03-14T18:12:07.212170: step 2573, loss 0.00101696, acc 1
2018-03-14T18:12:08.005625: step 2574, loss 0.00393743, acc 1
2018-03-14T18:12:08.800188: step 2575, loss 0.00186118, acc 1
2018-03-14T18:12:09.609325: step 2576, loss 0.00178859, acc 1
2018-03-14T18:12:10.408663: step 2577, loss 0.0041531, acc 1
2018-03-14T18:12:11.199880: step 2578, loss 0.00379416, acc 1
2018-03-14T18:12:11.993196: step 2579, loss 0.00283634, acc 1
2018-03-14T18:12:12.792218: step 2580, loss 0.00349041, acc 1
2018-03-14T18:12:13.586536: step 2581, loss 0.00963683, acc 1
2018-03-14T18:12:14.378202: step 2582, loss 0.00279453, acc 1
2018-03-14T18:12:15.174039: step 2583, loss 0.00382984, acc 1
2018-03-14T18:12:15.977876: step 2584, loss 0.00494124, acc 1
2018-03-14T18:12:16.776800: step 2585, loss 0.00918267, acc 1
2018-03-14T18:12:17.577946: step 2586, loss 0.00713501, acc 1
2018-03-14T18:12:18.371159: step 2587, loss 0.00267513, acc 1
2018-03-14T18:12:19.170235: step 2588, loss 0.00577047, acc 1
2018-03-14T18:12:19.969554: step 2589, loss 0.00381667, acc 1
2018-03-14T18:12:20.766990: step 2590, loss 0.00162971, acc 1
2018-03-14T18:12:21.559752: step 2591, loss 0.00417985, acc 1
2018-03-14T18:12:21.778998: step 2592, loss 0.00470271, acc 1
2018-03-14T18:12:22.574220: step 2593, loss 0.00274386, acc 1
2018-03-14T18:12:23.376039: step 2594, loss 0.00127169, acc 1
2018-03-14T18:12:24.171885: step 2595, loss 0.00459573, acc 1
2018-03-14T18:12:24.979345: step 2596, loss 0.00437871, acc 1
2018-03-14T18:12:25.776399: step 2597, loss 0.00311683, acc 1
2018-03-14T18:12:26.562625: step 2598, loss 0.00496811, acc 1
2018-03-14T18:12:27.358395: step 2599, loss 0.00239071, acc 1
2018-03-14T18:12:28.156697: step 2600, loss 0.00220038, acc 1

Evaluation:
2018-03-14T18:12:29.899757: step 2600, loss 0.346027, acc 0.887828

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-2600

2018-03-14T18:12:31.776892: step 2601, loss 0.0056884, acc 1
2018-03-14T18:12:32.579610: step 2602, loss 0.00747995, acc 1
2018-03-14T18:12:33.376305: step 2603, loss 0.00181105, acc 1
2018-03-14T18:12:34.167414: step 2604, loss 0.00503993, acc 1
2018-03-14T18:12:34.957738: step 2605, loss 0.00342899, acc 1
2018-03-14T18:12:35.756458: step 2606, loss 0.0018666, acc 1
2018-03-14T18:12:36.551133: step 2607, loss 0.00713042, acc 1
2018-03-14T18:12:37.347582: step 2608, loss 0.00343933, acc 1
2018-03-14T18:12:38.142230: step 2609, loss 0.00237161, acc 1
2018-03-14T18:12:38.945286: step 2610, loss 0.00142812, acc 1
2018-03-14T18:12:39.746760: step 2611, loss 0.0021526, acc 1
2018-03-14T18:12:40.546147: step 2612, loss 0.002363, acc 1
2018-03-14T18:12:41.345513: step 2613, loss 0.00232387, acc 1
2018-03-14T18:12:42.138234: step 2614, loss 0.00149758, acc 1
2018-03-14T18:12:42.934944: step 2615, loss 0.00307477, acc 1
2018-03-14T18:12:43.731118: step 2616, loss 0.00401437, acc 1
2018-03-14T18:12:44.521008: step 2617, loss 0.00473594, acc 1
2018-03-14T18:12:45.319727: step 2618, loss 0.00926279, acc 1
2018-03-14T18:12:45.547445: step 2619, loss 0.00240082, acc 1
2018-03-14T18:12:46.349298: step 2620, loss 0.0024675, acc 1
2018-03-14T18:12:47.146446: step 2621, loss 0.00166916, acc 1
2018-03-14T18:12:47.944578: step 2622, loss 0.00262998, acc 1
2018-03-14T18:12:48.746932: step 2623, loss 0.00334545, acc 1
2018-03-14T18:12:49.546631: step 2624, loss 0.0100944, acc 1
2018-03-14T18:12:50.349144: step 2625, loss 0.00242611, acc 1
2018-03-14T18:12:51.143601: step 2626, loss 0.00789032, acc 1
2018-03-14T18:12:51.943500: step 2627, loss 0.0032511, acc 1
2018-03-14T18:12:52.742246: step 2628, loss 0.00282642, acc 1
2018-03-14T18:12:53.532555: step 2629, loss 0.00366514, acc 1
2018-03-14T18:12:54.325805: step 2630, loss 0.00277614, acc 1
2018-03-14T18:12:55.131960: step 2631, loss 0.00606535, acc 1
2018-03-14T18:12:55.927705: step 2632, loss 0.0083735, acc 1
2018-03-14T18:12:56.715390: step 2633, loss 0.00422195, acc 1
2018-03-14T18:12:57.513036: step 2634, loss 0.00361419, acc 1
2018-03-14T18:12:58.313277: step 2635, loss 0.0020769, acc 1
2018-03-14T18:12:59.114777: step 2636, loss 0.00258826, acc 1
2018-03-14T18:12:59.912343: step 2637, loss 0.00264232, acc 1
2018-03-14T18:13:00.713369: step 2638, loss 0.00194559, acc 1
2018-03-14T18:13:01.507655: step 2639, loss 0.00158662, acc 1
2018-03-14T18:13:02.302342: step 2640, loss 0.0127182, acc 1
2018-03-14T18:13:03.102564: step 2641, loss 0.00349998, acc 1
2018-03-14T18:13:03.901874: step 2642, loss 0.00413634, acc 1
2018-03-14T18:13:04.692884: step 2643, loss 0.00287469, acc 1
2018-03-14T18:13:05.483212: step 2644, loss 0.00777921, acc 1
2018-03-14T18:13:06.279391: step 2645, loss 0.0078694, acc 1
2018-03-14T18:13:06.505273: step 2646, loss 0.0190977, acc 1
2018-03-14T18:13:07.295729: step 2647, loss 0.0036784, acc 1
2018-03-14T18:13:08.086320: step 2648, loss 0.00773265, acc 1
2018-03-14T18:13:08.876337: step 2649, loss 0.00387917, acc 1
2018-03-14T18:13:09.681039: step 2650, loss 0.00427119, acc 1
2018-03-14T18:13:10.479199: step 2651, loss 0.00290868, acc 1
2018-03-14T18:13:11.275373: step 2652, loss 0.00192809, acc 1
2018-03-14T18:13:12.071305: step 2653, loss 0.00267659, acc 1
2018-03-14T18:13:12.868903: step 2654, loss 0.00291609, acc 1
2018-03-14T18:13:13.664589: step 2655, loss 0.00338174, acc 1
2018-03-14T18:13:14.460762: step 2656, loss 0.00366869, acc 1
2018-03-14T18:13:15.264154: step 2657, loss 0.00310866, acc 1
2018-03-14T18:13:16.058113: step 2658, loss 0.00648838, acc 1
2018-03-14T18:13:16.857559: step 2659, loss 0.0140171, acc 1
2018-03-14T18:13:17.651120: step 2660, loss 0.00738621, acc 1
2018-03-14T18:13:18.441847: step 2661, loss 0.00307261, acc 1
2018-03-14T18:13:19.237199: step 2662, loss 0.00368626, acc 1
2018-03-14T18:13:20.030272: step 2663, loss 0.00578234, acc 1
2018-03-14T18:13:20.821844: step 2664, loss 0.00280304, acc 1
2018-03-14T18:13:21.622274: step 2665, loss 0.00176451, acc 1
2018-03-14T18:13:22.418553: step 2666, loss 0.00299621, acc 1
2018-03-14T18:13:23.208690: step 2667, loss 0.00405882, acc 1
2018-03-14T18:13:24.011138: step 2668, loss 0.00842033, acc 1
2018-03-14T18:13:24.807623: step 2669, loss 0.0043042, acc 1
2018-03-14T18:13:25.614545: step 2670, loss 0.00281435, acc 1
2018-03-14T18:13:26.417181: step 2671, loss 0.0041961, acc 1
2018-03-14T18:13:27.212142: step 2672, loss 0.00242454, acc 1
2018-03-14T18:13:27.433259: step 2673, loss 0.000813254, acc 1
2018-03-14T18:13:28.225953: step 2674, loss 0.00477723, acc 1
2018-03-14T18:13:29.028484: step 2675, loss 0.00358078, acc 1
2018-03-14T18:13:29.816660: step 2676, loss 0.0108011, acc 1
2018-03-14T18:13:30.625978: step 2677, loss 0.00273589, acc 1
2018-03-14T18:13:31.426440: step 2678, loss 0.00602793, acc 1
2018-03-14T18:13:32.225174: step 2679, loss 0.00295646, acc 1
2018-03-14T18:13:33.024887: step 2680, loss 0.00591479, acc 1
2018-03-14T18:13:33.817291: step 2681, loss 0.00542913, acc 1
2018-03-14T18:13:34.705082: step 2682, loss 0.00429577, acc 1
2018-03-14T18:13:35.561863: step 2683, loss 0.00321727, acc 1
2018-03-14T18:13:36.399247: step 2684, loss 0.00380622, acc 1
2018-03-14T18:13:37.200862: step 2685, loss 0.00219914, acc 1
2018-03-14T18:13:37.984573: step 2686, loss 0.00293156, acc 1
2018-03-14T18:13:38.792178: step 2687, loss 0.0045026, acc 1
2018-03-14T18:13:39.594130: step 2688, loss 0.00432225, acc 1
2018-03-14T18:13:40.383341: step 2689, loss 0.0189809, acc 0.984375
2018-03-14T18:13:41.177345: step 2690, loss 0.00162977, acc 1
2018-03-14T18:13:41.984548: step 2691, loss 0.00775335, acc 1
2018-03-14T18:13:42.779306: step 2692, loss 0.0022916, acc 1
2018-03-14T18:13:43.580348: step 2693, loss 0.00349994, acc 1
2018-03-14T18:13:44.385495: step 2694, loss 0.00366777, acc 1
2018-03-14T18:13:45.170952: step 2695, loss 0.00185218, acc 1
2018-03-14T18:13:45.970660: step 2696, loss 0.00246134, acc 1
2018-03-14T18:13:46.781656: step 2697, loss 0.0031293, acc 1
2018-03-14T18:13:47.572789: step 2698, loss 0.00396808, acc 1
2018-03-14T18:13:48.371511: step 2699, loss 0.00597134, acc 1
2018-03-14T18:13:48.595838: step 2700, loss 0.00191799, acc 1

Evaluation:
2018-03-14T18:13:50.151950: step 2700, loss 0.349815, acc 0.885442

Saved model checkpoint to /home/xxliu10/repos/self-taught-text-embeding/runs/1521067038/checkpoints/model-2700

